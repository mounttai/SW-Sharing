link,abstract
/doi/10.1287/isre.1030.0016," Embedded relationships with customers have been key in generating repeat business and economic advantage, especially in business-to-business settings. Such relationships are typically maintained through interpersonal interactions between customers and their providers. Lately, however, firms have been seeking to make their service operations more scalable by offering customers access to Internet-based, self-serve technology. This raises questions about the implications of inserting self-serve technology into embedded relationships. Recent research on the role of information technology (IT) within interfirm network relations suggests that relationships and the use of IT are complementary. However, most of this research focuses on the organizational level and fails to consider the instantiation of these interfirm relations by the actions and interactions of individual actors (e.g., customers and salespeople) representing their respective firms. In this paper, we explore the implications of using IT within interfirm relations through an analysis of customers’ and sales representatives’ (reps) work activities and interpersonal relationships. We apply a practice perspective that highlights how macrolevel phenomena such as interfirm relations are created and recreated through the microlevel actions taken by firm members. This analysis reveals that managing the complementarity between relationships and IT in practice is fraught with considerable tension. This study of WebGA, a bricks-and-clicks dotcom, highlights how the use of the self-serve technology made it more difficult for sales reps to build and maintain embedded relationships with their customers. The use of IT altered the nature and quality of information shared by the participants, undermined the ability of sales reps to provide consulting services to customers, reduced the frequency of their interaction, and prompted sales reps to expend social capital to promote customers’ technology adoption. These changes produced intended and unintended shifts in the network relations enacted by WebGA and its customers, and raised serious challenges to the viability of WebGA’s business model."
/doi/10.1287/mnsc.2019.3399," We study the role of vertical differentiation in the adoption of LEED (Leadership in Energy & Environmental Design), a multitier environmental building certification system. Our identification strategy relies on the timing of adoption and shows that builders seek to differentiate from each other by choosing a different certification level from previously certified buildings. A common concern in this framework is that mean-reverting behavior could be mistaken for differentiation. We develop a new method for establishing the importance of strategic interactions based on simulating from a model with independent choice and unobserved heterogeneity, and showing that such a model cannot generate the level of interaction that we observe. Finally, we estimate a model that incorporates both differentiation incentives and correlated market-level unobservables and use our estimates from this model to simulate the impact of reducing the number of LEED tiers from four to two. The simulations indicate that environmental investments depend on the location of the threshold between tiers. This paper was accepted by Bruno Cassiman, business strategy."
/doi/10.1287/mnsc.2016.2483," Employers and colleges value individuals with leadership service, but there is limited evidence on whether leadership service itself creates skills. Identification in this context has proved difficult because settings in which leadership service accrues to individuals for ostensibly random reasons are rare. In this study we estimate the effects of random assignment to classroom leadership positions in a Chinese secondary school. We find that leadership service increases test scores, increases students’ political popularity in the classroom, makes students more likely to take initiative, and shapes students’ beliefs about the determinants of success. The results suggest that leadership service may impact human capital and is not solely a signal of preexisting skills. Data are available at http://dx.doi.org/10.1287/mnsc.2016.2483 . This paper was accepted by John List, behavioral economics ."
/doi/10.1287/mnsc.2021.4037," We present evidence that unnecessarily complex disclosure can result from strategic incentives to shroud information. In our laboratory experiment, senders are required to report their private information truthfully but can choose how complex to make their reports. We find that senders use complex disclosure more than half the time. This obfuscation is profitable because receivers make systematic mistakes in assessing complex reports. Regression and structural analysis suggest that these mistakes could be driven by receivers who are naive about the strategic use of complexity or overconfident about their ability to process complex information. This paper was accepted by Yan Chen, behavioral economics and decision analysis."
/doi/10.1287/inte.6.1pt2.54," This paper reports a significant combination of a linear-programming model of the Liberty, a communication system which visually depicts the model's output by electronically-produced graphics, and a planning concept which has produced a new, more sensitive approach to asset/liability management of a banking organization in an increasingly volatile financial environment. During the past decade, banks generally have increased leverage and reduced liquidity, thereby making them increasingly vulnerable to interest rate volatility. The Management Reporting System (MRS) described is a practical and unique approach in marrying the various sophisticated disciplines necessary for effective management given such constraints. Liberty's Chairman credited the system with 25¢ per share of the 1973 Operating Earnings and noted that the mix of bank assets and liabilities now can be guided by precise, automated facts, rather than by mere “seat-of-the-pants” instinct. In its 1972 Annual Report, the Corporation stated its 1973 earning's goal “because of the reliable way our Management Reporting System has functioned in 1972.” That objective was met even though economic conditions were vastly different than assumed. The MRS's use permitted the timely adjustments necessary to manage earnings and achieve the publicly stated objective. The paper also explores a more realistic and sensitive approach to liquidity management developed at Liberty. Its impact and value was not only demonstrated during the 1974 liquidity crunch but by its adoption at several of the leading banks across the United States."
/doi/10.1287/opre.50.2.375.428," We consider a firm that provides multiple services using both specialized and flexible capacity. The problem is formulated as a two-stage, single-period stochastic program. The firm invests in capacity before the actual demand is known and optimally assigns capacity to customers when demand is realized. Sample applications include a car rental company's use of mid-sized cars to satisfy unexpectedly high demand for compact cars and an airline's use of business-class seats to satisfy economy-class demand. We obtain an analytical solution for a particular case, when services may be upgraded by one class. The simple form of the solution allows us to compare the optimal capacities explicitly with a solution that does not anticipate flexibility. Given that demand follows a multivariate normal distribution, we analytically characterize the effects of increasing demand correlation on the optimal solution. For the case with two customer classes, the effects of demand correlation are intuitive: Increasing correlation induces a shift from flexible to dedicated capacity. When there are three or more classes, there are also adjustments to the resources not directly affected by the correlation change. As correlation rises, these changes follow an alternating pattern (for example, if the optimal capacity of one resource rises, then the optimal capacity of the adjacent resource falls). These results make precise conjectures based on numerical experiments that have existed in the literature for some time."
/doi/10.1287/mnsc.2019.3534," We report the results of an experiment in which a company, Firm Vary, temporarily suspended its sponsored search advertising campaign on Google in randomly selected advertising markets in the United States. By shutting off its ads, Firm Vary lost customers, but only 63% as many as a nonexperimental estimate would have suggested. Following the experiment, Firm Vary merged with its closest competitor, Firm Fixed. Using combined data from both companies, the experiment revealed that spillover effects of Firm Vary’s search advertising on Firm Fixed’s business and its marketing campaigns were surprisingly small, even in the market for Firm Vary’s brand name as a keyword search term, where the two firms were effectively duopsonists. This paper was accepted by Eric Anderson, marketing ."
/doi/10.1287/mnsc.2017.2946," We present a model with dynamic investment flows, where fund managers have the ability to generate excess returns, and study how forcing them to commit part or all of their personal wealth to the fund they manage affects fund risk taking. We contrast the behavior of a manager who may invest her personal wealth in a private account to a manager who is either forced to commit her wealth to the fund she manages or not allowed to hold risky assets held by the fund privately. We show that a fund managed by a manager with higher ability does not necessarily achieve higher expected returns but achieves lower idiosyncratic volatility. For a manager with constant ability, restrictions placed on her personal account do not influence her choices in the fund, while for a manager whose ability varies stochastically, they result in higher expected returns and idiosyncratic volatilities. Fund strategies can be nonmonotone both in the manager’s commitment level and the ratio of manager to investor wealth. Our results are robust to incomplete information and to competing managers with correlated ability. The internet appendix is available at https://doi.org/10.1287/mnsc.2017.2946 . This paper was accepted by Neng Wang, finance."
/doi/10.1287/opre.2020.1997," Under full substitutability of preferences, it is known that a competitive equilibrium exists in trading networks and is equivalent to (chain) stable outcomes. In this paper, we formulate the problem of finding an efficient set of trades as a generalized submodular flow problem in a suitable network. Existence of a competitive equilibrium and its equivalence with the seemingly weaker notion of stability follow directly from the optimality conditions of the flow problem. Our formulation enables us to perform comparative statics with respect to the number of buyers, sellers, and trades. For instance, we establish that if a new buyer is added to the economy, at an equilibrium the prices of all existing trades increase. In addition, we give a polynomial time algorithm for finding competitive equilibria in trading networks and testing (chain) stability. Funding : O. Candogan gratefully acknowledges financial support from the University of Chicago Booth School of Business. M. Epitropou gratefully acknowledges financial support from the Department of Electrical and Systems Engineering, University of Pennsylvania. The research of R.V. Vohra was supported in part by the National Science Foundation [Grant AST-1343381]."
/doi/10.1287/mnsc.2020.3598," What are the determinants of in-house employment versus outsourcing in the service sector? I use detailed data on U.S. lobbying services to answer this question. I argue with a series of correlational exercises that firms tend to outsource lobbying tasks that demand a large amount of general skills, whereas they are more likely to assign firm-specific tasks to in-house lobbyists. I provide causal evidence that the need to do tasks that vary in their general skill component leads to a change in outsourcing. Using difference-in-difference estimations, I show that the 2010 British Petroleum oil spill increased the general skills needed by oil and gas firms and that, consequently, their use of lobbyists for hire increased. This paper was accepted by Joshua Gans, business strategy."
/doi/10.1287/mnsc.1040.0315," Computing the optimal portfolio policy of an investor facing capital gains tax is a challenging problem: because the tax to be paid depends on the price at which the security was purchased (the tax basis), the optimal policy is path dependent and the size of the problem grows exponentially with the number of time periods. Dammon et al. (2001, 2002, 2004), Garlappi et al. (2001), and Gallmeyer et al. (2001) address this problem by approximating the exact tax basis by the weighted average purchase price. Our contribution is threefold. First, we show that the structure of the problem has several attractive features that can be exploited to determine the optimal portfolio policy using the exact tax basis via nonlinear programming. Second, we characterize the optimal portfolio policy in the presence of capital gains tax when using the exact tax basis. Third, we show that the certainty equivalent loss from using the average tax basis instead of the exact basis is very small: it is typically less than 1% for problems with up to 10 periods, and this result is robust to the choice of parameter values and to the presence of transaction costs, dividends, intermediate consumption, labor income, tax reset provision at death, and wash-sale constraints."
/doi/10.1287/opre.2015.1381," We study a dynamic game in which short-run players repeatedly play a symmetric, strictly supermodular game whose payoffs depend on a fixed unknown state of nature. Each short-run player inherits the beliefs of his immediate predecessor in addition to observing the actions of the players in his social neighborhood in the previous stage. Because of the strategic complementary between their actions, players have the incentive to coordinate with others and learn from them. We show that in any Markov Bayesian equilibrium of the game, players eventually reach consensus in their actions. They also asymptotically receive similar payoffs despite initial differences in their access to information. We further show that, if the players’ payoffs can be represented by a quadratic function, then the private observations are optimally aggregated in the limit for generic specifications of the game. Therefore, players asymptotically coordinate on choosing the best action given the aggregate information available throughout the network. We provide extensions of our results to the case of changing networks and endogenous private signals."
/doi/10.1287/mnsc.2018.3131," This paper studies the effect of providing feedback to college students on their position in the grade distribution by using a natural field experiment. This information was updated every six months during a three-year period. We find that greater grades transparency decreases educational performance, as measured by the number of examinations passed and grade point average (GPA). However, self-reported satisfaction, as measured by surveys conducted after feedback is provided but before students take their examinations, increases. We provide a theoretical framework to understand these results, focusing on the role of prior beliefs and using out-of-trial surveys to test the model. In the absence of treatment, a majority of students underestimate their position in the grade distribution, suggesting that the updated information is “good news” for many students. Moreover, the negative effect on performance is driven by those students who underestimate their position in the absence of feedback. Students who overestimate initially their position, if anything, respond positively. The performance effects are short lived—by the time students graduate, they have similar accumulated GPA and graduation rates. This paper was accepted by John List, behavioral economics."
/doi/10.1287/orsc.10.5.569," Many scholars have described organization form as a management tool in the alignment of organization and environment. As the environment of many companies becomes more chaotic, the exploration of organization forms characterized by flexibility and adaptability has been intensifying. When reviewing existing literature on new organization forms, several gaps become apparent. These gaps can be traced back to the artificial separation between the macrolevel and the firm level of analysis and the prevalence of a static notion of form. To contribute to a more encompassing theory of new organization forms, a coevolutionary perspective is suggested. In this perspective, contextual variation of macrolevel management logics is proposed as a key mediator in the coevolution of organization and environment. At the firm level, the contextual variation of management logics is reflected in shared managerial schemas underlying strategic design actions. The resulting coevolutionary model shows how contextual applications of management logics may be a source of variation in new organization forms. On the basis of a literature review, three management logics, representing ideal types, are described: classical management logic, modern management logic, and postindustrial management logic. These logics are related to three levers of design actions which reflect fundamentally different interventions in form. Linking management logics to design levers results in a set of propositions to be tested in future empirical research."
/doi/10.1287/mnsc.2020.3901," We conducted a field experiment in a Dutch retail chain of 122 stores to study the interaction between team incentives, team social cohesion, and team performance. Theory predicts that the effect of team incentives on team performance increases with the team’s social cohesion because social cohesion reduces free-riding behavior. In addition, team incentives may lead to more coworker support or to higher peer pressure and thereby, can affect the team’s social cohesion. We introduced short-term team incentives in a randomly selected subset of stores and measured for all stores, both before and after the intervention, the team’s sales performance and the team’s social cohesion as well as coworker support and peer pressure. The average treatment effect of the team incentive on sales is 1.5 percentage points, which does not differ significantly from zero. In line with theory, the estimated treatment effect increases with social cohesion as measured before the intervention. Social cohesion itself is not affected by the team incentives. This paper was accepted by Yan Chen, decision analysis."
/doi/10.1287/mnsc.2018.3079," We analyze whether growth firms should delay current investment to hoard cash in order to reduce dilution from external financing. This hoarding motive is the natural counterpart to saving cash as a precaution to help secure funding for future investment opportunities. However, the two motives lead to fundamentally different implications for hoarding and for how cash interacts with key financial and investment decisions. In particular, our paper contributes to understanding why firms choosing private over public financing hoard less, and why product market competition has an ambivalent impact on the public–private choice. This paper was accepted by Gustavo Manso, finance."
/doi/10.1287/mnsc.2013.1755," In a market context, a status effect occurs when actors are accorded differential recognition for their efforts depending on their location in a status ordering, holding constant the quality of these efforts. In practice, because it is very difficult to measure quality, this ceteris paribus proviso often precludes convincing empirical assessments of the magnitude of status effects. We address this problem by examining the impact of a major status-conferring prize that shifts actors' positions in a prestige ordering. Specifically, using a precisely constructed matched sample, we estimate the effect of a scientist becoming a Howard Hughes Medical Institute (HHMI) Investigator on citations to articles the scientist published before the prize was awarded. We do find evidence of a postappointment citation boost, but the effect is small and limited to a short window of time. Consistent with theories of status, however, the effect of the prize is significantly larger when there is uncertainty about article quality, and when prize winners are of (relatively) low status at the time of election to the HHMI Investigator Program. This paper was accepted by David Hsu, entrepreneurship and innovation."
/doi/10.1287/serv.2017.0179," Long-term contracts along with their various internal and external variables lead to inevitable changes in the financial estimation of public–private partnership (PPP) projects. In these cases, and during renegotiations, the excess of benefit/cost should be shared among the key stakeholders, including the private contractor, government, and end users, in terms of contract extensions, annual subsidies, and tariff adjustments, respectively. However, while the allocation of excess befit/cost is an important factor in the successful execution of PPP projects, few methods have considered this issue. Moreover, these methods have rarely involved all three stakeholders and often have evaluated a limited number of possible solutions by qualitative techniques. To address the fair allocation of excess benefit/cost, this paper investigates some sharing mechanisms based on cooperative game concepts, including the core, the nucleolus, and the Shapley value. These mechanisms can improve the renegotiation regulations in PPP contracts and help decision makers manage renegotiations with better structure and supervision. The proposed allocation mechanisms are shown to be fair and practical approaches to managing the financial viability in PPP contracts."
/doi/10.1287/isre.1110.0408," We econometrically evaluate information worker productivity at a midsize executive recruiting firm and assess whether the knowledge that workers accessed through their electronic communication networks enabled them to multitask more productively. We estimate dynamic panel data models of multitasking, knowledge networks, and productivity using several types of micro-level data: (a) direct observation of more than 125,000 email messages over a period of 10 months; (b) detailed accounting data on individuals' project output and team membership for more than 1,300 projects spanning five years; and (c) survey and interview data about the same workers' IT skills, IT use, and information sharing. We find that (1) more multitasking is associated with more project output, but diminishing marginal returns, and (2) recruiters whose network contacts have heterogeneous knowledge—an even distribution of expertise over many project types—are less productive on average but more productive when juggling diverse multitasking portfolios. These results show how multitasking affects productivity and how knowledge networks, enabled by IT, can improve worker performance. The methods developed can be replicated in other settings, opening new frontiers for research on social networks and IT value."
/doi/10.1287/mnsc.1080.0913," There is an emerging debate in the scholarly literature regarding the extent to which academic human capital contributes to firm performance. This debate centers on the nature of an academic scientist's human capital and its institutional specificity. Using data on the human capital of biomedical scientists developed during their careers in academe, this paper analyzes how the depth of their scientifically and commercially oriented academic human capital contributes to firm performance when these scientists subsequently start or join for-profit firms. We find that the scientific and commercial components of an academic scientist's human capital have differential effects on the performance of research and invention tasks at the firm. We also find that the contribution of an academic scientist to a firm's patent productivity is decreasing with the depth of their scientifically oriented human capital, all else constant. These results support the view that academic human capital is heterogeneous and has an institutional specificity that mediates its value when applied in a commercialization environment."
/doi/10.1287/mnsc.41.3.401," Electronic Data Interchange (EDI) is an emerging type of standardized inter-organizational information system. We analyze the impact of EDI on the upstream suppliers’ competitive position in a simple two-level hierarchical market structure where the buyer faces a linear demand curve and the competing heterogeneous suppliers have an upward-sloping marginal cost function. We show that a suppliers’ adoption of EDI can generate positive externalities for the buyer and negative (or competitive) externalities for other suppliers. As a result, the buyer provides a price premium to those suppliers who adopt EDI and increases their sales volume and market share. Moreover, when the benefits that the buyer can derive from implementing EDI are substantial, and the suppliers’ EDI adoption costs are high, it may be in the buyer’s best interest to subsidize the suppliers so as to encourage them to adopt EDI, instead of mandating them to do so. Regardless of whether the buyer employs a mandatory or a subsidizing policy, the buyer and the end consumers may be the only ones who gain from this new technology. Consequently, a partial adoption by the supplier base may be optimal for the buyer when the suppliers’ adoption costs are sufficiently high. We also show that, while EDI reduces the transaction costs of the buyer, the upstream market tends to become more concentrated as a result of increased cost differentials. These results provide one economic explanation of the fact that many companies have actually reduced their supplier base after implementing EDI, despite a significant reduction in their market transaction costs."
/doi/10.1287/orsc.2014.0959," Although many recent studies have emphasized the multiplicity of institutional logics and the competition among them, how some institutional logics become prioritized over others in shaping organizational decisions is undertheorized. Drawing on panel data of 118 industrial facilities across 34 communities in Texas and Louisiana, we show that the saliency of different kinds of community logics significantly affects environmental practices—specifically, toxic waste emissions—of facilities in a community. Our results show that community logics not only have direct effects but also have indirect effects by filtering organizational reactions to broader field-level institutional logics. We theorize how community logics can amplify or dampen the influence of broader field-level logics and discuss the implications for the study of institutional complexity, social movements, and values in the configuration of institutional logics."
/doi/10.1287/mksc.2017.1042," With the cooperation of a large mobile service provider, we conduct a novel field experiment that simultaneously randomizes the prices of two competing movie theaters using mobile coupons. Unlike studies that vary only one firm’s prices, our experiment allows us to account for competitor response. We test mobile targeting based on consumers’ real-time and historic locations, allowing us to evaluate popular mobile coupon strategies in a competitive market. The experiment reveals substantial profit gains from mobile discounts during an off-peak period. Both firms could create incremental profits by targeting their competitor’s location. However, the returns to such “geoconquesting” are reduced when the competitor also launches its own targeting campaign. We combine our experimentally generated data with a demand model to analyze optimal pricing in a static Bertrand–Nash equilibrium. Interestingly, competitive responses raise the profitability of behavioral targeting where symmetric pricing incentives soften price competition. By contrast, competitive responses lower the profitability of geographic targeting, where asymmetric pricing incentives toughen price competition. If we endogenize targeting choice, both firms would choose behavioral targeting in equilibrium, even though more granular geobehavioral targeting combining both real-time and historic locations is possible. These findings demonstrate the importance of considering competitor response when piloting novel price-targeting mechanisms. Data are available at https://doi.org/10.1287/mksc.2017.1042 ."
/doi/10.1287/mnsc.2014.1957," We show that the cost of employee turnover in firms that rely on decentralized knowledge and personal relationships depends on the firms' planning horizons and the departing employees' incentives to transfer information. Using exogenous shocks to the relationship between borrowers and loan officers, we document that borrowers whose loan officers are on leave are less likely to receive new loans from the bank, are more likely to apply for credit from other banks, and are more likely to miss payments or go into default. These costs are smaller when turnover is expected, as in the case of maternity leave, or when loan officers have incentives to transfer information, as in the case of voluntary resignations. This paper was accepted by Wei Jiang, finance ."
/doi/10.1287/mnsc.2018.3142," What motivates the rich and powerful to exhibit generosity? We explore this important question in a large field experiment. We solicit donations from 32,174 alumni of an Ivy League university, including thousands of rich and powerful alumni. Consistent with past psychology research, we find that the rich and powerful respond dramatically, and differently than others, to being given a sense of agency over the use of donated funds. Gifts from rich and powerful alumni increase by 100%–350% when they are given a sense of agency. This response arises primarily on the intensive margin with no effect on the likelihood of donating. Results suggest that motivating the rich and powerful to act may require tailored interventions. This paper was accepted by Uri Gneezy, behavioral economics."
/doi/10.1287/mksc.2014.0867," In this paper, we untangle the searchable and experiential dimensions of quality responses to entry by counterfeiters in emerging markets with weak intellectual property rights. Our theoretical framework analyzes market equilibria under competition from counterfeiting as well as under monopoly branding. A key theoretical prediction is that emerging markets can be self-corrective with respect to counterfeiting issues in the following sense: First, counterfeiters can earn positive profits by pooling with authentic brands only when consumers have good faith in the market (i.e., they believe there is low probability that any product is a counterfeit). When the proportion of counterfeits in the market exceeds a cutoff value, brands invest in self-differentiation from the competitive-fringe counterfeiters. Second, to attain a separating equilibrium with counterfeiters, branded incumbents upgrade the searchable quality (e.g., appearance) of their products more and improve the experiential quality (e.g., functionality) less compared with monopoly equilibrium. However, in the pooling equilibrium with sporadic counterfeits, authentic firms instead may invest in experiential quality to attract more of the expert consumers who are well versed in quality. This prediction uncovers the nature of product differentiation in the searchable dimension and helps with analyzing real-world innovation strategies employed by authentic firms in response to entries by counterfeit entities. In addition, welfare analysis hints at a nonlinear relationship between social welfare and intellectual property enforcement."
/doi/10.1287/mnsc.2014.2110," This paper investigates how venture-backed companies are affected when others sharing the same investor suffer a negative shock. In theory, companies may be helped or hurt in this scenario. To examine the topic empirically, I estimate the impact of the collapse of the technology bubble on non-information-technology (non-IT) companies that were held alongside IInternet companies in venture portfolios. Using a difference-in-differences framework, I find that the end of the bubble was associated with a significantly larger decline in the probability of raising continuation financing for these non-IT companies in comparison to others. This does not appear to be driven by unobservable company characteristics such as company quality or IT relatedness; for the same portfolio company receiving capital from multiple venture firms, investors with greater Internet exposure were significantly less likely to continue to participate in follow-on rounds. This paper was accepted by Itay Goldstein, operations management."
/doi/10.1287/mnsc.2016.2499," We study the effects of reminders on people’s behavior in investment activities characterized by up-front costs and delayed benefits, such as getting an education and maintaining a healthy lifestyle. We conduct a field experiment and show that simple weekly reminders induce users of a gym to substantially increase their gym attendance over an extensive period. Users’ response to reminders is immediate (within hours) and recurrent for any subsequent reminder, which can be explained by limited attention. We find some evidence of habit formation, leading to more frequent physical activity also after treatment, although with an effect smaller than during treatment. Simple reminders are thus a cost-effective policy tool. Data are available at http://dx.doi.org/10.1287/mnsc.2016.2499 . This paper was accepted by Uri Gneezy, behavioral economics ."
/doi/10.1287/inte.28.4.64, The stochastic tree is a recently introduced generalization of the decision tree which allows the explicit depiction of temporal uncertainty while still employing the familiar rollback procedure for decision trees. We offer an introduction to stochastic-tree modeling and techniques involved in their application to medical-treatment decisions. We also describe an application of these tools to the analysis of the decision to undergo a total hip replacement from the perspectives of an individual patient (via utility analysis) and of society (via cost-effectiveness analysis).
/doi/10.1287/orsc.11.2.148.12508," Many employees in the world are evaluated and rewarded at work based on who they are (“particularism”) rather than based on impersonal judgments of their performance (“universalis”). Yet the field of organizational behavior has been virtually silent on how employees react to workplaces dominated by particularism. In an effort to understand the role of particularistic organizational practices, several ideas from comparative institutions theories are applied to questions of organizational behavior, and the model is tested in samples of large manufacturing and service organizations in the United States and Hungary. It was found that employees in a modernist political system (United States) did echo social scientists’ claims by reporting that their employers’ personnel practices were comparatively more universalistic than those in organizations operating in a neotraditional polity (Hungary). This perception of differences in personnel practices mediated the relationship between political system and employees’ trust in one another, their perceptions of coworker shirking, and their organizational commitment."
/doi/10.1287/orsc.2020.1403," We connect two distinct streams of research on categories to study the role of within-category typicality in the context of legitimacy shocks. We argue that, following a legitimacy shock, member organizations of the tainted, focal category suffer equally, irrespective of their typicality. However, only the typical members of the newly favored, oppositional category benefit. Therefore, the effects of legitimacy shocks are asymmetrically influenced by typicality. We argue this pattern is the result of a two-stage process of categorization by audiences, whereby audiences prioritize distinctions between organizations in a newly favored category and spend limited efforts considering distinctions in the tainted, focal category. We examine our theory in the context of the U.S. financial services industry, where four different kinds of organizations engage in competition: traditional commercial banks, community banks, single-bond credit unions, and multibond credit unions. Consistent with our theory, we show that both traditional commercial banks and community banks suffer in terms of deposit market share following the legitimacy shock of the 2007 financial crisis, but the relative gains to credit unions are strongest for single-bond credit unions."
/doi/10.1287/mnsc.2014.2002," Financially constrained borrowers have the incentive to influence the appraisal process in order to increase borrowing or reduce the interest rate. We document that the average valuation bias for residential refinance transactions is above 5%. The bias is larger for highly leveraged transactions, around critical leverage thresholds, and for transactions mediated through a broker. Mortgages with inflated valuations default more often. Lenders account for 60%–90% of the bias through pricing. This paper was accepted by Wei Jiang, finance ."
/doi/10.1287/mnsc.2013.1739," We analyze the implications of the decision to spawn or to retain a new product for the nature and evolution of the firm. In our model, a new product is spawned if the fit between the product and its parent firm organization is not adequate. We focus on the impact of the firm's history of spawning decisions on firm characteristics such as size, focus, profitability, and innovativeness, and analyze its role in shaping firm dynamics. In accordance with the empirical literature, our model predicts that older firms innovate less, spawn less, are more diversified and less profitable, and that firms with more valuable general or specialized resources innovate and spawn more. Echoing seemingly contradictory empirical findings, our model predicts that small, focused firms (large, diversified firms) innovate and spawn more, and are more profitable when sample heterogeneity is driven by the importance of organizational fit (the value of general resources). This paper was accepted by Bruno Cassiman, business strategy."
/doi/10.1287/orsc.2020.1369," Authenticity is a valuable attribution for organizations, but one that raises a challenge of audience acceptance for innovative entrepreneurs. In particular, organizations that depart from an established type risk being judged as inauthentic. However, entrepreneurs may be able to overcome this challenge by basing their authenticity on notions of craft—such as skilled hands-on techniques, sophisticated ingredients, and small-scale artistry rather than mass industrial manufacturing—that better support innovation. We propose that communities vary in the extent to which they embrace craft production as an evolved understanding of authenticity that is less concerned with conformity to type. This local context, in turn, conditions the likelihood of entrepreneurs creating innovative ventures that rely on perceptions of craft authenticity. We develop this argument through a mixed-methods study of the spatially uneven emergence of gourmet food trucks across the United States. Our findings contribute to research on authenticity and the geography of entrepreneurship and innovation."
/doi/10.1287/mnsc.2018.3035," Even though commodity-pricing models have been successful in fitting the term structure of futures prices and its dynamics, they do not generate accurate true distributions of spot prices. This paper develops a new approach to calibrate these models using not only observations of oil futures prices, but also analysts’ forecasts of oil spot prices. We conclude that to obtain reasonable expected spot curves, analysts’ forecasts should be used, either alone or jointly with futures data. The use of both futures and forecasts, instead of using only forecasts, generates expected spot curves that do not differ considerably in the short/medium term, but long term estimations are significantly different. The inclusion of analysts’ forecasts in addition to futures, instead of only futures prices, does not alter significantly the short/medium part of the futures curve but does have a significant effect on long-term futures estimations. This paper was accepted by Gustavo Manso, finance."
/doi/10.1287/opre.1110.1003," We present a methodology for long-term mine planning based on a general capacitated multicommodity network flow formulation. It considers underground and open-pit ore deposits sharing multiple downstream processing plants over a long horizon. The purpose of the model is to optimize several mines in an integrated fashion, but real size instances are hard to solve due to the combinatorial nature of the problem. We tackle this by solving the relaxation of a tight linear formulation, and we round the resulting near-integer solution with a customized procedure. The model has been implemented at Codelco, the largest copper producer in the world. Since 2001, the system has been used on a regular basis and has increased the net present value of the production plan for a single mine by 5%. Moreover, integrating multiple mines provided an additional increase of 3%. The system has allowed planners to evaluate more scenarios. In particular, the model was used to study the option of delaying by four years the conversion of Chiquicamata, Codelco's largest open-pit mine, to underground operations."
/doi/10.1287/mnsc.2020.3837," A person’s success often depends on whether others believe what they say. Growing evidence suggests that people are less likely to believe statements made by women rather than men. We consider whether assertive cheap talk, an important and widely used tool for increasing credibility, is a mechanism for this gender gap. If women face negative returns to assertive cheap talk, then they have less access to an effective tool for increasing their credibility. We provide evidence using a laboratory experiment and an online replication, both with real stakes, in an advice-following setting. We study whether assertive cheap talk affects advice following, whether subjects discriminate based on advisor gender, and whether there are differential returns to assertive cheap talk by gender. Subjects were randomly assigned to an unseen male or female team leader who were otherwise identical and to different types of prescripted, increasingly assertive written communication from the leader. Assertive language significantly increased advice following, but we find no evidence for gender discrimination. We also find that assertive language had positive returns for both male and female leaders, despite subjects perceiving this language as more masculine. However, female subjects were still less likely to choose the self-promotional language. Thus, even in the absence of discrimination, this choice would reduce adherence to advice provided by women, generating a gender gap. Greater use of assertive language could be an effective strategy for women to increase their influence and credibility in the labor market. This paper was accepted by Yan Chen, decision analysis."
/doi/10.1287/mnsc.2015.2308," We explore the impact of geographically bounded, intrafirm linkages (internal agglomerations) and geographically bounded, interfirm linkages (external agglomerations) on firms’ location strategies. Using data from the Census Bureau’s Longitudinal Business Database, we analyze the locations of new establishments of biopharmaceutical firms in the United States from 1993 to 2005. We consider all activities in the value chain and allow location choices to vary by research and development, manufacturing, and sales. Our findings suggest that internal agglomerations have a positive impact on location. The effects of internal agglomerations vary by activity, and they arise both within an activity (e.g., among plants) and across activities (e.g., between sales and manufacturing). Our results also suggest that previous estimates of the effect of external agglomerations may be overestimated because the existing literature abstracted from internal agglomerations. This paper was accepted by Bruno Cassiman, business strategy ."
/doi/10.1287/mksc.2018.1144," Consumers often learn the weights they ascribe to product attributes (“preference weights”) as they search. For example, after test driving cars, a consumer might find that he or she undervalued trunk space and overvalued sunroofs. Preference-weight learning makes optimal search complex because each time a product is searched, updated preference weights affect the expected utility of all products and the value of subsequent optimal search. Product recommendations, which take preference-weight learning into account, help consumers search. We motivate a model in which consumers learn (update) their preference weights. When consumers learn preference weights, it may not be optimal to recommend the product with the highest option value, as in most search models, or the product most likely to be chosen, as in traditional recommendation systems. Recommendations are improved if consumers are encouraged to search products with diverse attribute levels, products that are undervalued, or products for which recommendation-system priors differ from consumers’ priors. Synthetic data experiments demonstrate that proposed recommendation systems outperform benchmark recommendation systems, especially when consumers are novices and when recommendation systems have good priors. We demonstrate empirically that consumers learn preference weights during search, that recommendation systems can predict changes, and that a proposed recommendation system encourages learning. The data files and online appendix are available at https://doi.org/10.1287/mksc.2018.1144 ."
/doi/10.1287/opre.50.5.904.360," Decision making under uncertainty is a challenge faced by many decision makers. Stochastic programming is a major tool developed to deal with optimization with uncertainties which has found applications in, e.g., finance, such as asset–liability and bond–portfolio management. Computationally, however, many models in stochastic programming remain unsolvable because of overwhelming dimensionality. For a model to be well solvable, its special structure must be explored. Most of the solution methods are based on decomposing the data. In this paper we propose a new decomposition approach for two-stage stochastic programming, based on a direct application of the path-following method combined with the homogeneous self-dual technique. Numerical experiments show that our decomposition algorithm is very efficient for solving stochastic programs. In particular, we apply our decomposition method to a two-period portfolio selection problem using options on a stock index. In this model the investor can invest in a money-market account, a stock index, and European options on this index with different maturities. We experiment with our model with market prices of options on the S&P500."
/doi/10.1287/ijoc.1050.0136," Many simulation practitioners can get more from their analyses by using the statistical theory on design of experiments (DOE) developed specifically for exploring computer models. We discuss a toolkit of designs for simulators with limited DOE expertise who want to select a design and an appropriate analysis for their experiments. Furthermore, we provide a research agenda listing problems in the design of simulation experiments—as opposed to real-world experiments—that require more investigation. We consider three types of practical problems: (1) developing a basic understanding of a particular simulation model or system, (2) finding robust decisions or policies as opposed to so-called optimal solutions, and (3) comparing the merits of various decisions or policies. Our discussion emphasizes aspects that are typical for simulation, such as having many more factors than in real-world experiments, and the sequential nature of the data collection. Because the same problem type may be addressed through different design types, we discuss quality attributes of designs, such as the ease of design construction, the flexibility for analysis, and efficiency considerations. Moreover, the selection of the design type depends on the metamodel (response surface) that the analysts tentatively assume; for example, complicated metamodels require more simulation runs. We present several procedures to validate the metamodel estimated from a specific design, and we summarize a case study illustrating several of our major themes. We conclude with a discussion of areas that merit more work to achieve the potential benefits—either via new research or incorporation into standard simulation or statistical packages."
/doi/10.1287/mnsc.1050.0492," Faced with fragmented markets, saturated and demanding customers, and global competition, firms increasingly must design and offer a line of innovative, quality-differentiated products to target customers with differing willingness to pay (WTP). In this context, designing a special class of products that we term development-intensive products (DIPs)—for which the fixed costs of development far outweigh the unit-variable costs—presents some unique managerial challenges. Examples of such development-intensive offerings abound in a number of industries, including the pharmaceutical, information, and entertainment sectors of the economy. Our contributions in this paper are threefold: (a) to show that managerial insights from the traditional approach to product-line design developed for unit-variable cost-intensive products do not carry over to DIPs, (b) to present new mechanisms and managerial guidelines for designing a family of products for which development costs cannot be ignored, and (c) to illustrate the insights with an extended industry example. We find that the design approach based on degrading (or subtracting value from) a high-end product to obtain a subsumed low-end edition , shown in the literature to be an effective approach for designing unit cost-intensive products, can be inappropriate for DIPs. This limitation of value subtraction has implications for the number of variants and the sequence in which they are developed. As an alternative to a subsumed product-design strategy, we propose and examine the overlapped product-design approach , in which a low-end product is not completely subsumed within its high-end counterpart, but differentiated on additional vertical quality dimensions. Our results both explain the recent challenges of firms with subsumed low-end products and guide them in designing a product line to successfully address emerging low-end market segments."
/doi/10.1287/isre.1100.0290," This study extends existing information technology (IT) productivity research by evaluating the contributions of spending in IT outsourcing using a production function framework and an economywide panel data set from 60 industries in the United States over the period from 1998 to 2006. Our results demonstrate that IT outsourcing has made a positive and economically meaningful contribution to industry output and labor productivity. It has not only helped industries produce more output, but it has also made their labor more productive. Moreover, our analysis of split data samples reveals systematic differences between high and low IT intensity industries in terms of the degree and impact of IT outsourcing. Our results indicate that high IT intensity industries use more IT outsourcing as a percentage of their output, but less as a percentage of their own IT capital, and they achieve higher returns from IT outsourcing. This finding suggests that to gain greater value from IT outsourcing, firms need to develop IT capabilities by intensively investing in IT themselves. By comparing the results from subperiods and analyzing a separate data set for the earlier period of 1987–1999, we conclude that the value of IT outsourcing has been stable from 1998 to 2006 and consistent over the past two decades. The high returns we find for IT outsourcing also suggest that firms may be underinvesting in IT outsourcing."
/doi/10.1287/mnsc.1100.1286," Reference-dependent preferences have been well accepted in decision sciences, experimental economics, behavioral finance, and marketing. However, we still know very little about how decision makers form and update their reference points given a sequence of information. Our paper provides some novel experiments in a financial context to advance the understanding of reference-point formation over time. Our subjects' reference price is best described as a combination of the first and the last price of the time series, with intermediate prices receiving smaller and nondecaying weights. Hence, reference prices are not recursive. We provide a parsimonious formula to predict the reference points, which we test out-of-sample. The fit of the model is reasonably good. This paper was accepted by George Wu, decision analysis."
/doi/10.1287/mnsc.1040.0334," In this paper we present a new improved design for multiobject auctions and report on the results of experimental tests of that design. We merge the better features of two extant but very different auction processes, the Simultaneous Multiple Round (SMR) design used by the FCC to auction the electromagnetic spectrum and the Adaptive User Selection Mechanism (AUSM) of Banks et al. (1989, “Allocating uncertain and unresponsive resources: An experimental approach,” RAND Journal of Economics , Vol. 20, No. 1, pp. 1–25). Then, by adding one crucial new feature, we are able to create a new design, the Resource Allocation Design (RAD) auction process, which performs better than both. Our experiments demonstrate that the RAD auction achieves higher efficiencies, lower bidder losses, higher net revenues, and faster times to completion without increasing the complexity of a bidder's problem."
/doi/10.1287/mnsc.2015.2327," With a large nationwide retailer, we run a natural field experiment to measure the effects of energy use information disclosure, customer rebates, and sales agent incentives on demand for energy-efficient durable goods. Although a combination of large rebates plus sales incentives substantially increases market share, information and sales incentives alone each have zero statistical effect and explain at most a small fraction of the low baseline market share. Sales agents strategically comply only partially with the experiment, targeting information to more interested consumers but not discussing energy efficiency with the disinterested majority. These results suggest that seller-provided information is not a major barrier to energy-efficiency investments at current prices in this context. Data, as supplemental material, are available at http://dx.doi.org/10.1287/mnsc.2015.2327 . This paper was accepted by John List, behavioral economics ."
/doi/10.1287/mnsc.2019.3412," Platform marketplaces can potentially steer buyers to certain sellers by recommending or guaranteeing those sellers. Money-back guarantees—which create a direct financial stake for the platform in seller performance—might be particularly effective at steering as they align buyer and platform interests in creating a good match. We report the results of an experiment in which a platform marketplace—an online labor market—guaranteed select sellers for treated buyers. The presence of a guarantee strongly steered buyers to these guaranteed sellers, but offering guarantees did not increase sales overall, suggesting financial risk was not determinative for the marginal buyer. This preference for guaranteed sellers was not the result of their lower financial risk, but rather because buyers viewed the platform’s decision to guarantee as informative about relative seller quality. Indeed, a follow-up experiment showed that simply recommending the sellers that the platform would have guaranteed was equally effective at steering buyers. This paper was accepted by Chris Forman, information systems."
/doi/10.1287/mnsc.1070.0729," Probability forecasters who are rewarded via a proper scoring rule may care not only about the score, but also about their performance relative to other forecasters. We model this type of preference and show that a competitive forecaster who wants to do better than another forecaster typically should report more extreme probabilities, exaggerating toward zero or one. We consider a competitive forecaster's best response to truthful reporting and also investigate equilibrium reporting functions in the case where another forecaster also cares about relative performance. We show how a decision maker can revise probabilities of an event after receiving reported probabilities from competitive forecasters and note that the strategy of exaggerating probabilities can make well-calibrated forecasters (and a decision maker who takes their reported probabilities at face value) appear to be overconfident. However, a decision maker who adjusts appropriately for the misrepresentation of probabilities by one or more forecasters can still be well calibrated. Finally, to try to overcome the forecasters' competitive instincts and induce cooperative behavior, we develop the notion of joint scoring rules based on business sharing and show that these scoring rules are strictly proper."
/doi/10.1287/mnsc.2019.3443," We examine firm and industry characteristics associated with outsourcing and the relation between outsourcing and capital structure using a unique database of outsourcing purchase contracts. We find that highly valued, profitable firms with high-value added per employee and suppliers farther away with higher competition are more likely to outsource using purchase contracts. In addition, we document that firms that operate in industries with more severe import penetration and fewer fixed assets are more likely to outsource using purchase contracts. Examining the outside purchase contract and leverage decisions, we find that the outsourcing decision is associated with less leverage. Our results are consistent with firms that choose to use purchase contracts using less leverage to mitigate the potential loss of relation-specific investments of contracting parties that can occur with financial distress or bankruptcy. This paper was accepted by Gustavo Manso, finance ."
/doi/10.1287/mksc.2016.1021," Chronic diseases, which account for 75% of healthcare expenditure, are of particular importance in trying to understand the rapid growth of healthcare costs over the last few decades. Individuals suffering from chronic diseases can consume three types of services: secondary preventive care, which includes diagnostic tests; primary preventive care, which consists of drugs that help prevent the illness from getting worse; and curative care, which includes surgeries and expensive drugs that provide a quantum boost to the patient’s health. Although the majority of cases can be managed by preventive care, most consumers opt for more expensive curative care that leads to a substantial increase in overall costs. To examine these inefficiencies, we build a model of consumers’ annual medical insurance plan decisions and periodic consumption decisions and apply it to a panel data set. Our results indicate that there exists a sizable segment of consumers who purchase more comprehensive plans than needed because of high uncertainty vis-à-vis their health status, and that once in the plan, they opt for curative care even when their illness could be managed through preventive care. We examine how changing cost-sharing characteristics of insurance plans and providing more accurate information to consumers via secondary preventive care can reduce these inefficiencies. Data and the Web appendix are available at https://doi.org/10.1287/mksc.2016.1021 ."
/doi/10.1287/mnsc.2020.3895," What are the long-term consequences of compensation changes? Using data from an inbound sales call center, we study employee responses to a compensation change that ultimately reduced take-home pay by 7% for the average affected worker. The change caused a significant increase in the turnover rate of the firm’s most productive employees, but the response was relatively muted for less productive workers. On-the-job performance changes were minimal among workers who remained at the firm. We quantify the cost of losing highly productive employees and find that their heightened sensitivity to changes in compensation limits managers’ ability to adjust incentives. Our results speak to a driver of compensation rigidity and the difficulty managers face when setting compensation. This paper was accepted by Lamar Pierce, organizations."
/doi/10.1287/mnsc.2021.3966," Which factors shape the commercialization of academic scientific discoveries via startup formation? Prior literature has identified several contributing factors but does not address the fundamental problem that the commercial potential of a nascent discovery is generally unobserved, which potentially confounds inference. We construct a sample of approximately 20,000 “twin” scientific articles, which allows us to hold constant differences in the nature of the advance and more precisely examine characteristics that predict startup commercialization. In this framework, several commonly accepted factors appear not to influence commercialization. However, we find that teams of academic scientists whose former collaborators include “star” serial entrepreneurs are much more likely to commercialize their own discoveries via startups, as are more interdisciplinary teams of scientists. This paper was accepted by Sridhar Tayur, entrepreneurship and innovation."
/doi/10.1287/mksc.1110.0659," The goal of this paper is to study the behavior of consumers, dealers, and manufacturers in the car sector and present an approach that can be used by managers and policy makers to investigate the impact of significant demand shocks on profits, prices, and dealer networks. More specifically, we investigate consumer demand, substitution patterns, and price decisions across different cars and dealer locations to identify dealerships with low margins or high fixed costs and measure the value of closing down dealerships for manufacturers. We apply our model empirically to the San Diego area using a transactional data set with information about the locations of dealers and consumers, as well as manufacturer and retail prices. We find strong consumer disutility for travel and find that dealers have local demand areas that are shared with a small set of competitors. We show that a reduction of market demand by 30% over two years, similar to the economic crisis of 2008–2009, results in an annual drop in prices of approximately 11%. We discuss this price drop in the context of the 2009 federal policy measure known as the Car Allowance Rebate System program. We compare predictions and actual dealership closings in the General Motors and Chrysler dealer networks as an application of our approach."
/doi/10.1287/mnsc.2019.3457," The transition of the advertising market from traditional media to the internet has induced a proliferation of marketing agencies specialized in bidding in the auctions that are used to sell ad space on the web. We analyze how collusive bidding can emerge from bid delegation to a common marketing agency and how this can undermine the revenues and allocative efficiency of both the generalized second-price auction (GSP, used by Google, Microsoft Bing, and Yahoo!) and the Vickrey–Clarke–Groves (VCG) mechanism (used by Facebook). We find that despite its well-known susceptibility to collusion, the VCG mechanism outperforms the GSP auction in terms of both revenues and efficiency. This paper was accepted by Gabriel Weintraub, revenue management and market analytics ."
/doi/10.1287/isre.2021.1018," We investigate whether revenue-maximizing auctioneers selling heterogeneous items will allow for combinatorial bidding in the presence of auctioneer competition. We compare the choice of auction format by two competing auctioneers with that of a single auctioneer. Bidders are heterogeneous in their demands, with some having synergies for items. We find that, even if a single auctioneer offers a combinatorial auction, competing auctioneers in a comparable setting will not. Instead, the competing auctioneers will segment the market by restricting allowable package bids in order to increase competition between bidders. This shows that it might not be advantageous for an online market platform to offer combinatorial auctions as a design option to competing auctioneers."
/doi/10.1287/mnsc.2019.3539," This study examines how product market peers affect lending relationships. We contend that firms are more likely to borrow from a bank that has previously lent to a peer to mitigate information asymmetry with the bank when potential information processing efficiencies are greater (i.e., information efficiency hypothesis), but there will be a decreased propensity to borrow from a shared lender when the costs of leaking proprietary information are greater (i.e., proprietary information leakage hypothesis). We find that, after bank mergers that involve peers’ lenders, firms are more likely to switch banks to avoid sharing the same lenders as a product market peer. In cross-sectional analyses, we find that after bank mergers that involve a peer’s bank, firms are less likely to switch when the firm’s financial reporting is more opaque and has greater monitoring needs, consistent with the information efficiency hypothesis. In contrast, firms are more likely to switch after bank mergers that involve a peer’s bank when the firm belongs to an industry with greater proprietary costs and when the bank has greater incentives to leak information, consistent with the proprietary cost hypothesis. This paper was accepted by Brian Bushee, accounting."
/doi/10.1287/moor.2016.0799," In the Anscombe-Aumann setup, we provide conditions for a collection of observations to be consistent with a well-known class of smooth ambiguity preferences (Klibanoff P, Marinacci M, Mukerji S (2005) A smooth model of decision making under ambiguity. Econometrica 73(6):1849–1892.). Each observation is assumed to take the form of an equivalence between an uncertain act and a certain outcome. We provide three results that describe these conditions for data sets of different cardinality. Our findings uncover surprising links between the smooth ambiguity model and classic mathematical results in complex and functional analysis."
/doi/10.1287/moor.23.4.983," The question of “fairly” allocating costs or cost-savings among the participants of a joint enterprise is frequently answered by finding the nucleolus of a related cooperative game. In connection with various routing, sequencing and scheduling situations, connected games often arise. Their common feature is that all the essential coalitions (whose breaking up into subcoalitions is disadvantageous for its members) are connected with respect to a fixed order of the players (any player between two members of a coalition is also a member of the coalition). In the literature, several special classes of connected games are discussed that are shown to be balanced. In this paper, an algorithm is presented that computes the nucleolus of a general n -person balanced connected game. The input is the array of the explicitly given values of the n ( n + 1)/2 connected coalitions. The algorithm generates a sequence of at most n ( n − 1)/2 payoff vectors starting from a special vertex of the nonempty core and ending in the nucleolus. By exploiting the special structure of connected games, the initial as well as the subsequent payoff vectors are obtained by evaluating some simple recursive formulas. It is shown that the algorithm requires at most O( n 4 ) time and O( n 2 ) space. A 5-person illustrative example is also given."
/doi/10.1287/mnsc.2020.3709," We use cooperative game theory to investigate multiplayer allocation problems under the almost diminishing marginal contributions (ADMC) property. This property indicates that a player’s marginal contribution to a non-empty coalition decreases as the size of the coalition increases. We develop ADMC games for such problems and derive a necessary and sufficient condition for the non-emptiness of the core. When the core is non-empty, at least one extreme point exists, and the maximum number of extreme points is the total number of players. The Shapley value may not be in the core, which depends on the gap of each coalition. A player can receive a higher allocation based on the Shapley value in the core than based on the nucleolus, if the gap of the player is no greater than the gap of the complementary coalition. We also investigate the least core value for ADMC games with an empty core. To illustrate the applications of our results, we analyze a code-sharing game, a group buying game, and a scheduling profit game. This paper was accepted by Chung Piaw Teo, optimization."
/doi/10.1287/opre.2019.1942," This paper presents an exact penalization theory of the generalized Nash equilibrium problem (GNEP) that has its origin from the renowned Arrow–Debreu general economic equilibrium model. Whereas the latter model is the foundation of much of mathematical economics, the GNEP provides a mathematical model of multiagent noncooperative competition that has found many contemporary applications in diverse engineering domains. The most salient feature of the GNEP that distinguishes it from a standard noncooperative (Nash) game is that each player’s optimization problem contains constraints that couple all players’ decision variables. Extending results for stand-alone optimization problems, the penalization theory aims to convert the GNEP into a game of the standard kind without the coupled constraints, which is known to be more readily amenable to solution methods and analysis. Starting with an illustrative example to motivate the development, this paper focuses on two kinds of coupled constraints, shared (i.e., common) and finitely representable. Constraint residual functions and the associated error bound theory play an important role throughout the development."
/doi/10.1287/orsc.2019.1294," Management practices explain an important part of the heterogeneity in firm productivity, but the literature has largely focused on manufacturing, while leaving out research in the industrial setting. A key managerial practice in industrial research projects is the use of autonomy (through the delegation of decision rights). Our paper clarifies the drivers and the effects of autonomy in settings where other managerial instruments are less effective. We discuss that in industrial research projects, autonomy is set for efficiency reasons—autonomy allows researchers to make more competent decisions about a specific problem—as well as for motivational considerations—autonomy motivates researchers to exert greater effort. We also argue that project - relevant capital —the resources that enhance the productivity of researchers on a given project—is a key driver of autonomy. We theorize that the efficiency and motivational channels have opposite implications for the relationship between project-relevant capital and autonomy and find that, empirically, this relationship is U-shaped, which is suggestive evidence of the presence of both channels."
/doi/10.1287/mnsc.2020.3632," Exposure to environmental cues triggers sudden preference reversals in several choice contexts, including consumption and intertemporal, social, and risky choices. This paper introduces a dual-self model of cue-triggered behavior that (1) is based on a general mechanism that makes it applicable to many choice contexts, (2) allows a sharp comparative analysis of the responsiveness to cues, (3) can explain a wide range of behavioral anomalies, from a cue-triggered present bias to high-frequency variations in social and risk preferences, and (4) can inform the design of managerial interventions and advertising strategies employing environmental cues. Testable restrictions combining choice and nonchoice data fully characterize the model. This paper was accepted by Manel Baucells, decision analysis."
/doi/10.1287/isre.1110.0394," The bullwhip effect is a major source of supply chain inefficiency. Whereas prior literature has identified a number of potential contributing factors and recommended such remedies as information sharing enabled by information technology (IT) or electronic linkage (EL), few studies have provided empirical support. We use industry-level data to examine whether EL use with buyer and supplier industries helps reduce the bullwhip effect as measured by inventory–demand variance ratio. Our major findings are that (1) EL use with supplier industries reduces the bullwhip effect, whereas (2), surprisingly, EL use with buyer industries increases it, but (3) this adverse effect tends to be mitigated by IT use. These findings point to the possible asymmetric effects of EL use in supply chains and provide a different perspective to the existing conclusions in the literature that EL use improves performance. Combining the above results, we have learned that the use of EL tends to behave differently depending on whether it is used upstream or downstream in the supply chain. This also sheds light on the conditions under which such investment may be more (or less) beneficial."
/doi/10.1287/isre.1120.0451," This paper considers on-demand services and its impact on market structure, firm profitability, and consumer welfare. The unique properties of on-demand services are the conversion of fixed costs to variable costs, removal of capacity constraint, and fast setup time (which enables quick entry by any firm at any time when there is opportunity), whereas privacy and security concerns and switching costs have been noted as the biggest barriers from adopting on-demand services. With a stylized model capturing these benefits and barriers to using on-demand services, we establish several results. First, we show that conversion of fixed cost to variable cost enables new and small firms to enter existing markets and leads to the creation of new markets. Second, we show that competition and the threat of new entrants can be an important driver of a firm's decision to switch to on-demand services. In addition, a firm's barriers to using on-demand services can influence another firm's entry decision. Third, we show that two identical firms may employ different technologies in equilibrium. Fourth, we show that fast setup time and removal of capacity constraint associated with on-demand services make it impossible for firms to make supranormal return and would lead to a perfect competitive market, even when there is only one firm, under very general conditions. Such a result still holds even when there exists an economy of scale (e.g., quantity discount) from using on-demand services. On the other hand, when there are barriers preventing firms from offering similar products and products are substantially differentiated, on-demand services can amplify this advantage of entry barriers by enabling firms to further increase prices and enhance their profitability. Therefore, contrary to the common belief that offering on-demand services is best for firms offering commodity products, we show on-demand services to be more profitable for firms with differentiated products."
/doi/10.1287/mnsc.2021.4063," Driving is an integral component of many operational systems, and any small improvement in driving quality can have a significant effect on accidents, traffic, pollution, and the economy in general. However, making improvements is challenging given the complexity and multidimensionality of driving as a task. In this paper, we investigate the effectiveness of nudging to improve driving performance. In particular, we leverage a smartphone application launched by our industry partners to send three types of nudges through notifications to drivers, indicating how they performed on the current trip with respect to their personal best, personal average, and latest driving performance. We measure the resulting driving performance using telematics technology (i.e., real-time sensor data from an accelerometer, Global Positioning System (GPS), and gyroscope in a mobile device). Compared with the “no-nudge” control group, we find that personal best and personal average nudges improve driving performance by approximately 18% standard deviations of the performance scores calculated by the application. In addition, these nudges improve interaccident times (by nearly 1.8 years) and driving performance consistency, as measured by the standard deviation of the performance score. Noting that driving abilities and feedback seeking may vary across individuals, we adopt a generalized random forest approach, which shows that high-performing drivers who are not frequent feedback seekers benefit the most from personal best nudges, whereas low-performing drivers who are also frequent feedback seekers benefit the most from the personal average nudges. Finally, we investigate the potential mechanism behind the results by conducting an online experiment in a nondriving context. The experiment shows that the performance improvements are directly driven by the changes in participants’ effort in response to different nudges and that our key findings are robust in alternative (nondriving) settings. Our analysis further shows that nudges are effective when the variability in reference points is low, which explains why the personal best and personal average nudges are effective, whereas the last score nudge is not. This paper was accepted by Vishal Gaur, operations management."
/doi/10.1287/mnsc.1070.0741," Performance-based contracting is reshaping service support supply chains in capital-intensive industries such as aerospace and defense. Known as “power by the hour” in the private sector and as “performance-based logistics” (PBL) in defense contracting, it aims to replace traditionally used fixed-price and cost-plus contracts to improve product availability and reduce the cost of ownership by tying a supplier's compensation to the output value of the product generated by the customer (buyer). To analyze implications of performance-based relationships, we introduce a multitask principal-agent model to support resource allocation and use it to analyze commonly observed contracts. In our model the customer (principal) faces a product availability requirement for the “uptime” of the end product. The customer then offers contracts contingent on availability to n suppliers (agents) of the key subsystems used in the product, who in turn exert cost reduction efforts and set spare-parts inventory investment levels. We show that the first-best solution can be achieved if channel members are risk neutral. When channel members are risk averse, we find that the second-best contract combines a fixed payment, a cost-sharing incentive, and a performance incentive. Furthermore, we study how these contracts evolve over the product deployment life cycle as uncertainty in support cost changes. Finally, we illustrate the application of our model to a problem based on aircraft maintenance data and show how the allocation of performance requirements and contractual terms change under various environmental assumptions."
/doi/10.1287/trsc.2016.0706," We propose routing algorithms for plug-in hybrid electric vehicles (PHEVs) that account for the significant energy efficiency differences of vehicle operating modes and recommend the predominant mode of operation for each road segment during route planning. This is to enhance fuel economy and reduce emissions. We introduce the energy-efficient routing problem (EERP) for PHEVs and formulate this problem as a new class of the shortest path problem. The objective of the EERP is to not only find a path to any given destination but also to identify the predominant operating mode for each segment of the path to minimize fuel consumption. EERP can be generalized to a new class of problems in the context of network optimization, where for each arc we need to choose which resources to use to minimize the consumption of one of the resources subject to a constraint on the other resource. In this problem, the resource selection is mutually exclusive, which means we cannot choose both resources together for an arc. We prove that the EERP is NP-complete. We then propose two exact algorithms, and a fully polynomial time approximation scheme (FPTAS) to solve the EERP. We demonstrate the performance of our proposed exact and FPTAS algorithms using road network data from Southeast Michigan. The results show that incorporating our proposed algorithms during route planning leads to significant energy savings for PHEVs over simplistic routing algorithms and current practice."
/doi/10.1287/inte.7.4.56," —“Assessment of energy R&D programs for the Appalachian region”; —“From Mexico: A wheat distribution model”; —“Management science model used in Bell system corporate planning”; —“News: Gravitational models in product distribution”; —“News: Ship combat system”; —“News: Medical treatment and evacuation”; —“News: Police patrol operations”; —“News: Pricing of products in the solar array manufacturing industry”; —“Seen Elsewhere” with five overviews: (1) A Rachet Model of Advertising Carryover Effects ( Journal of Marketing , February 1976, Vol. 13, No. 3, pp. 76–79) by Leonard J. Parsons (Claremont Graduate School); (2) Image inputs to a Probabilistic Model: Predicting Retail Potential ( Journal of Marketing , July 1976, Vol. 40, No. 3, pp. 48–53) by Thomas J. Stanley and Murphy A. Sewall (State University of New York at Albany), (3) The State of Practice in Planning Systems ( Sloan Management Review , Winter 1977, Vol. 18, No. 2, pp. 1–24) by H. Igor Ansoff (Vanderbilt University), (4) Production Performance and Customer Satisfaction: A New Concept ( Journal of Marketing April 1976, Vol. 40, No. 2, pp. 11–16) by John E. Swan and Linda Jones Combs (University of Arkansas), (5) Articles from SIMSNIPS, February 1977 and May 1977: A Study of Buffer Management Policies for Data Management Systems, Simulating a Virtual Data Machine, Honeywell Time-Sharing System, Dynamics of a Crash Victim, Patient Admission as a Markov Decision Process, Gasoline-Consumption Model, Simulation of Alternate Pediatric Hospital Care Units, Volume III, Air Defense System, Dayton Aircraft Cabin Fire Model, Reference Scene, Growth, Water Planning, Wheat Yield, Undersea Oil Sites, Computer Workload, Airport Parking, Driver-Vehicle Behavior at an Intersection, Hotel Management, Fire Station Location."
/doi/10.1287/mnsc.2020.3754," This paper develops a theory of financing of entrepreneurial ventures via crypto tokens, which is not limited to platform-based ventures. We compare token financing with traditional equity financing, focusing on agency problems and information asymmetry frictions associated with the two financing methods, as well as on risk sharing between entrepreneurs and investors. Token financing introduces an agency problem not present under equity financing (underproduction), while mitigating an agency problem often associated with equity financing (entrepreneurial effort underprovision). Our theory abstracts from all institutional and potentially transient differences between tokens and equity and is based on a single intrinsic characteristic of tokens: they represent claims to a venture’s output. We show that tokens are likely to dominate equity for ventures developing goods or services that involve low marginal production costs, those for which entrepreneurial effort is crucial, and/or those with relatively low payoff volatility. In addition, tokens can have an advantage over equity in signaling venture quality to outside investors. This paper was accepted by Kay Giesecke, finance."
/doi/10.1287/moor.2020.1095," Consider a dominance relation (a preorder) ≿ on a topological space X , such as the greater than or equal to relation on a function space or a stochastic dominance relation on a space of probability measures. Given a compact set K ⊆ X , we study when a continuous real function on K that is strictly monotonic with respect to ≿ can be extended to X without violating the continuity and monotonicity conditions. We show that such extensions exist for translation invariant dominance relations on a large class of topological vector spaces. Translation invariance or a vector structure are no longer needed when X is locally compact and second countable. In decision theoretic exercises, our extension theorems help construct monotonic utility functions on the universal space X starting from compact subsets. To illustrate, we prove several representation theorems for revealed or exogenously given preferences that are monotonic with respect to a dominance relation."
/doi/10.1287/orsc.1100.0584," The notion that firms can improve their innovativeness by tapping users and customers for knowledge has become prominent in innovation studies. Similar arguments have been made in the marketing literature. We argue that neither literatures take sufficient account of firm organization. Specifically, firms that attempt to leverage user and customer knowledge in the context of innovation must design an internal organization appropriate to support it. This can be achieved in particular through the use of new organizational practices, notably, intensive vertical and lateral communication, rewarding employees for sharing and acquiring knowledge, and high levels of delegation of decision rights. In this paper, six hypotheses were developed and tested on a data set of 169 Danish firms drawn from a 2001 survey of the 1,000 largest firms in Denmark. A key result is that the link from customer knowledge to innovation is completely mediated by organizational practices. This work is licensed under a Creative Commons Attribution 4.0 International License. You are free to copy, distribute, transmit and adapt this work, but you must attribute this work  as “ Organization Science . Copyright © 2017 INFORMS. https://doi.org/10.1287/orsc.1100.0584 , used under a  Creative Commons Attribution License: http://creativecommons.org/licenses/by/4.0/ .”"
/doi/10.1287/trsc.2021.1050," We study cooperation among hinterland container transport operators that may share transport capacity and demand in corridors between inland and sea ports. We model this transportation problem as a minimum cost flow problem and assume that operators share the total cost based on a bargaining outcome, which has been proven equivalent to the Shapley value. To examine the stability of such cooperation, we perform a sensitivity analysis of the membership of the Shapley value (the bargaining outcome) to the core (the set of stable outcomes) by leveraging a novel concept of parametric cooperative games. We obtain closed-form solutions for identical players that explicitly characterize the impact of overcapacity on the stability of cooperation. For more general cases, we develop a computational approach based on parametric optimization techniques. The numerical results indicate that our primary analytical result, that is, that overcapacity undermines stability, is generally valid, and that overcapacitated networks may permit stable cooperation in only a limited range of settings."
/doi/10.1287/mnsc.13.2.B52," Past treatment of the single machine maintenance problem has shown that preventive maintenance may be desirable for equipment for which failures are caused at least partially by wear-out factors. In all previous treatment, however, the size of the maintenance-repair crew has been held constant and the optimal maintenance period has then been determined. This paper develops a simultaneous solution for the maintenance-repair crew size and the optimal maintenance period. The optimal maintenance period is seen to shift as the size of the maintenance-repair crew varies. For the multi-machine maintenance problem, the sharing of the maintenance-repair crew creates a queuing system. Because of its complexity, an analytical solution of this multi-machine maintenance queuing system is not feasible. A simulation model was used to develop a set of general rules for scheduling maintenance for the multi-machine case."
/doi/10.1287/mnsc.2019.3471," How does market competition affect pay inequality between and within firms? Using division managers as a pool of similar workers and the Canada–U.S. Free Trade Agreement, we find that greater competition increases overall pay inequality between, but not within, firms. This null effect within firms is not driven by a lack of statistical power. Instead, we find that it arises primarily within subsamples of firms with higher predicted levels of social comparison. Increased competition leads to greater pay-performance sensitivity among the higher-paid managers within firms, while it leads to greater overpayment among the other managers. These patterns are consistent with firm principals offering higher-powered incentives to their best managers and overpaying the rest. Altogether, this study suggests that, while competition leads to greater pay inequality overall, principals aim to maintain equality within firms and do so through the differential provision of incentives among employees. This paper was accepted by Bruno Cassiman, business strategy ."
/doi/10.1287/deca.2018.0383," Authentication is a major component in protecting the security of online user services. An effective implementation of security policies requires compliance from users, who are one class of key stakeholders in the cybersecurity policy decision problem. We examine this multiple stakeholder decision problem by conducting a virtual public values forum, a policy decision structuring methodology to characterize stakeholder values by eliciting essential trade‐offs among conflicting objectives. We assess trade‐offs for a sample of users to explore heterogeneity in user values and the relationship of trade‐offs to both individual user characteristics and online context. We obtained responses from 265 online service users and elicited their trade‐offs among three conflicting objectives related to authentication security: (1) maximizing security, (2) maximizing convenience, and (3) minimizing cost. Using an additive multiattribute value model with four attributes, we obtained scaling coefficients that denote the relative valuation of each attribute to the decision maker and discovered that for the attribute ranges considered, security followed by cost receive the highest priority; however, there is a group of respondents who consider convenience to have higher valuation than either cost or security. We also explore the relationships between user characteristics (self-efficacy, response efficacy, response cost, and perceived severity) and the calculated scaling coefficients."
/doi/10.1287/mnsc.1100.1214," This paper develops an economic theory of the costs and benefits of corporate culture—in the sense of shared beliefs and values—in order to study the effects of “culture clash” in mergers and acquisitions. I first use a simple analytical framework to show that shared beliefs lead to more delegation, less monitoring, higher utility (or satisfaction), higher execution effort (or motivation), faster coordination, less influence activities, and more communication, but also to less experimentation and less information collection. When two firms that are each internally homogeneous but different from each other merge, the above results translate to specific predictions about how the change in homogeneity will affect firm behavior. This paper's predictions can also serve more in general as a test for the theory of culture as shared beliefs."
/doi/10.1287/mnsc.2017.2865," We analyze the optimal execution problem of a portfolio manager trading multiple assets. In addition to the liquidity and risk of each individual asset, we consider cross asset interactions in these two dimensions, which substantially enriches the nature of the problem. Focusing on the market microstructure, we develop a tractable order book model to capture liquidity supply/demand dynamics in a multiasset setting, which allows us to formulate and solve the optimal portfolio execution problem. We find that cross asset risk and liquidity considerations are of critical importance in constructing the optimal execution policy. We show that even when the goal is to trade a single asset, its optimal execution may involve transitory trades in other assets. In general, optimally managing the risk of the portfolio during the execution process affects the time synchronization of trading in different assets. Moreover, links in the liquidity across assets lead to complex patterns in the optimal execution policy. In particular, we highlight cases where aggregate costs can be reduced by temporarily “overshooting” one’s target portfolio. This paper was accepted by Jerome Detemple, finance."
/doi/10.1287/mnsc.49.2.160.12742," This paper evaluates the relative performances of several well–known and widely–used incentive mechanisms under controlled experimental conditions. The scenario utilized is a delegated investment setting where effort and risk aversions contribute to moral hazard among fund managers. Analytical intractability of the problem requires a computational modeling approach to simulate comparative solutions for specific contracts under different parametric settings. Through a simulation exercise, we consider multiple agents who decide their investment strategy over several consecutive periods. Agents learn about estimation and market uncertainty through repeated realizations of investment returns. In each sequence of periods, a number of different incentive mechanisms based on the agent's communication and/or outcome are considered. Results of the computational experiments are presented. Our results overwhelmingly show the efficacy of the incentive contracts in improving the welfare of the investors. In the presence of an estimation risk, when agents learn from their past performances, the market volatility interacts with the estimation risk that makes risk–sharing arrangements such as limited liability overly important. Paying the agent to assume the risk may no longer lead to the best performance incentives."
/doi/10.1287/mnsc.2018.3274," We offer the first empirical analysis connecting the timing of general partner (GP) compensation to private equity fund performance. Using detailed information on limited partnership agreements between private equity limited and general partners, we find that “GP-friendly” contracts—agreements that pay general partners on a deal-by-deal basis instead of withholding carried interest until a benchmark return has been earned—are associated with higher returns, both gross and net of fees. This is robust to measures of performance persistence, time period effects, and other contract terms and is related to exit-timing incentives. Timing practices balance GP incentives against limited partner downside protection. This paper was accepted by Gustavo Manso, finance."
/doi/10.1287/msom.3.2.151.9989," This paper models a type of vendor-managed inventory (VMI) agreement that occurs in practice called a (z, Z) contract. We investigate the savings due to better coordination of production and delivery facilitated by such an agreement. The optimal behavior of both the supplier and the retailer are characterized. The optimal replenishment and production policies for a supplier are found to be up-to policies, which are shown to be easily computed by decoupling the periods when the supplier outsources from those when the supplier does not outsource. A simple application of the newsvendor relation is used to define the retailer's optimal policy. Numerical analysis is conducted to compare the performance of a single supplier and a single retailer operating under a (z, Z) VMI contract with the performance of those operating under traditional retailer-managed inventory (RMI) with information sharing. Our results verify some observations made in industry about VMI and show that the (z, Z) type of VMI agreement performs significantly better than RMI in many settings, but can perform worse in others."
/doi/10.1287/mksc.2019.1183," Sports franchises derive significant portions of their revenues from season ticket holders. A development that may affect season ticket management is the growth of legal secondary markets. We develop a structural model that integrates both the supply and demand sides of the secondary market into season ticket buyers’ ticket purchase and usage choices. We use a panel data set that combines season and single ticket purchase records with ticket usage data to investigate the value of secondary markets. We estimate that the secondary market increases the team’s season ticket revenues by about $1 million per season. At the level of the individual season ticket customer, we estimate an increase in customer lifetime value ranging from $1,327 in the lowest quality seat tier to $2,553 in the highest. In terms of value to the customer, the average dollar value of having a secondary market is $138 per season ticket. Across segments, the secondary market provides the equivalent of a 4% discount in the premium seat tier versus an 11% discount in the economy seat tier. Whereas the secondary market creates more value in the premium-ticket tier segments, the secondary market has the most impact on behavior in the low price oriented segment."
/doi/10.1287/mnsc.2021.4088," We argue that extrapolative expectations drive boom–bust cycles in the postwar art market. Price run-ups coincide with increases in demand fundamentals but are followed by predictable busts. Predictable changes account for about half of the variance of five-year price changes. High prices coincide with many attributes of speculative bubbles: trading volume, the share of short-term trades, the share of postwar art, and volatility are all higher during booms. In addition, short-term transactions underperform long-term transactions. Survey evidence further confirms the link between beliefs, prices, and volume dynamics as in models in which extrapolative beliefs fuel speculative bubbles. This paper was accepted by Tyler Shumway, finance."
/doi/10.1287/mnsc.49.12.1653.25115," We consider the order-fulfillment process of a supplier producing a customized capital good, such as production equipment, commercial aircraft, medical devices, or defense systems. As is common in these industries, prior to receiving a firm purchase order from the customer, the supplier receives a series of shared forecasts, which are called “soft orders.” Facing a stochastic internal manufacturing lead time, the supplier must decide at what time to begin the fulfillment of the order. This decision requires a trade-off between starting too early, leading to potential holding or cancellation costs, and starting too late, leading to potential delay costs. We collect detailed data of shared forecasts, actual purchase orders, production lead times, and delivery dates for a supplier-buyer dyad in the semiconductor equipment supply chain. Under the assumption that the supplier acts rationally, optimally balancing the cancellation, holding, and delay costs, we are able to estimate the corresponding imputed cost parameters based on the observed data. Our estimation results reveal that the supplier perceives the cost of cancellation to be about two times higher and the holding costs to be about three times higher than the delay cost. In other words, the supplier is very conservative when commencing the order fulfillment, which undermines the effectiveness of the overall forecast-sharing mechanism."
/doi/10.1287/mnsc.2016.2503," We demonstrate that widely used measures of antigay sentiment and the size of the lesbian, gay, bisexual, and transgender (LGBT) population are misestimated, likely substantially. In a series of online experiments using a large and diverse but nonrepresentative sample, we compare estimates from the standard methodology of asking sensitive questions to measures from a “veiled” methodology that precludes inference about an individual but provides population estimates. The veiled method increased self-reports of antigay sentiment, particularly in the workplace: respondents were 67% more likely to disapprove of an openly gay manager when asked with a veil, and 71% more likely to say it should be legal to discriminate in hiring on the basis of sexual orientation. The veiled methodology also produces larger estimates of the fraction of the population that identifies as LGBT or has had a sexual experience with a member of the same sex. Self-reports of nonheterosexual identity rose by 65%, and same-sex sexual experiences by 59%. We conduct a “placebo test” and show that for nonsensitive placebo items, the veiled methodology produces effects that are small in magnitude and not significantly different from zero in seven out of eight items. Taken together, the results suggest antigay discrimination might be a more significant issue than formerly considered, as the nonheterosexual population and antigay workplace-related sentiment are both larger than previously measured. Data, as supplemental material, are available at http://dx.doi.org/10.1287/mnsc.2016.2503 . This paper was accepted by Uri Gneezy, behavioral economics ."
/doi/10.1287/mnsc.48.3.414.7730," In this paper, we consider a supply-chain model consisting of a single product, one supplier, and multiple retailers. Demand at the retailers is random, but stationary. Each retailer places her orders to the supplier according to the well-known ( Q,R ) policy. We assume that the supplier has online information about the demand, as well as inventory activities of the product at each retailer, and uses this information when making order/replenishment decisions. We first propose a replenishment policy for the supplier, which incorporates information about the inventory position of the retailers. Then, we provide an exact analysis of the operating measures of such systems. Assuming the inventory/replenishment decisions are made centrally for the system, we compare the performance of our model with those that do not use information in their decision making, namely, systems that use installation stock policies via a numerical experiment. Based on our numerical results, we identify the parameter settings under which information sharing is most beneficial."
/doi/10.1287/mksc.2021.1316," In 2014, Washington State used a lottery system to allocate licenses to firms in the newly legalized retail cannabis industry, generating random variation in how many stores entrepreneurs were able to own. We observe highly detailed data on all subsequent industry transactions, including prices, wholesale costs, markups, and product assortments. We find that entrepreneurs who are randomly allocated more store licenses ultimately earn substantially higher per store profits than do single-store firms, suggesting that the returns to scale in the mom-and-pop retail sector are quite large. Despite these firms having less local competition, this increase in profits does not come at the expense of consumers. Rather, retailers in multistore chains ultimately charge significantly lower prices and margins and offer greater product variety. This gap in prices is not initially present but grows substantially over time, as does the difference in assortment size and profits between stores in multistore chains and stores operating alone, consistent with firm learning. Using the full history of outcomes, we track the evolution of firms in this new market and show that multistore retailers use an initial advantage in offering larger assortments to position themselves as the low-price, large-assortment retail option and attract a larger but more price-sensitive set of customers. These results have implications for the study of retail concentration and mergers, countervailing buyer power, and consumer search. Our results suggest that policies to help entrepreneurs expand in retail may have large benefits to both firms and consumers."
/doi/10.1287/mnsc.2013.1749," We estimate the stock market effects of the Tiger Woods scandal on his sponsors and sponsors' competitors. In the 10–15 trading days after the onset of the scandal, the full portfolio of sponsors lost more than 2% of market value, with losses concentrated among the core three sponsors: Electronic Arts, Nike, and PepsiCo (Gatorade). Sponsors' day-by-day losses correlate strongly with Google search intensity regarding the endorsement-related impact of the scandal, as well as with qualitative indicators of “endorsement-related news.” At least some sponsors' losses were competitors' gains, suggesting that endorsement deals are partially a business-stealing strategy. However, competitors who were themselves celebrity endorsement intensive fared relatively worse than those who were not endorsement intensive, and that difference also correlates day by day with news/search intensity regarding the scandal. It appears that the scandal sent a negative marketwide signal about the reputation risk associated with celebrity endorsements. This paper was accepted by Pradeep Chintagunta, marketing."
/doi/10.1287/msom.2021.0970," Problem definition : Putting customer experience at the heart of service design has become a governing principle of today’s “experience economy.” Echoing this principle, our paper addresses a service designer’s problem of how to select and sequence activities in designing a service package. Academic/practical relevance: Empirical literature shows an ideal sequence often entails an interior peak ; that is, the peak (i.e., highest-utility) activity is placed neither at the beginning nor the end of the package. Theoretic literature, by contrast, advocates placing the peak activity either at the beginning or at the end. Our paper bridges this gap by developing a theory accounting for interior peaks. It also provides managerial implications for activity sequencing and selection. Methodology : We model the activity sequencing and selection problem as a nonlinear optimization problem and reformulate its objective as an additive function to generate structural insights. Results : We show that heterogeneity in memory decay explains the phenomenon of interior peaks. The optimal sequence is in either an “IU” or “UI” shape. An interior peak is optimal when the memory decay rate of the peak activity is neither too high nor too low. Managerial implications : Our research sheds light on service sequencing by weighing the phenomenon of interior peaks. In the presence of an interior peak, we show it is optimal to schedule a low point immediately before or after the peak activity, creating a contrast in customer experience. In addition, interior peaks arise partly because the peak activity is more memorable than others. Guided by this logic, as the peak activity becomes even more memorable, one might be tempted to move it to an earlier slot; we show that, counterintuitively, moving it to a later slot can be optimal. Our research also provides implications for activity selection by showing the optimal portfolio may consist of activities with the highest- and lowest-utility values but not those with medium values."
/doi/10.1287/orsc.2020.1376," Team production is ubiquitous in the economy, but managing teams effectively remains a challenge for many organizations. This paper studies how familiarity among teammates influences the performance of specialist teams, relative to nonspecialist teams. Applying theories of team production to contexts where team members coordinate interdependent activities extemporaneously, we develop predictions about factors that shift the marginal returns to specialization along two dimensions of familiarity: social familiarity and functional familiarity. We test our hypotheses in the context of Defence of the Ancients 2 (DOTA2), a major e-sports game where, in some formats, players are exogenously assigned to five-person teams. After analyzing nearly 6.5 million matches, we find that specialist teams are relatively more successful when members are more socially and functionally familiar with one another. The results suggest that the plug-and-play perspective on specialist teams is incomplete; rather, specialization and familiarity are complements in dynamic environments where team members coordinate extemporaneously. Funded: Financial support from the UCL School of Management and Worcester Polytechnic Institute is gratefully acknowledged."
/doi/10.1287/deca.1100.0178," Our study analyzes the determinants of investors' risk-taking behavior. We find that investors' risk-taking behavior is affected by their subjective risk attitude in the financial domain and by the risk and return of an investment alternative. Our results also suggest that, consistent with previous findings in the literature, the objective, or historical, return and volatility of a stock are worse predictors of risk-taking behavior than subjective risk and return measures. Moreover, we illustrate that overconfidence, or more precisely, miscalibration, has an impact on risk behavior as predicted by theoretical models. However, our results regarding the effect of various determinants on risk-taking behavior heavily depend on the content domain in which the respective determinant is elicited. We interpret this as an indication for an extended content domain specificity. In particular, with regard to the Markets of Financial Instruments Directive, we believe practitioners could improve on their investment advising process by incorporating some of the determinants that, by our argument, influence investment behavior."
/doi/10.1287/mnsc.1060.0520," We consider three sets of phenomena that feature prominently in the financial economics literature: (1) conditional mean dependence (or lack thereof) in asset returns, (2) dependence (and hence forecastability) in asset return signs, and (3) dependence (and hence forecastability) in asset return volatilities. We show that they are very much interrelated and explore the relationships in detail. Among other things, we show that (1) volatility dependence produces sign dependence, so long as expected returns are nonzero, so that one should expect sign dependence, given the overwhelming evidence of volatility dependence; (2) it is statistically possible to have sign dependence without conditional mean dependence; (3) sign dependence is not likely to be found via analysis of sign autocorrelations, runs tests, or traditional market timing tests because of the special nonlinear nature of sign dependence, so that traditional market timing tests are best viewed as tests for sign dependence arising from variation in expected returns rather than from variation in volatility or higher moments; (4) sign dependence is not likely to be found in very high-frequency (e.g., daily) or very low-frequency (e.g., annual) returns; instead, it is more likely to be found at intermediate return horizons; and (5) the link between volatility dependence and sign dependence remains intact in conditionally non-Gaussian environments, for example, with time-varying conditional skewness and/or kurtosis."
/doi/10.1287/opre.1100.0877," Breast cancer is the most common non-skin cancer affecting women in the United States, where every year more than 20 million mammograms are performed. Breast biopsy is commonly performed on the suspicious findings on mammograms to confirm the presence of cancer. Currently, 700,000 biopsies are performed annually in the U.S.; 55%–85% of these biopsies ultimately are found to be benign breast lesions, resulting in unnecessary treatments, patient anxiety, and expenditures. This paper addresses the decision problem faced by radiologists: When should a woman be sent for biopsy based on her mammographic features and demographic factors? This problem is formulated as a finite-horizon discrete-time Markov decision process. The optimal policy of our model shows that the decision to biopsy should take the age of patient into account; particularly, an older patient's risk threshold for biopsy should be higher than that of a younger patient. When applied to the clinical data, our model outperforms radiologists in the biopsy decision-making problem. This study also derives structural properties of the model, including sufficiency conditions that ensure the existence of a control-limit type policy and nondecreasing control-limits with age."
/doi/10.1287/moor.2019.1022," A solution on a set of transferable utility (TU) games satisfies strong aggregate monotonicity (SAM) if every player can improve when the grand coalition becomes richer. It satisfies equal surplus division (ESD) if the solution allows the players to improve equally. We show that the set of weight systems generating weighted prenucleoli that satisfy SAM is open, which implies that for weight systems close enough to any regular system, the weighted prenucleolus satisfies SAM. We also provide a necessary condition for SAM for symmetrically weighted nucleoli. Moreover, we show that the per capita nucleolus on balanced games is characterized by single-valuedness (SIVA), translation covariance (TCOV) and scale covariance (SCOV), and equal adjusted surplus division (EASD), a property that is comparable to but stronger than ESD. These properties together with ESD characterize the per capita prenucleolus on larger sets of TU games. EASD and ESD can be transformed to independence of ( adjusted ) proportional shifting , and these properties may be generalized for arbitrary weight systems p to I(A)S p . We show that the p -weighted prenucleolus on the set of balanced TU games is characterized by SIVA, TCOV, SCOV, and IAS p and on larger sets by additionally requiring IS p ."
/doi/10.1287/deca.1060.0076," Decision analysis and the psychology of judgment and decision making are two distinct fields linked by common foundations and overlapping communities of researchers. Progress in psychological science is important to decision analysis because it provides insights about when decision analysis is likely to be needed as well as the practical problems we may encounter in implementing analytic processes in real world settings. This special issue includes four contributions to the psychology of decision making that are relevant to prescriptive decision analysis. The first article proposes a theoretical account of when choice heuristics are likely to perform well (or not) relative to normative benchmarks. The second contribution examines how decision makers aggregate multiple sources of information. The third article reports a survey study of real-world risk-taking behavior, and the fourth article investigates the sensitivity of probability assessments to time horizons."
/doi/10.1287/mnsc.2016.2588," Experimental tests of expected-utility theory (EU) have accumulated empirical observations in which the predictions of EU are systematically violated. The cumulative prospect theory (CPT) explains violations such as the Allais paradoxes and fourfold pattern of risk attitudes as resulting from nonlinear probability transformations. Here we show that the classical paradoxes for decisions under risk can be explained with preferences that are linear in probabilities for any choice set and that maximize an expected-utility function with respect to an endogenous target return. We introduce the maximin payoff as a plausible and even natural target return from a choice set and show that the resulting target-adjusted utility (TAU) model explains additional empirical observations such as the scale dependence of the Allais paradox that cannot be explained by standard specifications of CPT. Further, using data from three prominent laboratory experiments, we find that TAU is effective in explaining observed behaviors. This paper was accepted by James Smith, decision analysis ."
/doi/10.1287/orsc.1090.0447," Change in firm governance is often associated with inbound and outbound movements of key decision makers. This research extends that observation by treating mobility as a trigger of demographic change in management teams that, in turn, influences organizational survival. Mobility occasions transformations in demographic profiles both within a firm and among firms sharing a competitive arena. In the former case, shifts in diversity may alter the quasi-resolution of conflict achieved by the firm's upper echelons, or, conversely, serve to inject novel views and ideas. In the latter case, migration may modify the demographic overlap among firms and thus rearrange their competitive positioning. We present here an empirical test of this two-pronged manifestation of demographic change and stress the moderating roles of team age and competitive intensity."
/doi/10.1287/moor.1040.0091," We explore the properties of a congestion game in which users of a congested resource anticipate the effect of their actions on the price of the resource. When users are sharing a single resource, we establish that the aggregate utility received by the users is at least 3/4 of the maximum possible aggregate utility. We also consider extensions to a network context, where users submit individual payments for each link in the network they may wish to use. In this network model, we again show that the selfish behavior of the users leads to an aggregate utility that is no worse than 3/4 of the maximum possible aggregate utility. We also show that the same analysis extends to a wide class of resource allocation systems where end users simultaneously require multiple scarce resources. These results form part of a growing literature on the “price of anarchy,” i.e., the extent to which selfish behavior affects system efficiency."
/doi/10.1287/mksc.1040.0094," We argue that standardized information disclosure (information using a common format and uniform metrics) creates asymmetric opportunities for firms, which affects their strategies and survival. We test our predictions using a longitudinal, quasi-experimental field study, involving the Nutrition Labeling and Education Act of 1990 (NLEA), and we focus on firm market share within a category as a key asymmetry. Findings indicate that, in general, the NLEA had no effect on firm responses. However, when accounting for firm differences, we observe that the NLEA led to (1) an increase in small-share firm exits and (2) a greater increase in distribution for large-share firms. No concurrent increase in price by large-share firms following the NLEA was observed. We conclude by discussing the implications of these effects for firm strategy, the design of public policy, and theories regarding the impact of information on markets."
/doi/10.1287/orsc.2015.0970," In the early to mid-1990s, technology alliances suddenly surged to unprecedented levels—roughly 300% growth per year from 1990 to 1995—and then declined just as precipitously. This massive increase in alliance activity caused the crystallization of a giant component in the global technology network that connected a large portion of the world’s firms, government labs, universities, and other organizations. However, when alliance activity declined, the component disintegrated. What caused this spike in alliance activity? And did this large-but-transient change in collaboration activity leave any enduring effect? The data here suggest that a major technology shock may have provoked this alliance surge. A technology shock may simultaneously unleash significant innovation opportunities while creating great uncertainty in the economic environment. Though it is well known that firms often use alliances both to respond to uncertainty and facilitate innovation, little is known about how technology shocks affect the collaboration behavior of firms and how these two factors separately influence innovation outcomes. I integrate an inductive study of collaboration activity and a technology shock with existing research on economics, alliances, and networks to build a set of arguments about how technology shocks will influence alliance behavior, how changes in alliance behavior will influence the global technology collaboration network, and about how each of these changes is likely to influence the innovative outcomes of firms. I then explore the separate and joint effects of the technology shock and collaboration activity on innovation using a large sample panel study of patenting by North American firms."
/doi/10.1287/mksc.1090.0529," The price-aggressive discount format, popularized by chains such as Aldi and Lidl, is very successful in most Western economies. Its success is a major source of concern for traditional supermarkets. Discounters not only have a direct effect on supermarkets' market shares, but they also exert considerable pressure to improve operational efficiency and/or to decrease prices. We use an empirical entry model to study the degree of intra- and interformat competition between discounters and supermarkets. Information on the competitive impact of new entrants is derived from the observed entry decisions of supermarkets and discounters in a large cross section of local markets, after controlling for a number of local market characteristics. In our modeling framework, we endogenize the number of retailers and allow for asymmetric intra- and interformat competitive effects in a flexible way. We apply our modeling approach to the German grocery industry, where the discount format has stabilized after two decades of continued growth. We find evidence of intense competition within both the supermarket and discounter format, although competition between supermarkets is found to be more severe. Most importantly, discounters only start to affect the profitability of conventional supermarkets from the third entrant onwards. This may explain why many retailers rush to add a discount chain to their portfolio: early entrants may benefit from the growth of the discount-prone segment without cannibalizing the profits of their more conventional supermarket stores."
