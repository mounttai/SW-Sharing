link,abstract
/doi/10.1287/mnsc.2021.3967," This paper investigates empirically the effect of market power on dynamic pricing in the presence of inventories. Our setting is the auto retail industry; we analyze how automotive dealerships adjust prices to inventory levels under varying degrees of market power. We first establish that inventory fluctuations create scarcity rents for cars that are in short supply. We then show that dealers’ ability to adjust prices in response to inventory depends on their market power, that is, the quantity of substitute inventory in their selling area. Specifically, we show that the slope of the price–inventory relationship (higher inventory lowers prices) is significantly steeper when dealers find themselves in a situation of high rather than low market power. A dealership with high market power moving from a situation of inventory shortage to a median inventory level lowers transaction prices by about 0.57% ceteris paribus, corresponding to 32.5% of dealers’ average per-vehicle profit margin or $145.6 on the average car. Conversely, when competition is more intense, moving from inventory shortage to a median inventory level lowers transaction prices by about 0.35% ceteris paribus, corresponding to 20.2% of dealers’ average per-vehicle profit margin or $90.9. To our knowledge, we are the first to empirically show that market power affects firms’ ability to dynamically price. This paper was accepted by Juanjuan Zhang, marketing."
/doi/10.1287/mnsc.2014.1932," A key concern about counterfeits and weak intellectual property protection is that they may hamper innovation by displacing legitimate sales. This paper combines a natural policy experiment with randomized lab experiments to estimate the heterogeneous impacts of counterfeiting on the sales and consumer purchase intent related to branded products of various quality levels. I collect new product-line-level panel data (1993–2004) on Chinese shoe companies. I identify heterogeneous effects of counterfeit entry on sales of authentic products of three quality tiers, finding that counterfeits have both advertising effects for a brand and substitution effects for authentic products, additionally the effects linger for some years. The advertising effect dominates the substitution effect for high-end authentic product sales, and the substitution effect outweighs the advertising effect for low-end product sales. The positive effect of counterfeits is most pronounced for high-fashion products (such as women's high-leg boots and dress shoes), shoes tailored to young customers, and high-end products of brands not yet well-known at the time of counterfeiter entry. This paper was accepted by David Hsu, entrepreneurship and innovation."
/doi/10.1287/inte.1110.0610," A large US retailer that procures transportation services from third-party carriers experienced an unexpected jump in fuel surcharges as the price of diesel fuel skyrocketed in the summer of 2008. As a result, it sought to limit its future exposure to diesel price risk. We collaborated with this retailer to create a lane assignment optimizer (LAO) that incorporates diesel price risk when selecting carriers for its transportation lanes. The LAO tool has significantly improved the retailer's capability to evaluate the trade-off between the two crucial components of a lane's per-shipment cost: base price and risk-adjusted fuel surcharge. The retailer can now take diesel price risk into account when selecting cost-effective carriers for its lanes, negotiating fuel surcharge limits to share diesel price risk with its carriers, and better aligning the fuel surcharges it pays with the true cost of diesel. We estimate that the more favorable contract terms the retailer negotiated for 2009–2011 translate to nearly $5 million in potential savings during years with unexpected diesel price hikes, such as 2008."
/doi/10.1287/mnsc.2017.2864," Prior studies attribute analysts’ forecast superiority over time-series forecasting models to their access to a large set of firm, industry, and macroeconomic information (an information advantage), which they use to update their forecasts on a daily, weekly or monthly basis (a timing advantage). This study leverages recently developed mixed data sampling (MIDAS) regression methods to synthesize a broad spectrum of high frequency data to construct forecasts of firm-level earnings. We compare the accuracy of these forecasts to those of analysts at short horizons of one quarter or less. We find that our MIDAS forecasts are more accurate and have forecast errors that are smaller than analysts’ when forecast dispersion is high and when the firm size is smaller. In addition, we find that combining our MIDAS forecasts with analysts’ forecasts systematically outperforms analysts alone, which indicates that our MIDAS models provide information orthogonal to analysts. Our results provide preliminary support for the potential to automate the process of forecasting firm-level earnings, or other accounting performance measures, on a high-frequency basis. The online appendix is available at https://doi.org/10.1287/mnsc.2017.2864 . This paper was accepted by Mary Barth, accounting."
/doi/10.1287/inte.1080.0415," The US Environmental Protection Agency (EPA) is the lead federal agency for the security of drinking water in the United States. The agency is responsible for providing information and technical assistance to the more than 50,000 water utilities across the country. The distributed physical layout of drinking-water utilities makes them inherently vulnerable to contamination incidents caused by terrorists. To counter this threat, the EPA is using operations research to design, test, and deploy contamination warning systems (CWSs) that rapidly detect the presence of contaminants in drinking water. We developed a software tool to optimize the design process, published a decision-making process to assist utilities in applying the tool, pilot-tested the tool on nine large water utilities, and provided training and technical assistance to a larger group of utilities. We formed a collaborative team of industry, academia, and government to critique our approach and share CWS deployment experiences. Our work has demonstrated that a CWS is a cost-effective, timely, and capable method of detecting a broad range of contaminants. Widespread application of these new systems will significantly reduce the risks associated with catastrophic contamination incidents: the median estimated fatalities reduction for the nine utilities already studied is 48 percent; the corresponding economic-impact reduction is over $19 billion. Because of this operations research program, online monitoring programs, such as a CWS, are now the accepted technology for reducing contamination risks in drinking water."
/doi/10.1287/mksc.1090.0516," During the summer of 2005, the three domestic U.S. automobile manufacturers offered a customer promotion that allowed customers to buy new cars using discount programs formerly offered only to employees. The initial months of the promotion were record sales months for each of the three firms, suggesting that customers thought that the prices offered during the promotion were particularly attractive. In reality, however, many customers paid higher prices under the employee discount pricing promotion. We propose that the promotion changed customers' beliefs about current versus future prices, convincing them to purchase during the promotion rather than delay in anticipation of future discounts. We investigate several alternative explanations for the simultaneous increase in prices and sales, including advertising, decreased financing costs, industry trends, disutility of bargaining, consumer differences, and changes in trade-in values. None of these explanations fully explains the concomitant increase in prices and sales."
/doi/10.1287/mnsc.2013.1873," We examine the role of target firms’ accounting quality in the merger and acquisition process. We predict that target firm accounting quality will be positively associated with (1) the likelihood that the deal will be structured as a negotiation rather than as an auction, (2) the speed with which the deal reaches final resolution, and (3) the likelihood that the proposed deal is ultimately completed. Our empirical evidence is consistent with these predictions. These results complement and extend existing findings on target firm accounting quality and provide new evidence that financial accounting quality relates positively to the efficient allocation of the economy’s capital resources. This paper was accepted by Mary Barth, accounting ."
/doi/10.1287/mnsc.2014.2088," Relationship lending may create benefits for borrowers by reducing information asymmetries. However, empirical evidence is mixed. We conduct a meta-analysis to summarize and explain the heterogeneity in the results in the literature using hand-collected information from 101 studies in the United States, Europe, Asia, and Latin America from 1970 to 2010. We find that strong relationships are generally beneficial for borrowers, but lending outcomes differ across the relationships’ dimensions. Long-lasting, exclusive, and synergy-creating bank relationships are associated with higher credit volume and lower loan rates. These benefits are more likely in the United States and in countries where bank competition is high. They are not related to the importance of small and medium-sized enterprises in an economy, suggesting that prevalence of relationship lending does not necessarily come along with borrower benefits. Our inferences are robust when we control for observed systematic heterogeneity in the original studies and hold in a bootstrapping analysis. Data, as supplemental material, are available at http://dx.doi.org/10.1287/mnsc.2014.2088 . This paper was accepted by Wei Jiang, finance ."
/doi/10.1287/mnsc.2021.4089," We study anticompetitive horizontal mergers in a dynamic model with noisy collusion. At each instant, firms either privately choose output levels or merge to form a monopoly, trading off the benefits of avoiding price wars against the costs of merging. The potential to merge decreases pre-merger collusion, as punishments effected by price wars are weakened. We thus extend the result of Davidson and Deneckere [Davidson C, Deneckere R (1984) Horizontal mergers and collusive behavior. Internat. J. Indust. Organ. 2(2):117–132.], who analyzed the weakening of punishments post-merger, demonstrating that pre-merger collusion is weakened, in a fully stochastic model. Thus, although anticompetitive mergers harm competition ex post, the implication is that barriers and costs of merging due to regulation should be reduced to promote competition exante. This paper was accepted by Tomasz Piskorski, finance."
/doi/10.1287/isre.1080.0190," The interactive nature of the Internet promotes collaborative business models (e.g., auctions) and facilitates information-sharing via social networks. In Internet auctions, an important design option for sellers is the setting of a secret reserve price that has to be met by a buyer's bid for a successful purchase. Bidders have strong incentives to learn more about the secret reserve price in these auctions, thereby relying on their own network of friends or digital networks of users with similar interests and information needs. Information-sharing and flow in digital networks, both person-to-person and via communities, can change bidding behavior and thus can have important implications for buyers and sellers in secret reserve price auctions. This paper uses a multiparadigm approach to analyze the impact of information diffusion in social networks on bidding behavior in secret reserve price auctions. We first develop an analytical model for the effect of shared information on individual bidding behavior in a secret reserve price auction with a single buyer facing a single seller similar to eBay's Best Offer and some variants of NYOP. Next, we combine the implications from our analytical model with relational data that describe the individual's position in social networks. We empirically test the implications of our analytical model in a laboratory experiment, and examine the impact of information diffusion in social networks on bidding behavior in a field study with real purchases where we use a virtual world as proxy for the real world. We find that the amount and dispersion of information in the individualized context, and betweenness centrality in the social network context, have a significant impact on bidding behavior. Finally, we discuss the implications of our results for buyers and sellers."
/doi/10.1287/trsc.1120.0442," Airport congestion is a major cause for the large delays that currently affect the air transport industry. These delays have huge cost implications—for the U.S. economy these costs were estimated at $32.9 billion in 2007. In this paper, we present a mixed-integer linear optimization model aimed at assisting airlines in the making of integrated flight scheduling and fleet assignment decisions that take aircraft and passenger delay costs explicitly into account. The objective of the model is to maximize the expected profits of an airline that faces a given origin/destination-based travel demand and operates in congested, slot-constrained airports. Both airline competition and airline cooperation are dealt with in the model, though in a simplified manner. The model was applied to a case study involving the main network of TAP Portugal, which comprises 31 airports and 100 daily flight legs. The results obtained through the model suggest that the Portuguese legacy carrier can improve their expected profits significantly, while diminishing the total number of flights and slightly increasing the passengers' average connecting time. The calculation effort involved in the application of the model even on a desktop computer is small enough to allow its real-time utilization in International Air Transport Association scheduling conferences. These findings clearly indicate that the model is a significant addition to the airline planning toolbox."
/doi/10.1287/mksc.2018.1090," We examine the effect of managerial response on consumer voice in a dynamic quality environment. We argue that the consumer is motivated to write reviews not only because reviews may impact other consumers, but because reviews may impact the management and the quality of the service. We examine this empirically in a scenario in which reviewers receive a credible signal that the service provider is listening. Specifically, we examine the “managerial response” feature allowed by many review platforms. We hypothesize that managerial responses will stimulate reviewing activity and, in particular, will stimulate negative reviews that are seen as more impactful. This effect is further heightened because managers respond more and in more detail to negative reviews. Using a multiple-differences specification, we show that reviewing activity and particularly negative reviewing is indeed stimulated by managerial response. Our specification exploits comparison of the same hotel immediately before and after response initiation and compares a given hotel’s reviewing activity on sites with review response initiation to that on sites that do not allow managerial response. We also explore the mechanism behind the effect using an online experiment. Data and the online appendix are available at https://doi.org/10.1287/mksc.2018.1090 ."
/doi/10.1287/mnsc.2019.3284," Time-series data—measurements of a quantity over time—can be presented as stocks (the quantity at each point in time) or flows (the change in quantity from one point in time to the next). In a series of six experiments, we find that the choice of presenting data as stocks or flows can have a consequential impact on judgments. The same data can lead to positive or negative assessments when presented as stocks versus flows and can engender optimistic or pessimistic forecasts for the future. For example, when employment data from 2007 to 2013 are shown as flows (jobs created or lost), President Obama’s impact on the economy during his first year in office is viewed positively, whereas when the same data are shown as stocks (total jobs), his impact is viewed negatively. The results highlight a challenge that accompanies the growing reliance on data and analytics for decision making within organizations: seemingly benign choices—such as that between two informationally equivalent data presentations—can substantively impact how data are interpreted and used, even though the underlying information is the same. This paper was accepted by Yuval Rottenstreich, decision analysis."
/doi/10.1287/orsc.2021.1447," We hypothesize that employee mobility between organizations will be lower when the organizations’ managers share affiliation ties. We test this idea by examining interorganizational employee mobility between large corporate law practices. We find that a practice area is less likely to hire attorneys from a rival practice area when the leaders of the two practice areas attended the same law school at the same time, our proxy for the presence of an affiliation tie. The negative relationship is stronger for hiring higher-ranked attorneys, and it is driven by practice leaders from the same law school class. Exploiting appointments of new practice leaders, we find a sharp and immediate decline in interorganizational mobility following an appointment that creates an affiliation tie between the leadership of the practice areas. Although we cannot rule out the possibility that job seekers’ preferences drive the results, we conclude that rival managers’ ties deserve further scrutiny because they might limit the outside employment opportunities of their subordinates."
/doi/10.1287/orsc.8.5.489," During the heady revolutionary days of the 1960s, Slater and Bennis (Slater, P. E., W. G. Bennis. 1964. Democracy is inevitable. Harvard Bus. Rev. 42 (2) 51–59.) declared the inevitability of democracy at the workplace. Twenty-five years later, in a retrospection of that article, the authors claimed that they were right (Slater and Bennis [Slater, P. E., W. G. Bennis. 1990. Democracy is inevitable. Harvard Bus. Rev. 68 (5) 167–176.]). Unfortunately, the data do not support their claim (Lawler et al. [Lawler, E. E., S. A. Mohrman, G. E. Ledford. 1992. Employee Involvement and Total Quality Management . Jossey-Bass Publishers, San Francisco.]). Nonetheless, workplace democracy is inevitable. This article argues in favor of the inevitability of participatory management, one form of workplace democracy, on the basis of its coherence to the social philosophical assumptions about human nature that underlie the forms of political arrangements (democracy) and economic arrangements (mixed economy) in the United States. These communitarian philosophical assumptions have been thoroughly argued in the political science and economic literature to be ethically superior to other sets of social philosophical assumptions that underlie authoritarianism and libertarianism. Currently, organization theory is approximately 200 years behind this literature. Persons who experience significant benefits as a result of the central position of “liberty” in the social philosophical assumptions of democracy and capitalism tend to design organizational systems that significantly restrict the liberty of their employees. The current push for more democratic features is coming from organization theorists doing work on corporate culture, total quality management, gainsharing, and other systems of management that encourage decentralization, and from business ethics scholars doing work on the societal accountability of organizations. The very slow rate of evolution to workplace democracy is primarily attributed to the central role of the power elite. Whereas the American political and economic revolutionaries came from within the power elite of their times that is not yet the case for workplace democracy advocates."
/doi/10.1287/opre.2021.2148," Managerial optimization challenges in service industries often entail the need to ensure customer satisfaction. For example, in airplane boarding, the boarding time should be minimized, but to ensure customer satisfaction, the process must not be too stressful for passengers. However, many authors assume that total boarding time minimization and customer satisfaction are complementary goals, even though there is little empirical knowledge on the topic. We challenge this assumption and contend that the discomfort perceived by an individual primarily depends on their personal boarding time, that is, the time spent waiting to be seated, and only somewhat on the total boarding time of all passengers. It is known that letting slow passengers (e.g., passengers with overhead bin luggage) enter the plane first reduces the total boarding time. However, in the theory section of our paper, we show that the average individual boarding time is minimized by applying the contrary procedure, that is, having slow passengers enter last. This policy modestly increases total boarding time but greatly reduces average individual boarding time. Moreover, we propose a new boarding policy that offers the best of both worlds. Thus, if it is true that passengers care greatly about their individual boarding times, then airlines should rethink their policies. To evaluate this and other hypotheses, we conduct an international survey on air passenger preferences with 1,500 participants equally drawn from Germany, Israel, and the United States. In addition to providing some interesting results on flight preferences in general, the research confirms our hypothesis on individual boarding time."
/doi/10.1287/mnsc.2019.3292," We study relationships between parties who have different preferences about how to tailor decisions to changing circumstances. Our model suggests that relational contracts supported by formal contracts may achieve relational adaptation that improves on adaptation decisions achieved by formal or relational contracts alone. Our empirics consider revenue-sharing contracts between movie distributors and an exhibitor. The exhibitor has discretion about whether and when to show a movie, and the parties frequently renegotiate formal contracts after a movie has finished its run. We document that such ex post renegotiation is consistent with the distributor rewarding the exhibitor for adaptation decisions that improve their joint payoffs. This paper was accepted by Joshua Gans, business strategy."
/doi/10.1287/mnsc.2020.3702," We show that, following shocks that change an industry’s competitive environment, firms with more short-term institutional investors experience smaller drops in sales and investment and have better long-term performance than similar firms affected by the shocks. To do so, these firms introduce new products, file more trademarks, intensify their innovation efforts, conduct more diversifying acquisitions, and have higher executive turnover in the aftermath of the shocks. Our findings suggest that firms with more short-term investors adapt better to the new competitive environment. Endogeneity of institutional ownership and other selection problems do not appear to drive our findings. This paper was accepted by Gustavo Manso, finance."
/doi/10.1287/msom.1070.0166," Classical inventory models offer a variety of insights into the optimal way to manage inventories of individual products. However, top managers and industry analysts are often concerned with the aggregate macroscopic view of a firm's inventory rather than with the inventories of individual products. Given that classical inventory models often do not account for many practical considerations that a company's management faces (e.g., competition, industry dynamics, business cycles, the financial state of the company and of the economy, etc.) and that they are derived at the product level and not the firm level, can insights from these models be used to explain the inventory dynamics of entire companies? This exploratory study aims to address this issue using empirical data. We analyze absolute and relative inventories using a quarterly data panel that contains 722 public U.S. companies for the period 1992–2002. We have chosen companies that are not widely diversified and whose business in large part relies on inventory management to concentrate on empirically testing hypotheses derived from a variety of classical inventory models (economic order quantity (EOQ), [ Q , r ], newsvendor, periodic review, etc.). We find empirical evidence that firms operating with more uncertain demand, longer lead times, and higher gross margins have larger inventories. Furthermore, larger companies appear to benefit from economies of scale and therefore have relatively less inventory than smaller companies. We obtain mixed evidence on the relationship between inventory levels and inventory holding costs. We also analyze the breakdown of data into eight segments—oil and gas, electronics, wholesale, retail, machinery, hardware, food, and chemicals—and find that, with a few notable exceptions, our hypotheses are supported within the segments as well. Overall, our results demonstrate that many of the predictions from classical inventory models extend beyond individual products to the aggregate firm level; hence, these models can help with high-level strategic choices in addition to tactical decisions."
/doi/10.1287/mnsc.2020.3579," Product price risk is a potentially important factor for firms’ liquidity management. A natural place to evaluate the impact of this risk on liquidity management is the electricity industry, because producing firms face substantial price volatility in wholesale markets. Empirically, higher volatility of electricity prices leads to an increase in cash holdings, and this effect is robust to instrumenting for price risk using weather volatility. Cash increases more with price risk in firms using inflexible production technologies and those that cannot easily hedge electricity prices, indicating that operating flexibility and hedging are substitutes for liquidity management. This paper was accepted by Karl Diether, finance."
/doi/10.1287/stsc.2021.0137," We examine how mission-oriented grand challenges—formed to address the public sector’s unmet needs through development of new technologies and products for high potential impact—originate and catalyze industry incubation. Our analysis of six prominent cases identifies the incubation process, consisting of identification of unmet needs as a grand challenge, championing and articulation of a mission, leverage of private enterprise, and success or failure of the mission for subsequent industry emergence. The resulting conceptual model highlights key similarities and differences of industry incubation stemming from the public sector’s mission-oriented grand challenges relative to industries triggered by scientific discoveries or unmet user needs where the public sector is not as salient. The analysis reveals successful outcomes are associated with the public sector’s goal setting and carrying out “market functions” pertaining to selection, coordination, and knowledge sharing. We also provide cautions and caveats regarding fault lines that may arise in public-private partnerships."
/doi/10.1287/mnsc.2021.4097," We investigate the optimal portfolio choice problem for an investor who has a utility function of the smooth ambiguity model. We identify necessary and sufficient conditions for a given portfolio to be optimal for such an investor. We define the implied ambiguity of a portfolio as the smallest ambiguity aversion coefficient with which the portfolio is optimal, and the measure of ambiguity perception as the part of the variability in asset returns that can be attributed to the ambiguity. We show that there are one-to-one relations between the implied ambiguity, the Sharpe ratio, and the pricing errors when the portfolio is taken as the pricing portfolio, and that the measure of ambiguity perception is determined by the Sharpe ratio and the alpha. Based on the U.S. stock market data, we assess how ambiguity averse the representative investor is and what types of stocks the investor perceives as having more ambiguous returns than others. This paper was accepted by Manel Baucells, behavioral economics and decision analysis."
/doi/10.1287/mnsc.2016.2558," We develop a rational expectations model in which an issuer purchases credit ratings sequentially, deciding which to disclose to investors. Opacity about contacts between the issuer and rating agencies induces potential asymmetric information about which ratings the issuer obtained. While the equilibrium forces disclosure of ratings when the market knows these have been generated, endogenous uncertainty about whether there are undisclosed ratings can arise and lead to selective disclosure and rating bias. Although investors account for this bias in pricing, selective disclosure makes ratings noisier signals of project value, leading to inefficient investment decisions. Our paper suggests that regulatory disclosure requirements are welfare enhancing. This paper was accepted by Gustavo Manso, finance ."
/doi/10.1287/orsc.1120.0812," I develop the thesis that in related diversified firms, the core business (in my analysis, the largest business) may provide benefits such as scope economies to a related segment, but it may also exert power and constrain the segment to act in its interests in various internal and external transactions. This enables the core business to shift productivity gains toward itself from the segment, which could lead to various inefficiencies within the related diversified firm. Using input/output flow data and a multilevel model with the segment as the unit of analysis, I first show that a segment’s productivity is lower compared with a single-business firm when it shares backward and forward complementarity (i.e., when it shares transactions with common suppliers and customers) with the core business. Correspondingly, I show that as a mirror image, the core business’s productivity is enhanced when the business shares backward and forward complementarity with segments and when segments are backward integrated with it (i.e., when the core business provides outputs to segments). These shifts in productivity and the attendant inefficiencies do not seem to be destroying the entire value from related diversification. Overall, the findings support the argument that the power and influence exerted by the core business—and concomitantly, the subsidization of the core business by related segments—is an important source of costs borne by segments in a related diversified firm."
/doi/10.1287/mnsc.2013.1773," This paper studies how industry peers respond when another firm in the industry is the subject of a hostile takeover attempt. The industry peers cut their capital spending, free cash flows, and cash holdings, and increase their leverage and payouts to shareholders. They also adopt more takeover defenses. The stock price reaction upon announcement of the takeover is positive and larger for peer firms with higher capital spending and higher free cash flows. Before the takeover attempt, the peer firms borrow less and invest more than predicted. Both stock returns and performance improve after the takeover attempt. These results are consistent with the argument that the control threat has important spillover effects for the other firms in the industry. This paper was accepted by Wei Xiong, finance."
/doi/10.1287/mnsc.40.8.984," We develop a model of network growth in the presence of network externalities for the case where a buyer initiates an interorganizational system with its suppliers. In our two-stage model, suppliers joining the network in the first stage can gain economic benefit from increased market share or higher price for the primary product. Suppliers encounter negative externalities since the economic benefit accruing to participating suppliers is less for increasingly larger networks. In the first stage, the buyer may experience initial supplier adoption of the network followed by a “stalling” problem due to negative externalities. In order to overcome this stalling problem, the buyer may find it optimal to subsidize some suppliers' costs to join the network in the second stage. We characterize the buyer's optimal second stage subsidy policy and show the conditions under which the buyer will find it optimal to offer a subsidy. If the suppliers have some positive ex ante expectation of a second stage subsidy, the growth of the network will be retarded in the first stage resulting in suboptimal profits for the buyer."
/doi/10.1287/orsc.1100.0623," Research in strategy has identified and tried to explain four types of rents: monopolistic rents, efficiency rents, quasi rents, and Schumpeterian rents. Building on previous work on political and institutional strategies, we add a fifth type of rent: influence rents. Influence rents are the extra profits earned by a firm because the rules of the game (laws, regulations, and informal rules) are designed or changed to suit it. To aid the analysis of the relationship between institutional context and firm performance and to provide a structure to guide research, we develop a framework with five key components: (a) an identification of the five fundamental problems of a market economy, (b) a typology that describes the five different types of institutions that emerge to solve these problems, (c) the market-ordering mechanisms used by institutions to solve these problems, (d) the common causes of weak institutional performance, and (e) generic strategies used by firms to exploit these weaknesses of an institutional context to enhance firm performance. We highlight potential applications of the framework as well as an illustrative research agenda that can advance the development of theory to explain the emergence and persistence of influence rents."
/doi/10.1287/opre.2020.2068," Sales and operations planning processes are used to align production quantities and customer demand. Two key activities of these processes are demand planning and production planning, which are often assigned to individuals in different departments. Production planning requires accurate demand forecasts from demand planning to be able to choose proper production quantities, but demand planners have to invest effort to create accurate demand forecasts. We study the role of social preferences (altruism, inequality aversion, and competitive pressure) in incentivizing demand planners to invest effort, and we analyze how social preferences interact with monetary incentives. We use a game-theoretic model and laboratory experiments. Our results indicate that social preferences can be used to incentivize demand planners to invest effort and that this effect is anticipated by production planners. The resulting more accurate demand forecasts and adapted production quantities result in higher company profit. We also provide an optimization model for optimally allocating investments to financial incentives and social preference building."
/doi/10.1287/mnsc.2021.3961," This paper contributes to the literature on decision making under multiple probability models by studying a class of variational preferences. These preferences are defined in terms of Fréchet mean utility functionals, which are based on the Wasserstein metric in the space of probability models. In order to produce a measure that is the “closest” to all probability models in the given set, we find the barycenter of the set. We derive explicit expressions for the Fréchet–Wasserstein mean utility functionals and show that they can be expressed in terms of an expansion that provides a tractable link between risk aversion and ambiguity aversion. The proposed utility functionals are illustrated in terms of two applications. The first application allows us to define the social discount rate under model uncertainty. In the second application, the functionals are used in risk securitization. The barycenter in this case can be interpreted as the model that maximizes the probability that different decision makers will agree on, which could be useful for designing and pricing a catastrophe bond. This paper was accepted by Manel Baucells, decision analysis."
/doi/10.1287/inte.2020.1044," Improving airport collaborative decision making is at the heart of airport operations centers (APOCs) recently established in several major European airports. In this paper, we describe a project commissioned by Eurocontrol, the organization in charge of the safety and seamless flow of European air traffic. The project’s goal was to examine the opportunities offered by the colocation and real-time data sharing in the APOC at London’s Heathrow airport, arguably the most advanced of its type in Europe. We developed and implemented a pilot study of a real-time data-sharing and collaborative decision-making process, selected to improve the efficiency of Heathrow’s operations. In this paper, we describe the process of how we chose the subject of the pilot, namely the improvement of transfer-passenger flows through the airport, and how we helped Heathrow move from its existing legacy system for managing passenger flows to an advanced machine learning–based approach using real-time inputs. The system, which is now in operation at Heathrow, can predict which passengers are likely to miss their connecting flights, reducing the likelihood that departures will incur delays while waiting for delayed passengers. This can be done by off-loading passengers in advance, by expediting passengers through the airport, or by modifying the departure times of aircraft in advance. By aggregating estimated passenger arrival time at various points throughout the airport, the system also improves passenger experiences at the immigration and security desks by enabling modifications to staffing levels in advance of expected surges in arrivals. The nine-stage framework we present here can support the development and implementation of other real-time, data-driven systems. To the best of our knowledge, the proposed system is the first to use machine learning to model passenger flows in an airport."
/doi/10.1287/isre.2020.0921," The mobile applications (apps) market is one of the most successful software markets. As the platform grows rapidly, with millions of apps and billions of users, search costs are increasing tremendously. The challenge is how app developers can target the right users with their apps and how consumers can find the apps that fit their needs. Cross-promotion, advertising a mobile app (target app) in another app (source app), is introduced as a new app-promotion framework to alleviate the issue of search costs. In this paper, we model source app user behaviors (downloads and postdownload usages) with respect to different target apps in cross-promotion campaigns. We construct a novel app similarity measure using latent Dirichlet allocation topic modeling on apps’ production descriptions and then analyze how the similarity between the source and target apps influences users’ app download and usage decisions. To estimate the model, we use a unique data set from a large-scale random matching experiment conducted by a major mobile advertising company in Korea. The empirical results show that consumers prefer more diversified apps when they are making download decisions compared with their usage decisions, which is supported by the psychology literature on people’s variety-seeking behavior. Lastly, we propose an app-matching system based on machine-learning models (on app download and usage prediction) and generalized deferred acceptance algorithms. The simulation results show that app analytics capability is essential in building accurate prediction models and in increasing ad effectiveness of cross-promotion campaigns and that, at the expense of privacy, individual user data can further improve the matching performance. This paper has implications on the trade-off between utility and privacy in the growing mobile economy."
/doi/10.1287/isre.2021.0993," The prevalence of consumers sharing their purchases on social media platforms (e.g., Instagram and Pinterest) and the use of this information by potential future consumers have substantial implications for online retailing. In this study, we examine how product characteristics and the type of information provider jointly impact purchase decisions in a social network setting. We first propose an analytical observational learning framework integrating the impact of product differentiation and social ties. Then, we use two experimental studies to validate our analytical results and provide additional insights. Our key findings are that the effect of learning from strangers is stronger for vertically differentiated products than for horizontally differentiated products. However, the effect of learning from friends does not depend on whether the underlying product is horizontally or vertically differentiated. What is more interesting is the nuanced role of social ties: For horizontally differentiated products, the effect of learning increases with the strength of social ties. In addition, contact-based tie strength is more important than structure-based tie strength in accelerating observational learning. These findings provide motivation for online retailers to generate alternative strategies for increasing product sales through social networks. For example, online retailers offering horizontally differentiated products have strong incentives to cooperate with social media platforms (e.g., Instagram and Pinterest) in encouraging customers to share their purchase information."
/doi/10.1287/isre.1100.0302," Using agent-based simulation experiments, we investigate the outcome of SAs between two smaller online search engine companies in competition with a dominant market leader in settings where an advertiser's decision making is the consequence of a combination of NI (e.g., an individual's willingness to follow others' decisions) and IP. In particular, we focus on a context in which the combined search engine company competes with a market leader holding a larger share of the market than the two runner-up “underdogs” combined. Our results indicate that, with the presence of NI and cascading effects, an alliance with “only” 35%–40% combined market share could compete with a leader whose market share, at the time of an alliance, is 60%–65%. Although important, size alone might be insufficient to build the market as suggested by the “vanilla” network effect theory. Another noteworthy finding is that a nonlinear association exists between NI and an alliance outcome; the combined runner-up companies have the best chance of success when the extent of NI is midrange, rather than on the high or low end of continuum. Contrary to the conventional view, this finding might also stimulate discussions among network science researchers. Furthermore, our results suggest that NI substantially moderates the relationship between the combined market share at the time of an alliance and the likelihood of resulting alliance success."
/doi/10.1287/orsc.1050.0168," Organization design in its verb form is explored through a study of the design practices of a major contemporary architect, Frank O. Gehry, and his firm, Gehry Partners, LLP. Through four case studies, we explore how the organization design of his architectural projects is an outcome of Gehry Partner’s design gestalt. We argue that this design gestalt is a primary source of their organization designing and is composed of an architectural vision, the tight coupling of multiple representation technologies, and a commitment to a collaborative process of design and construction. These elements of design together form a holistic, organizing pattern—their design gestalt—that is evident in all of Gehry Partners projects, both their buildings and their organizational forms. We offer three characteristics of organization designing—focus on form giving, relation to environment, and temporality. We argue that developing a design gestalt and strengthening the capacity for organization designing is crucial for firms in our increasingly knowledge- and experience-based economy."
/doi/10.1287/mksc.1120.0724," Firms that sell via a direct channel and via indirect channels have to decide whether to allow third-party sellers to use trademarked brand names of products in their advertising. This question has been particularly controversial for advertising on search engines. In June 2009, Google started allowing any third-party reseller of a product to use a trademark such as “DoubleTree” in the text of its ad, even if the reseller did not have the trademark holder's permission. We study the effects of this change empirically within the hotel industry. We find some evidence that allowing third-party sellers to use a trademark in their online search advertising weakly reduced the likelihood of a consumer clicking on a trademark holder's paid search ads. However, the decrease in paid clicks was outweighed by a large increase in consumers clicking on the unpaid links to the hotelier's website within the main search results. Our evidence shows that when a third-party seller focuses on a trademarked brand in its ads, the ads become less distinct, and customers are more likely to ignore the advertised offers and buy from the direct channel."
/doi/10.1287/mnsc.2020.3617," In the recent Basel Accords, the expected shortfall (ES) replaces the value-at-risk (VaR) as the standard risk measure for market risk in the banking sector, making it the most popular risk measure in financial regulation. Although ES is—in addition to many other nice properties—a coherent risk measure, it does not yet have an axiomatic foundation. In this paper, we put forward four intuitive economic axioms for portfolio risk assessment—monotonicity, law invariance, prudence, and no reward for concentration—that uniquely characterize the family of ES. Therefore, the results developed herein provide the first economic foundation for using ES as a globally dominating regulatory risk measure, currently employed in Basel III/IV. Key to the main results, several novel notions such as tail events and risk concentration naturally arise, and we explore them in detail. As a most important feature, ES rewards portfolio diversification and penalizes risk concentration in a special and intuitive way, not shared by any other risk measure. This paper was accepted by Manel Baucells, decision analysis."
/doi/10.1287/mnsc.15.1.57," This paper examines the hypothesis that “outliers” observed in empirical frequency distributions of share price relatives can be anticipated and explained via the theory of financial analysis. Specifically, price is treated as a ratio estimate. Each term in the estimate is subject to error, and both numerator and denominator of the ratio are considered to be normally distributed. Then deviations from the ideal Gaussian form for the empirical frequency distributions of change in price are explained in terms of fundamental economic variables that interact to determine numerical values for the numerator and denominator of the ratio."
/doi/10.1287/opre.1060.0297," The multiple-family economic lot scheduling problem with safety stocks (MFELSP-SS) with normally distributed, time-stationary demand is considered in a manufacturing setting where the relevant costs include family setup costs, item setup costs, and inventory holding costs for both cycle and safety stocks. A family is a subset of the items that share a common family setup with its associated setup cost and setup time. Each item within the family may have its own setup time and setup cost. The families form a partition of the set of items manufactured on a single facility. The safety stock level for any item is a function of the time interval between production runs for the item, the service level specified, and the variance of its demand. We consider safety stocks explicitly in the formulation, as their holding costs vary nontrivially with the model’s decision variables. The MFELSP-SS differs from multilevel inventory models with family setups in that the former assumes noninstantaneous inventory replenishment and considers the cost of holding safety stocks; the latter assumes instantaneous replenishment and does not directly assess the impact of safety stock levels on the total cost. An efficient solution procedure is developed for this model. Properties of the nonconvex feasible space are identified and used in the solution approach. The solution to the mathematical model comprises the basic period length, the family multipliers, and the item multipliers that give the lowest total cost of setups and carrying inventory. The family multipliers and item multipliers are restricted to integer powers of two."
/doi/10.1287/mnsc.47.7.894.9807," The erosion of service quality throughout the economy is a frequent concern in the popular press. The American Customer Satisfaction Index for services fell in 2000 to 69.4%, down 5 percentage points from 1994. We hypothesize that the characteristics of services—inseparability, intangibility, and labor intensity—interact with management practices to bias service providers toward reducing the level of service they deliver, often locking entire industries into a vicious cycle of eroding service standards. To explore this proposition we develop a formal model that integrates the structural elements of service delivery. We use econometric estimation, interviews, observations, and archival data to calibrate the model for a consumer-lending service center in a major bank in the United Kingdom. We find that temporary imbalances between service capacity and demand interact with decision rules for effort allocation, capacity management, overtime, and quality aspirations to yield permanent erosion of the service standards and loss of revenue. We explore policies to improve performance and implications for organizational design in the service sector."
/doi/10.1287/orsc.1110.0695," An extensive body of knowledge exists on network outcomes and on how network structures may contribute to the creation of outcomes at different levels of analysis, but less attention has been paid to understanding how and why organizational networks emerge, evolve, and change. Improved understanding of network dynamics is important for several reasons, perhaps the most critical being that the understanding of network outcomes is only partial without an appreciation of the genesis of the network structures that resulted in such outcomes. To provide a context for the papers in this special issue, and with the broader goal of furthering network dynamics research, we present a framework that begins by discussing the meaning and role of network dynamics and goes on to identify the drivers and key dimensions of network change as well as the role of time in this process. We conclude with theoretical and methodological issues that researchers need to address in this domain."
/doi/10.1287/opre.40.2.384," We consider inventory systems with several distinct items. Demands occur at constant, item specific rates. The items are interdependent because of jointly incurred fixed procurement costs: The joint cost structure reflects general economies of scale, merely assuming a monotonicity and concavity (submodularity) property. Under a power-of-two policy each item is replenished with constant reorder intervals which are power-of-two multiples of some fixed or variable base planning period. Our main results include a proof that, depending upon whether the base planning period is fixed or variable, the best among all power-of-two policies has an average cost which comes within either 6% or 2% of an easily computable lower bound for the minimum cost value . We also derive two efficient algorithms to compute an optimal power-of-two policy. The proposed algorithms generate as a by-product, a specific cost allocation of the joint cost structure to the individual items. With this specific allocation, the problem with separable costs is in fact equivalent to the original problem with nonseparable joint costs in the sense that the two problems share the same sets of optimal power-of-two policies with identical associated long-run average costs."
/doi/10.1287/msom.1120.0420," Suppliers are increasingly being asked to share information about their vulnerability to climate change and their strategies to reduce greenhouse gas emissions. Their responses vary widely. We theorize and empirically identify several factors associated with suppliers being especially willing to share this information with buyers, focusing on attributes of the buyers seeking this information and of the suppliers being asked to provide it. We test our hypotheses using data from the Carbon Disclosure Project's Supply Chain Program, a collaboration of multinational corporations requesting such information from thousands of suppliers in 49 countries. We find evidence that suppliers are more likely to share this information when requests from buyers are more prevalent, when buyers appear committed to using the information, when suppliers belong to more profitable industries, and when suppliers are located in countries with greenhouse gas regulations. We find evidence that these factors also influence the comprehensiveness of the information suppliers share and their willingness to share the information publicly."
/doi/10.1287/orsc.12.6.683.10086," The keiretsu structuring of assembler-supplier relations historically enabled Japanese auto assemblers to remain lean and flexible while enjoying a level of control over supply akin to that of vertical integration. Yet currently there is much talk of breakdowns in keiretsu networks. This paper examines some recent developments in Japanese parts-supply keiretsu . We argue that keiretsu relationships are drifting from “hybrid” or “network” (i.e., keiretsu ) governance modes toward the extremes of arms-length contracting and top-down administration. These changes are best understood through a combination of transaction cost and learning perspectives on alliance. Consistent with transaction-cost economics, the shift in purchase-supply relationships can be traced to changes in the nature of parts transactions and keiretsu -governance structures. A learning perspective on alliance complements and extends transaction-cost theory, providing additional explanation of the sources of change and the specific governance choices being made. Our first two cases document a drift in Toyota's keiretsu supply network toward a hierarchical form in the management of parts-supply transactions. Toyota has effectively internalized its transactions with Daihatsu by taking a controlling interest. Toyota's strategy toward long-term partner Denso, on the other hand, was very different. Toyota built, from the ground up, an in-house capability in electronic components, thus scaling down its dependence on Denso. A third case considers a general trend in the Japanese auto industry toward greater standardization of parts. With the routinization of quality, reliability, and speed in supply management, the need for keiretsu -style governance has declined. The withering of keiretsu obligations is also traceable to globalization and the continuing weakness of the Japanese economy, which have prompted Japanese firms to question received business practice."
/doi/10.1287/ijoc.2020.1005," Learning the customers’ experience and behavior creates competitive advantages for any company over its rivals. The insurance industry is an essential sector in any developed economy and a better understanding of customers’ risk profile is critical to decision making in all aspects of insurance operations. In this paper, we explore the idea of using copula-based dependence models to learn the hidden risk of policyholders in property insurance. Specifically, we build a novel copula model to accommodate the dependence over time and over space among spatially clustered property risks. To tackle the computational challenge caused by the discreteness feature of large-scale insurance data, we propose an efficient multilevel composite likelihood approach for parameter estimation. Provided that latent risk induces correlation, the proposed customer learning method offers improved predictive analytics by allowing insurers to borrow strength from related risks in predicting new risks and also helps reveal the relative importance of the multiple sources of unobserved heterogeneity in updating policyholders’ risk profile. In the empirical study, we examine the loss cost of a portfolio of entities insured by a government property insurance program in Wisconsin. We find both significant temporal and spatial association among property risks. However, their effects on the predictive distribution of loss cost are different for the new and renewal policyholders. The two sources of dependence are complements for the former and substitutes for the latter. These findings are shown to have substantial managerial implications in key insurance operations such as experience rating, capital allocation, and reinsurance arrangement."
/doi/10.1287/ited.1120.0100," A robust graduate engineering education experience requires students to learn the fundamental subject knowledge, to develop their ability to apply what they know to actual projects, and to contribute to the current body of knowledge by writing theses or dissertations. At the University of Tennessee, Knoxville, Industrial and Systems Engineering students have an opportunity, in the Student Projects with Industry (SPI) program within the Center for Productivity Innovation, to develop their research ideas in conjunction with industry. The success of the SPI program is assessed by evaluating the impact of the SPI program on the preparation of the students, the academic welfare of the department, and the program's economic and social impact on the community. The SPI program provides students with simulated work experiences that enhance their leadership attributes, developing students' critical thinking capabilities, and improving their technical, organizational, and social skills. That these skills enhance students' success both in the university and in their careers is evident in measurable results, including higher student graduation rates, an increased number of publications, and a wider sponsor network for potential funding. The impact can further be measured by the millions of dollars affecting the local economy, in addition to the intangible social benefits gained."
/doi/10.1287/orsc.2014.0903," Asalient but rarely explicitly studied characteristic of interfirm relationships is that they can intentionally be formed for finite periods of time. What determines firms’ intertemporal choices between different alliance time horizons? Shadow of the future theorists suggest that when an alliance has an explicitly set short-term time frame, there is an increased risk that partners may behave opportunistically. This does not readily explain the high incidence of time-bound alliances being formed. Reconciling insights from the shadow of the future perspective with nascent research on the flexibility of temporary organizations, and shifting the focus from the level of individual transactions to that of strategic alliance portfolios, we argue that firms may be willing to accept a higher risk of opportunism when there are offsetting gains in strategic flexibility in managing their strategic alliance portfolio. Consequently, we hypothesize that environmental factors that increase the need for strategic flexibility—namely, dynamism and complexity in the environment—are likely to increase the relative share of time-bound alliances in strategic alliance portfolios. Our analysis of longitudinal data on the intertemporal alliance choices of a large sample of small and medium-sized enterprises provides support for this argument. Our findings fill an important gap in theory about time horizons in interfirm relationships and temporary organizations and show the importance of separating planned terminations from duration-based performance measures."
/doi/10.1287/mnsc.2016.2693," We analyze the words that firms use to describe their products so we can examine the determinants of which industries conglomerate firms operate within. Our central finding is that multiple-industry firms operate across industries with higher product language overlap. Multiple-industry firms also avoid industries with more distinct language boundaries and those with more specialized within-industry language. We also find evidence linking these results to specific synergies such as potential entry into new markets and realized synergies in the form of higher 10-K product description growth. These findings are consistent with multiple-product firms operating primarily in industries that lack language specialization. Our findings show that most conglomerates are not true diversified conglomerates with little overlap in their lines of business, as most firms that operate across multiple industries choose industries with high language overlap and potential synergies. Our results support theories of firm organization and organizational language. The online appendix is available at https://doi.org/10.1287/mnsc.2016.2693 . This paper was accepted by Amit Seru, finance."
/doi/10.1287/mksc.2013.0836," The nature of marketing science is changing in a systematic, predictable, and irrevocable way. As information technology enables ubiquitous customer communication and big customer data, the fundamental nature of the firm's connection to the customer changes: better, more personalized service can be offered, from which service relationships are deepened, and consequently, more profitable customers grow the influence of service within the goods sector and expand the service sector in the economy. Marketing is becoming more personalized, and marketing science techniques that exploit customer heterogeneity are becoming more important. Information technology improvements also guarantee the increasing importance and usage of computationally intensive data processing and “big data.” Most importantly, these trends have already lasted for more than a century, and they will become even more pronounced in the coming years as a result of the monotonic nature of technology improvement. These changes imply a transformation of marketing science in both the topics to be emphasized and the methods to be employed. Increasingly, and inevitably, all of marketing will come to resemble to a greater degree the formerly specialized area of service marketing, only with an increased emphasis on marketing analytics."
/doi/10.1287/mnsc.2021.4059," I study the effects of language commonality (i.e., sharing a native language) on information production in financial markets. Using a hand-collected data set on the prevalent dialects for 2,091 cities (counties) in China, I identify the effects of language commonality separately from those of shared hometown and geographic proximity. In in-sample tests, language commonality between analysts and CEOs increases the return of trading on analysts’ recommendations by 5.5%. The results mainly stem from less intelligible dialects. Broadly speaking, language commonality can alleviate communication frictions when nonnative languages are used in professional settings. This paper was accepted by Gustavo Manso, finance."
/doi/10.1287/mnsc.2021.4141," We study how innovative firms manage their innovation portfolios after filing for Chapter 11 reorganization using three decades of data. We find that they sell off core (i.e., technologically critical and valuable), rather than peripheral, patents in bankruptcy. The selling pattern is driven almost entirely by firms with greater use of secured debt, and the mechanism is secured creditors exercising their control rights on collateralized patents. Creditor-driven patent sales in bankruptcy have implications for technology diffusion—the sold patents diffuse more slowly under new ownership and are more likely to be purchased by patent trolls. This paper was accepted by Gustavo Manso, finance."
/doi/10.1287/mnsc.1040.0356," A well-studied problem in the literature on airline revenue (or yield) management is the optimal allocation of seat inventory among fare classes, given a demand distribution for each class. In practice, the seat allocation decisions of one airline affect the passenger demands for seats on other airlines. In this paper, we examine the seat inventory control problem under both horizontal competition (two airlines compete for passengers on the same flight leg) and vertical competition (different airlines fly different legs on a multileg itinerary). Such vertical competition can be the outcome of a code-sharing agreement between airlines, because each airline sells seats on the partner airlines’ flights but the airlines are unwilling, or unable, to coordinate yield management decisions. We provide a general sufficient condition under which a pure-strategy Nash equilibrium exists in these revenue management games, and we also compare the total number of seats available in each fare class with, and without, competition. Analytical results as well as numerical examples demonstrate that more seats are protected for higher-fare passengers under horizontal competition than when a single airline acts as a monopoly. Under vertical competition the booking limit may be higher or lower, however, than the monopoly level, depending on the demand for connecting flights in each fare class. Finally, we discuss revenue-sharing contracts that coordinate the actions of both airlines."
/doi/10.1287/mnsc.2017.2770," Two competing principal–agent models explain why firms pay dividends. The substitute model proposes that corporate insiders pay dividends to signal and build trust with outside shareholders who lack legal protection. The outcome model, in contrast, surmises that when shareholders have legal protection, they demand dividends from insiders to prevent them from expropriating corporate funds. Either way, dividends represent an agency cost paid to align the interests of shareholders and insiders. Expropriations by insiders and reduced investment by shareholders are also agency costs, but they are difficult to identify with archival data. Using a laboratory experiment, we identify the impact of strengthened shareholder protection on all three types of agency costs. Dividend payout ratios are five times larger with stronger investor protection, insider expropriation ratios are twice as high, and outsider investment falls by 45%. Thus, we find evidence that strengthening shareholder protection introduces previously unidentified agency costs into the insider–investor relationship. Data and the online appendix are available at https://doi.org/10.1287/mnsc.2017.2770 . This paper was accepted by Uri Gneezy, behavioral economics."
/doi/10.1287/moor.2017.0856," We consider an optimal risk-sensitive portfolio allocation problem accounting for the possibility of cascading defaults. Default events have an impact on the distress state of the surviving stocks in the portfolio. We study the recursive system of non-Lipschitz quasilinear parabolic HJB-PDEs associated with the value function of the control problem in the different default states of the economy. We show the existence of a classical solution to this system via super-sub solution techniques and give an explicit characterization of the optimal feedback strategy in terms of the value function. We prove a verification theorem establishing the uniqueness of the solution. A numerical analysis indicates that the investor significantly accounts for contagion effects when making investment decisions, and that his strategy depends nonmonotonically on the aggregate risk level."
/doi/10.1287/opre.1090.0704," Retailing is a huge industry. In the United States, retail business represents about 40% of the economy and is the largest employer. Retail supply chain management is still more art than science, but this is changing rapidly as retailers begin to apply analytic models to the huge volume of data they are collecting on consumer purchases and preferences. This industry-wide movement resembles the transformation of Wall Street that occurred in the 1970s when physicists and other “rocket scientists” applied their analytic skills to investment decisions. The Consortium for Operational Excellence in Retailing (COER) (codirected by Ananth Raman, Harvard Business School, and myself) is a group of academics working with about 50 leading retailers to assess their progress towards rocket science retailing and to accelerate that progress through selected research projects. After some brief comments on the current state of industry practice in retail supply chain management, this paper will describe examples of COER research in four areas: assortment planning, pricing, inventory optimization, and store execution."
/doi/10.1287/msom.2017.0668," In an industry with knowledge spillover and debt financing, equilibrium investments in research and development (R&D) projects are subject to three economic forces. First, knowledge spillover among firms enables free dissemination of new technologies and produces investment synergies. Second, knowledge spillover also causes free riding: in equilibrium, firms underinvest in R&D expecting to benefit from investments by others. Third, debt financing creates incentive for risk shifting: equity holders overinvest in riskier R&D projects. We study how interactions among these forces affect a firm’s investment decisions and equilibrium industry outcomes using a three-stage game between two firms and the external debt market. We characterize subgame perfect, Pareto-dominant equilibria and show that for some parameter choices, free riding and risk shifting cancel each other in the decisions of individual firms, resulting in the first-best investments. Interestingly, for some cases, the equilibrium with first-best investments becomes possible only when risk shifting by one firm enables free riding by the other firm. We also show that debt can be used by firms as a commitment device in a multistage game. This value of debt is shared with investors, who can earn positive profits despite being perfectly competitive. This enriches the understanding of the financial pecking order theory by showing that even firms with unlimited internal capital may prefer external debt financing. This paper has been accepted for the Manufacturing & Service Operations Management Special Issue on Interface of Finance, Operations, and Risk Management."
/doi/10.1287/mksc.1110.0669," Commercial open source software (COSS) products—privately developed software based on publicly available source code—represent a rapidly growing, multibillion-dollar market. A unique aspect of competition in the COSS market is that many open source licenses require firms to make certain enhancements public, creating an incentive for firms to free ride on the contributions of others. This practice raises a number of puzzling issues. First, why should a firm further develop a product if competitors can freely appropriate these contributions? Second, how does a market based on free riding produce high-quality products? Third, from a public policy perspective, does the mandatory sharing of enhancements raise or lower consumer surplus and industry profits? We develop a two-sided model of competition between COSS firms to address these issues. Our model consists of (1) two firms competing in a vertically differentiated market, in which product quality is a mix of public and private components, and (2) a market for developers that firms hire after observing signals of their contributions to open source. We demonstrate that free-riding behavior is supported in equilibrium, that a mandatory sharing setting can result in high-quality products, and that free riding can actually increase profits and consumer surplus."
/doi/10.1287/mnsc.2020.3721," Digital platforms provide a variety of technology-enabled tools that enhance market transparency, such as real-time monitoring, ratings of buyers and sellers, and low-cost complaint channels. How do these innovations affect moral hazard and service quality? We investigate this problem by comparing driver routing choices and efficiency on a large digital platform, Uber, with traditional taxis. The identification is enabled by matching taxi and Uber trips at the origin-destination-time level so they are subject to the same underlying optimal route, by exploiting characteristics of the pricing schemes that differentially affect the incentives of taxi and Uber drivers in various circumstances, and by examining changes in behavior when drivers switch from taxis to Uber. We find that (1) taxi drivers route longer in distance than matched Uber drivers on metered airport routes by an average of 8%, with nonlocal passengers on airport routes experiencing even longer routing; (2) no such long routing is found for short trips in dense markets (e.g., within-Manhattan trips) or airport trips with a flat fare; and (3) long routing in general leads to longer travel time, instead of saving passengers time. These findings are consistent with digital platform designs reducing driver moral hazard, but not with competing explanations such as driver selection or differences in driver navigation technologies. We also find evidence of Uber drivers’ long routing on airport trips in times of surge pricing, suggesting that the tech-enabled market designs may not be binding in our setting. This paper was accepted by Chris Forman, information systems."
/doi/10.1287/opre.1120.1146," Flight delays have been a growing issue and they have reached an all-time high in recent years, with the airlines' on-time performance at its worst level in 2007 since 1995. A recent report by the Joint Economic Committee of the U.S. Congress chaired by Senator Charles E. Schumer has estimated that the total cost to the U.S. economy because of flight delays was as much as $41 billion in 2007. The goal of this paper is to build stochastic models of airline networks and utilize publicly available data to answer the following policy questions: Which are the bottleneck airports in the U.S. air-travel infrastructure (i.e., airports that cause most delay propagation)? How would increasing airport capacity at these airports alleviate delay propagation? What are the appropriate metrics for measuring the robustness of airline schedules? How could these schedules be made more robust? Which flight in an aircraft rotation is a bottleneck flight (and, hence, deserves managerial attention)? Flight delays are typically attributed to two factors: (i) the randomness in the intrinsic travel time for a scheduled flight (which is the travel time excluding propagated delays), and (ii) the propagation of this randomness through the air-travel network and infrastructure. We model both of these factors that cause travel delays. The contribution of this paper is twofold. First, we develop stochastic models, using empirical data, to analyze the propagation of delays through air-transportation networks. Our stochastic models allow us to develop three important robustness measures for airline networks. Second, our analysis enables us to make policy recommendations regarding managing bottleneck resources in the air-travel infrastructure, which, if addressed, could lead to a significant improvement in air-travel reliability."
/doi/10.1287/opre.43.6.970," Financial intermediaries—banks, thrifts, and life insurance companies—have experienced low productivity over the last decade or two. Low productivity has manifested itself as a declining market share of their products relative to capital market assets. In some cases, low productivity caused a failure to meet contractual obligations embodied in their financial products. These failures resulted in customer losses, and/or taxpayer losses when failed intermediaries were guaranteed by government agencies. This productivity problem has been analyzed mostly from an economic science perspective, by R. C. Merton (Merton, R. C. 1990. The financial system and economic performance. J. Fin. Serv. Res. 263–300.) and Z. Bodie (Bodie, Z. 1990. Pension funds and financial innovation. Finan. Mgmt. (Autumn).). The focus of the economic analysis is the improvement of regulatory measures for intermediaries whose financial products are guaranteed by government agencies. In this paper we take a management science perspective by focusing on the technology of financial product management. An assessment of current technologies finds that their use can leave financial intermediaries exposed to substantial risks. An improved technology— integrated product management (IPM)—is suggested that enables intermediaries to increase productivity. Therefore, they can respond more effectively to market pressures from competing capital market assets and to regulatory pressures from government agencies. Technical and organizational aspects of integrated product management are described, and its application to three examples is discussed. The problem outlined here presents a major challenge to management scientists. It is an example of the service-sector applications that A. Geoffrion (Geoffrion, A. M. 1992. Forces, trends and opportunities in MS/OR. Opns. Res. 40 423–445.) addressed in his 1991 Omega Rho lecture."
/doi/10.1287/inte.1110.0614," Industrial and Commercial Bank of China (ICBC), the world's largest publicly traded bank as measured by market capitalization, deposit volume, and profitability, has a network of over 16,000 branches. This network is an important core competency and is fundamental to ICBC business development. To keep its leading position in the fast-changing and competitive China market, ICBC needed to reconfigure its branch locations and service capabilities to match the regional economy and customer distribution; therefore, it had to quickly identify new high-potential market areas in which to open branches. ICBC partnered with IBM to customize an operations research-based branch network optimization system, Branch Reconfiguration (BR), which it has implemented in over 40 major cities in China. In a typical major city (e.g., Suzhou), ICBC attributes US $1.04 billion in increased deposits to BR. The BR project is an example of successfully using operations research and management sciences to transform the service channels of a large bank in a manner that will continue to improve the bank's business development and decision making."
/doi/10.1287/mnsc.2017.2762," We model a corporate board evaluating a chief executive officer (CEO) of uncertain management ability. Each director receives a noisy private signal about CEO ability, after which directors discuss this ability and vote to retain or replace the CEO. Directors care about true CEO ability, since it affects their equity holding values; however, a CEO may impose costs of dissent on a director who votes to fire but fails to oust her. We relate the equilibrium CEO firing decision to board size, board composition, the effect of an imprecise public signal, and the cost and probability of finding a good replacement CEO. The online appendix is available at https://doi.org/10.1287/mnsc.2017.2762 . This paper was accepted by Gustavo Manso, finance."
/doi/10.1287/mnsc.2017.2927," The agriculture industry plays a critical role in the U.S. economy, and various industry sectors depend on the output of farms. To protect and raise farmers’ income, the U.S. government offers two subsidy programs to farmers: the Price Loss Coverage (PLC) program, which pays farmers a subsidy when the market price falls below a reference price, and the Agriculture Risk Coverage (ARC) program, which is triggered when farmers’ revenue is below a threshold. Given the unique features of PLC and ARC, we develop models to analyze their impacts on consumers, farmers, and the government. Our analysis generates several insights. First, while PLC always motivates farmers to plant more acres compared to the no-subsidy case, farmers may plant fewer acres under ARC, leading to a lower crop supply. Second, despite the prevailing intuition that ARC generally dominates PLC, we show that both farmers and consumers may be better off under PLC for a large range of parameter values, even when the reference price represents the historical average market price. Third, the subsidy that increases consumer surplus results in higher government expenditure. Finally, we calibrate our model with U.S. Department of Agriculture (USDA) data and provide insights about the effects of crop and market characteristics on the relative performance of PLC and ARC. We provide guidelines to farmers for enrolling crops in the subsidy programs, and show that our guidelines are supported by farmers’ enrollment statistics. We also show that if the economic and political frictions caused by running the subsidy programs is significant, the subsidy that benefits both consumers and farmers may actually result in lower social welfare. The online appendix is available at https://doi.org/10.1287/mnsc.2017.2927 . This paper was accepted by Serguei Netessine, operations management."
/doi/10.1287/orsc.10.4.439," Utilizing a model drawn from both transaction cost economics and social exchange theory, we analyze determinants of strategic flexibility in a sample of strategic alliances involved in joint development agreements or joint research pacts. Findings indicate that, in general, determinants suggested by transaction cost economics provided flexibility in modification and inflexibility in exit. From social exchange theory, trust was found to be positively related to both types of flexibility while another component of social exchange theory, dependence, was found to be negatively related to the strategic flexibility of the alliance. Results also found that factors suggested by both transaction cost economic theory and social exchange theory were related to the concept of trust. Economic constraints as suggested by transaction cost economics were positively related to trust between the alliance partners while dependence was negatively related to trust. Additionally, the quality of communication and the existence of shared values were positively related to trust between the exchange partners. Results provide support for the role of determinants from both transaction cost economics and social exchange theory in the flexibility of strategic alliances."
/doi/10.1287/mksc.2019.1188," Data brokers often use online browsing records to create digital consumer profiles that they sell to marketers as predefined audiences for ad targeting. However, this process is a “black box”—little is known about the reliability of the digital profiles that are created or of the audience identification provided by buying platforms. In this paper, we investigate using three field tests the accuracy of a variety of demographic and audience-interest segments. We examine the accuracy of more than 90 third-party audiences across 19 data brokers. Audience segments vary greatly in quality and are often inaccurate across leading data brokers. In comparison with random audience selection, the use of black box data profiles, on average, increased identification of a user with a desired single attribute by 0%–77%. Audience identification can be improved, on average, by 123% when combined with optimization software. However, given the high extra costs of targeting solutions and the relative inaccuracy, we find that third-party audiences are often economically unattractive except for higher-priced media placements."
/doi/10.1287/mnsc.46.4.548.12057," This paper studies a key driver of the demand for the products and services of the global IT industry—returns from IT investments. We estimate an intercountry production function relating IT and non-IT inputs to GDP output, on panel data from 36 countries over the 1985–1993 period. We find significant differences between developed and developing countries with respect to their structure of returns from capital investments. For the developed countries in the sample, returns from IT capital investments are estimated to be positive and significant, while returns from non-IT capital investments are not commensurate with relative factor shares. The situation is reversed for the developing countries subsample, where returns from non-IT capital are quite substantial, but those from IT capital investments are not statistically significant. We estimate output growth contributions of IT and non-IT capital and discuss the contrasting policy implications for capital investment by developed and developing economies."
/doi/10.1287/mnsc.2018.3222," We measure the impact of bank capital requirements on corporate borrowing, investment, and employment using loan-level data. The Basel II regulatory framework makes capital requirements vary across both banks and firms, which allows us to control for time-varying firm-level risk and bank-level credit supply shocks. We find that a 1 percentage point increase in capital requirements reduces lending by 2.3%–4.5%. Firms can attenuate this reduction by substituting borrowing across banks, but only to a limited extent. The resulting reduction in borrowing capacity affects significantly both investment and employment: for firms whose effective capital requirements increase by 1 percentage point, fixed assets are reduced by 1.1%, capital expenditures by 2.7%, and employment by 0.8%. This paper was accepted by Tomasz Piskorski, finance."
/doi/10.1287/inte.2013.0719," Shanghai Baoshan Iron and Steel Complex (Baosteel) is China’s largest and the world’s third-largest steel company. In 2005, our research team was tasked with developing advanced operations research-based planning tools to improve the operational efficiency of Baosteel’s Shanghai plant. In the following six years, we developed novel optimization algorithms and tailored metaheuristics, and implemented four decision support systems (DSSs) to replace the manual planning methods at the Shanghai plant. The DSSs have brought scientific operations management to Baosteel and transformed the plant’s production and final-product delivery operations. Baosteel estimates that from 2007 to 2012, they provided a cumulative economic benefit of 77 million. Based on their current usage at this plant, they also estimate that these DSSs will continue to provide an annual economic benefit of 20 million, which represents a 17 percent improvement of Baosteel’s information technology and operations management capability. They have also reduced Baosteel’s carbon dioxide emissions by 585,770 tons annually."
/doi/10.1287/opre.2017.1599," Since its initial development, long-term contracts have been associated with the gas industry in all regions of the world. This was also the case in Europe where natural gas trade was, for a long time, dominated by bilateral long-term agreements between producers and midstreamers. These contracts fixed a minimum volume to be exchanged (take or pay) and indexed the gas price using a price formula that usually referred to oil product prices. These arrangements allowed market risk sharing between the producer (who takes the price risk) and the midstreamer (who takes the volume risk). They also offered risk hedging since oil is considered as a trusted commodity by investors. The fall of the European natural gas demand, combined with the increase of the oil price, favored the emergence of a gas volume bubble that caused significant losses for most of the European midstreamers bound by long-term agreements. As a result, the downstream part of the industry brought forward the idea of indexing contracts on gas spot prices. In this paper, we present an equilibrium model that endogenously captures the contracting behavior of both producer and midstreamer, who strive to hedge their profit-related risk. Players can choose between gas forward and oil-indexed contracts. Using the model, we show that (i) contracting can reduce the trade risk for both producer and midstreamer; (ii) oil-indexed contracts should be signed only when oil and gas spot prices are well correlated, otherwise, these contracts hold less interest for risk mitigation; (iii) contracts are best suited when the upstream cost structure is mainly driven by capital costs; and (iv) a high level of risk aversion from the midstreamer might deprive upstream investments and downstream consumer surplus. The online appendix is available at https://doi.org/10.1287/opre.2017.1599 ."
/doi/10.1287/mnsc.2017.2960," This paper documents the increasing importance of software for successful innovation in manufacturing sectors well beyond the traditional definition of electronics and information technology. Using panel data for 229 publicly listed firms from 18 countries across four manufacturing industries over the period 1981–2005, we find significant variation across firms in the software intensity of their innovative activity. Firms that exhibit a higher level of software intensity generate more patents per R&D dollar, and their investment in R&D is more highly valued by equity markets. Data and the online appendix are available at https://doi.org/10.1287/mnsc.2017.2960 . This paper was accepted by Anandhi Bharadwaj, information systems."
/doi/10.1287/mksc.2014.0845," There are few marketing studies of social learning about new technologies in low-income countries. This paper examines how learning through opinion leaders and social networks influences demand for nontraditional cookstoves—a technology with important health and environmental consequences for developing country populations. We conduct marketing interventions in rural Bangladesh to assess how stove adoption decisions respond to (a) learning the adoption choices of locally identified “opinion leaders” and (b) learning about stove attributes and performance through social networks. We find that households generally draw negative inferences about stoves through social learning and that social learning is more important for stoves with less evident benefits. In an institutional environment where consumers are distrustful of new products and brands, consumers appear to rely on their networks more to learn about negative product attributes. Overall, our findings imply that external information and marketing campaigns can induce initial adoption and experiential learning about unfamiliar technologies, but sustained use ultimately requires that new technologies match local preferences."
/doi/10.1287/mnsc.1050.0464," In many settings, firms rely on independent contractors, or freelancers, for the provision of certain services. The benefits of such relationships for both firms and workers are often understood in terms of increased flexibility. Less understood is the impact of freelancing on individual performance. While it is often presumed that the performance of freelancers is largely portable across organizations, it is also possible that a given worker’s performance may vary across organizations if he or she develops firm-specific skills and knowledge over time. We examine this issue empirically by considering the performance of cardiac surgeons, many of whom perform operations at multiple hospitals within narrow periods of time. Using patient mortality as an outcome measure, we find that the quality of a surgeon’s performance at a given hospital improves significantly with increases in his or her recent procedure volume at that hospital but does not significantly improve with increases in his or her volume at other hospitals. Our findings suggest that surgeon performance is not fully portable across hospitals (i.e., some portion of performance is firm specific). Further, we provide preliminary evidence suggesting that this result may be driven by the familiarity that a surgeon develops with the assets of a given organization."
/doi/10.1287/mnsc.2020.3695," We study whether, how, and why the investment of a firm depends on the investment of other firms in the same product market. Using an instrumental variable based on the presence of local knowledge externalities, we find a sizeable complementarity of investment among product market peers, holding across a large majority of sectors. Peer effects are stronger in concentrated markets, featuring more heterogeneous firms, and for smaller firms with less precise information. Our findings are consistent with a model in which managers are imperfectly informed about fundamentals and use peers’ investments as a source of information. Product market peer effects in investment could amplify shocks in production networks. This paper was accepted by Gustavo Manso, finance."
/doi/10.1287/mnsc.2016.2718," We model illiquidity as a restriction on the stopping rules investors can follow in selling assets, and apply this framework to the valuation of thinly traded investments. We find that discounts for illiquidity can be surprisingly large, approaching 30%–50% in some cases. Immediacy plays a unique role and is valued much more than ongoing liquidity. We show that investors in illiquid enterprises have strong incentives to increase dividends and other cash payouts, thereby introducing potential agency conflicts. We also find that illiquidity and volatility are fundamentally entangled in their effects on asset prices. This aspect may help explain why some assets are viewed as inherently more liquid than others and why liquidity concerns are heightened during financial crises. This paper was accepted by Gustavo Manso, finance."
/doi/10.1287/mksc.2018.1108," Individual demand for consumer packaged goods shows discrete jumps between zero and large quantities, under a marginal change in price. Ruling out multiple alternative explanations, this paper provides evidence from microdata in the yogurt category that these jumps are caused by consumer fixed purchasing costs per product. We formulate and estimate a model in which (1) such fixed costs limit the number of different products considered and (2) consumers use prices to screen a product in and out of their consideration set. Our structural estimation finds that the consumer incurs fixed costs of $0.81 to consider a product. These costs are increased by 280% if she has not purchased the product for a year and are decreased by 59% when the product is featured in the store; the dependence of fixed costs on information shifters suggests that these costs are incurred because of consideration. Consideration being scarce at the shelf, firms compete fiercely for customers: We simulate counterfactual markups in a world full of feature advertising and find that firms enjoy higher equilibrium markups because the provision of information softens competition for consideration. Data and the online appendix are available at https://doi.org/10.1287/mksc.2018.1108 ."
/doi/10.1287/msom.2021.1023," Problem definition : We study an urban bike lane planning problem based on the fine-grained bike trajectory data, which are made available by smart city infrastructure, such as bike-sharing systems. The key decision is where to build bike lanes in the existing road network. Academic/practical relevance : As bike-sharing systems become widespread in the metropolitan areas over the world, bike lanes are being planned and constructed by many municipal governments to promote cycling and protect cyclists. Traditional bike lane planning approaches often rely on surveys and heuristics. We develop a general and novel optimization framework to guide the bike lane planning from bike trajectories. Methodology : We formalize the bike lane planning problem in view of the cyclists’ utility functions and derive an integer optimization model to maximize the utility. To capture cyclists’ route choices, we develop a bilevel program based on the Multinomial Logit model. Results : We derive structural properties about the base model and prove that the Lagrangian dual of the bike lane planning model is polynomial-time solvable. Furthermore, we reformulate the route-choice-based planning model as a mixed-integer linear program using a linear approximation scheme. We develop tractable formulations and efficient algorithms to solve the large-scale optimization problem. Managerial implications : Via a real-world case study with a city government, we demonstrate the efficiency of the proposed algorithms and quantify the trade-off between the coverage of bike trips and continuity of bike lanes. We show how the network topology evolves according to the utility functions and highlight the importance of understanding cyclists’ route choices. The proposed framework drives the data-driven urban-planning scheme in smart city operations management."
/doi/10.1287/orsc.1100.0570," Dynamic service settings—characterized by workers who interact with customers to deliver services in a rapidly changing, uncertain, and complex environment (e.g., hospitals)—play an important role in the economy. Organizational learning studies in these settings have largely investigated autonomous learning via cumulative experience as a strategy for performance improvement. Whether induced learning through the use of deliberate learning activities provides additional performance benefits has been neglected. We argue that the use of deliberate learning activities offers performance benefits beyond those of cumulative experience because these activities counter the learning challenges presented by rapid knowledge growth, uncertainty, and complexity in dynamic settings. We test whether there are additional performance benefits to using deliberate learning activities and whether the effectiveness of these activities depends on interdisciplinary collaboration in the workgroup. We test our hypotheses in a study of 23 hospital neonatal intensive care units (NICUs) involved in a quality improvement collaborative. We find that using deliberate learning activities is associated with better workgroup performance, as measured by NICUs' risk-adjusted mortality rates for 2159 infant patients, but only after two years. In the shorter term, using these activities is associated with worse performance. By the third year, the positive impact of using deliberate learning activities is similar to the benefit of cumulative experience (18% and 20% reduction in odds of mortality, respectively). Contrary to prediction, interdisciplinary collaboration mediates, rather than moderates, the relationship between using deliberate learning activities and workgroup performance. Thus, our data suggest that using deliberate learning activities fosters interdisciplinary collaboration."
/doi/10.1287/mnsc.1050.0362," Diagnostic information allows an agent to predict the state of nature about the success of an investment project better than the prior. We analyze the optimal pricing scheme for selling diagnostic information to buyers with different, privately known, ex ante success probability. Investment costs and returns of successful projects are assumed to be the same for all buyers. The value of diagnostic information is the difference in expected payoffs with and without it, and we show that the willingness to pay for diagnostic information is nonmonotonic in the ex ante success probability. When the information seller can offer only one quality level, and negative payments are not allowed, we find that the optimal menu of (linear) contracts is remarkably simple. A pure royalty is offered to buyers with low ex ante success probability, and a pure fixed fee is offered to buyers with high ex ante success probability."
/doi/10.1287/mnsc.2017.2827," Structured finance boomed during the run-up to the 2008 financial crisis. Highly rated, structured securities offered higher yield than other similarly rated bonds because of their concentration of systematic risk, but regulatory capital requirements did not account for this risk. As a result, regulated entities facing capital constraints had an incentive to invest in them. We show that life insurance companies exposed to unrealized losses from low interest rates in the early 2000s increased their holdings of highly rated securitized assets, consistent with regulatory arbitrage distorting the demand to hold these assets. This paper was accepted by Amit Seru, finance."
/doi/10.1287/msom.2017.0684," Most consumers in rural areas of many developing countries cannot afford to purchase certain livelihood improvement products such as home appliances. To improve consumer welfare and manufacturer profit, many governments launch different types of subsidy programs that offer subsidies to consumers, manufacturers, or both. Motivated by a subsidy program developed by the Chinese government in 2007, we present a parsimonious model to determine the optimal subsidy program in different settings so as to gain a better understanding about the conditions under which it is optimal for the government to subsidize consumers only, manufacturers only, or both. Our analysis reveals that the structure of the optimal subsidy program depends on (a) whether there is a well-established market selling price for the products; and (b) the relative emphasis that the government places on consumer welfare versus manufacturer profit. Also, we find that governments can improve consumer welfare by developing subsidy programs that involve multiple (competing) manufacturers with different market sizes and adequate capacities. Our findings provide insights for developing effective government subsidy programs. The online appendix is available at https://doi.org/10.1287/msom.2017.0684 ."
/doi/10.1287/mnsc.1090.1055," This paper compares the innovation performance of established pharmaceutical firms and biotech companies, controlling for differences in the scale and scope of research. We develop a structural model to analyze more than 3,000 drug research and development projects advanced to preclinical and clinical trials in the United States between 1980 and 1994. Key to our approach is careful attention to the issue of selection. Firms choose which compounds to advance into clinical trials. This choice depends not only on the technical promise of the compound, but also on commercial considerations such as the expected profitability of the market or concerns about product cannibalization. After controlling for selection, we find that (a) even after controlling for scale and scope in research, established pharmaceutical firms are more innovative than newly entered biotech firms; (b) older biotech firms display selection behaviors and innovation performances similar to established pharmaceutical firms; and (c) compounds licensed during preclinical trials are as likely to succeed as internal compounds of the licensor, which is inconsistent with the “lemons” hypothesis in technology markets."
/doi/10.1287/mnsc.1100.1253," When firms recruit inventors, they acquire not only the use of their skills but also enhanced access to their stock of ideas. But do hiring firms actually increase their use of new recruits' prior inventions? Our estimates suggest they do, quite significantly in fact, by approximately 219% on average. However, this does not necessarily reflect widespread “learning by hiring.” In fact, we estimate that a recruit's exploitation of her own prior ideas accounts for almost half of the above effect, with much of the diffusion to others being limited to the recruit's immediate collaborative network. Furthermore, although one might expect the recruit's role to diminish rapidly as her tacit knowledge diffuses across her new firm, our estimates indicate that her importance is surprisingly persistent over time. We base these findings on an empirical strategy that exploits the variation over time in hiring firms' citations to the recruits' premove patents. Specifically, we employ a difference-in-differences approach to compare premove versus postmove citation rates for the recruits' prior patents and corresponding matched-pair control patents. Our methodology has three benefits compared to previous studies that also examine the link between labor mobility and knowledge flow: (1) it does not suffer from the upward bias inherent in the conventional cross-sectional comparison, (2) it generates results that are robust to a more stringently matched control sample, and (3) it enables a temporal examination of knowledge flow patterns. This paper was accepted by Kamalini Ramdas, entrepreneurship and innovation."
/doi/10.1287/isre.1080.0218," Prior studies investigating business-to-consumer e-commerce have focused predominantly on online shopping by individuals on their own, although consumers often desire to conduct their shopping activities with others. This study explores the important, but seldom studied, topic of collaborative online shopping. It investigates two design components that are pertinent to collaborative online shopping support tools, namely, navigation support and communication support. Results from a laboratory experiment indicate that compared to separate navigation, shared navigation effectively reduces uncoupling (i.e., the loss of coordination with one's shopping partner) incidents per product discussed and leads to fewer communication exchanges dedicated to resolving each uncoupling incident, thereby enhancing coordination performance. Compared to text chat, voice chat does not help reduce the occurrence of uncoupling, but likely increases the efficiency in resolving uncoupling. The results further show that shared navigation and voice chat can significantly enhance the collaborative shoppers' perceptions of social presence derived from their online shopping experiences. The interaction effect on social presence implies that the benefit of shared navigation is higher in the presence of text chat than in the presence of voice chat."
/doi/10.1287/mnsc.1090.1069," We analyze the duration and outcomes of patent examination at the European Patent Office utilizing an unusually rich data set covering a random sample of 215,265 applications filed between 1982 and 1998. In our empirical analysis, we distinguish between three groups of determinants: applicant characteristics, indicators of patent quality and value, and determinants that affect the complexity of the examination task. The results from an accelerated failure time model indicate that more controversial claims lead to slower grants but faster withdrawals, whereas well-documented applications are approved faster and withdrawn more slowly. We find strong evidence that applicants accelerate grant proceedings for their most valuable patents, but that they also prolong the battle for such patents if a withdrawal or refusal is imminent. This paper develops implications of these results for managerial decision making in research and development and innovation management."
/doi/10.1287/orsc.2019.1311," We offer theory and evidence about how the fit between firm experience (supply side) and consumer preferences (demand side) affects postentry performance into a new technology. Specifically, we explore different types of preentry experience (technological and market experience) and use different aspects of postentry performance to draw inferences about consumer heterogeneity. Preentry technological experience (same product and different consumers) helps firms attract a larger share of intensive users (aligning with early adopters) but only if they enter the market early when these adopters make decisions. Preentry market experience (different product and same consumers) helps firms attract a larger share of lighter users, consistent with characterizations of mass market users. Exploiting different components of firm performance in the global second-generation mobile telecommunications industry (average usage intensity and market penetration) allows us to articulate and identify the paths and mechanisms that allow preentry experience to affect postentry performance. The theory as well as important theoretical boundary conditions have implications for research on preentry experience, demand-side heterogeneity, and industry evolution."
/doi/10.1287/mnsc.1060.0531, We propose a new approach to assess systemic financial stability of a banking system using standard tools from modern risk management in combination with a network model of interbank loans. We apply our model to a unique data set of all Austrian banks. We find that correlation in banks' asset portfolios dominates contagion as the main source of systemic risk. Contagion is rare but can nonetheless wipe out a major part of the banking system. Low bankruptcy costs and an efficient crisis resolution policy are crucial to limit the systemwide impact of contagious default events. We compute the “value at risk” for a lender of last resort and find that the funds necessary to prevent contagion are surprisingly small.
/doi/10.1287/isre.2021.1010," Digital technologies have led to the emergence of many platforms in our economy today. In certain platform networks, buyers in one market purchase services from providers in many other markets, whereas in others, buyers primarily purchase services from providers within the same market. Accordingly, network interconnectivity—which measures the degree to which consumers in one market purchase services from service providers in a different market—varies across different industries. We examine how network interconnectivity affects interactions between an incumbent platform serving multiple markets and an entrant platform seeking to enter one of these markets. Our model yields several interesting results. First, even if the entrant can advertise at no cost, it still may not want to make every user in a local market aware of its service, as doing so may trigger a competitive response from the incumbent. Second, having more mobile buyers, which increases interconnectivity between markets, can reduce the incumbent’s incentive to fight and, thus, increase the entrant’s incentive to expand. Third, stronger interconnectivity between markets may or may not make the incumbent more defensible: when advertising is not costly and mobile buyers consume in both their local markets and the markets they visit, a large number of mobile buyers will increase the entrant’s profitability, thereby making it difficult for the incumbent to deter entry. However, when advertising is costly or mobile buyers only consume in the markets they travel to, a large number of mobile buyers will help the incumbent deter entry. When advertising cost is at an intermediate level, the entrant prefers a market with moderate interconnectivity between markets. Fourth, we find that even if advanced targeting technologies can enable the entrant to also advertise to mobile buyers, the entrant may choose not to do so in order to avoid triggering the incumbent’s competitive response. Finally, we find that the presence of network effects is likely to decrease the entrant’s profit. Our results offer managerial implications for platform firms and help understand their performance heterogeneity."
/doi/10.1287/mnsc.1100.1155," We study the impact of financial innovations on real investment decisions within the framework of an incomplete market economy comprised of firms, investors, and an intermediary. The firms face unique investment opportunities that arise in their business operations and can be undertaken at given reservation prices. The cash flows thus generated are not spanned by the securities traded in the financial market and cannot be valued uniquely. The intermediary purchases claims against these cash flows, pools them together, and sells tranches of primary or secondary securities to the investors. We derive necessary and sufficient conditions under which projects are undertaken due to the intermediary's actions, and firms are amenable to the pool proposed by the intermediary, compared to the no-investment option or the option of forming alternative pools. We also determine the structure of the new securities created by the intermediary and identify how it exploits the arbitrage opportunities available in the market. Our results have implications for valuation of real investments, synergies among them, and their financing mechanisms. We illustrate these implications using an example of inventory decisions under random demand. This paper was accepted by John Birge, focused issue editor."
/doi/10.1287/mnsc.2015.2200," Our paper investigates spillover effects across different business segments of publicly traded financial conglomerates. We find that the investment decisions of mutual fund shareholders do not depend only on the prior performance of the mutual funds; they also depend on the prior performance of the funds’ management companies. Flows into equity and bond mutual funds increase with the prior stock price performance of the funds’ management companies after controlling for fund performance and other fund characteristics. The sensitivity of flows to the management company’s performance is not justified by the subsequent performance of the affiliated funds. The results indicate that the reputation of a company’s brand has a significant impact on the behavior of its customers. This paper was accepted by Wei Jiang, finance ."
/doi/10.1287/mnsc.2013.1764," The movement of information technology (IT) workers among firms is believed to be an important mechanism by which IT-related innovations diffuse throughout the economy. We use a newly developed source of employee microdata—an online resume database—to model IT workers' mobility patterns. We find that firms derive significant productivity benefits from the IT investments of other firms from which they hire IT labor. Our estimates indicate that over the last two decades, productivity spillovers from the IT investments of other firms transmitted through this channel have contributed 20%–30% as much to productivity growth as firms' own IT investments. Moreover, we find that the productivity benefits of locating near other IT-intensive firms can primarily be explained by the mobility of technical workers within the region. Our results are unique to the flow of IT workers among firms, not other occupations, which rules out some alternative explanations related to the similarity of firms that participate in the same labor flow network. This paper was accepted by Yu (Jeffrey) Hu, guest department editor, information systems."
/doi/10.1287/mnsc.2014.2005," We build a model of investment and financing decisions to study the choice between bonds and bank loans in a firm’s marginal financing decision and its effects on corporate investment. We show that firms with more growth options, with higher bargaining power in default, operating in more competitive product markets, or facing lower credit supply are more likely to issue bonds. We also demonstrate that, by changing the cost of financing, these characteristics affect the timing of investment. We test these predictions using a sample of U.S. firms and present new evidence that supports our theory. Data, as supplemental material, are available at http://dx.doi.org/10.1287/mnsc.2014.2005 . This paper was accepted by Gustavo Manso, finance."
/doi/10.1287/mnsc.2015.2295," Consider a firm that would like to commit to a focused business strategy because focus improves efficiency and thus increases profit. We identify two general conditions under which tougher competition strengthens the firm’s ability to commit to a focused strategy. Under these conditions, competition fosters commitment for two reasons: (i) competition reduces the value of the option to diversify ( the contestability effect ), and (ii) competition increases the importance of being efficient ( the efficiency effect ). We use a number of different models of imperfect competition to illustrate the applicability of our results. Our examples suggest that the contestability effect is very general. In contrast, the efficiency effect often requires further conditions, which are specific to the nature of competition in each model. In both cases, our analysis helps us predict when these effects are more likely to be observed. This paper was accepted by Bruno Cassiman, business strategy ."
/doi/10.1287/mksc.2018.1135," Measuring the causal effects of digital advertising remains challenging despite the availability of granular data. Unobservable factors make exposure endogenous, and advertising’s effect on outcomes tends to be small. In principle, these concerns could be addressed using randomized controlled trials (RCTs). In practice, few online ad campaigns rely on RCTs and instead use observational methods to estimate ad effects. We assess empirically whether the variation in data typically available in the advertising industry enables observational methods to recover the causal effects of online advertising. Using data from 15 U.S. advertising experiments at Facebook comprising 500 million user-experiment observations and 1.6 billion ad impressions, we contrast the experimental results to those obtained from multiple observational models. The observational methods often fail to produce the same effects as the randomized experiments, even after conditioning on extensive demographic and behavioral variables. In our setting, advances in causal inference methods do not allow us to isolate the exogenous variation needed to estimate the treatment effects. We also characterize the incremental explanatory power our data would require to enable observational methods to successfully measure advertising effects. Our findings suggest that commonly used observational approaches based on the data usually available in the industry often fail to accurately measure the true effect of advertising. The online appendix and data files are available at https://doi.org/10.1287/mksc.2018.1135 ."
/doi/10.1287/isre.2018.0800," We investigate the impact of collaborative filtering recommender algorithms (e.g., Amazon’s “Customers who bought this item also bought”) commonly used in e-commerce on sales diversity. We use data from a randomized field experiment run on the website of a top retailer in North America across 82,290 products and 1,138,238 users. We report four main findings. First, we demonstrate and quantify across a wide range of product categories that the use of traditional collaborative filters (CFs) is associated with a decrease in sales diversity relative to a world without product recommendations. Furthermore, the design of the CF matters. CFs based on purchase data are associated with a greater effect size than those based on product views. Second, the decrease in aggregate sales diversity may not always be accompanied by a corresponding decrease in individual-level consumption diversity. In fact, it is even possible for individual consumption diversity to increase while aggregate sales diversity decreases. Third, copurchase network analyses show that while recommenders can help individuals explore new products, similar users still end up exploring the same kinds of products, resulting in concentration bias at the aggregate level. Fourth and finally, there is a difference between absolute and relative impact on niche items. Specifically, absolute sales and views for niche items in fact increase, but their gains are smaller compared with the gains in views and sales for popular items. Thus, whereas niche items gain in absolute terms, they lose out in terms of market share. We discuss economic impacts and managerial implications. The online appendices are available at https://doi.org/10.1287/isre.2018.0800 ."
/doi/10.1287/trsc.1100.0327," Because of historically high fuel prices, the trucking industry's operating expenses are higher than ever and thus profit margins are lower than ever. To cut costs, the trucking industry is searching for and exploring new ideas. We investigate the potential of collaborative opportunities in truckload transportation. When carriers serve transportation requests from many shippers, they may be able to reduce their repositioning costs by exchanging one or more of them. We develop optimization models to determine the maximum benefit that can be derived from collaborating. We also develop various exchange mechanisms which differ in terms of information sharing requirements and side payment options that allow carriers to realize some or all of the costs savings opportunities."
/doi/10.1287/mnsc.2019.3392," We study a model where each competing firm has a target segment where it has full consumer information and can exercise personalized pricing, and consumers may engage in identity management to bypass the firm’s attempt to price discriminate. In the absence of identity management, more consumer information intensifies competition because firms can effectively defend their turf through targeted personalized offers, thereby setting low public prices offered to nontargeted consumers. But the effect is mitigated when consumers are active in identity management because it raises the firm’s cost of serving nontargeted consumers. When firms have sufficiently large and nonoverlapping target segments, identity management can enable firms to extract full surplus from their targeted consumers through perfect price discrimination. Identity management can also induce firms not to serve consumers who are not targeted by either firm when the commonly nontargeted market segment is small. This results in a deadweight loss. Thus, identity management by consumers can benefit firms and lead to lower consumer surplus and lower social welfare. Our main insight continues to be valid when a fraction of consumers are active in identity management or when there is a cost of identity management. We also discuss the regulatory implications for the use of consumer information by firms as well as the implications for management. This paper was accepted by Juanjuan Zhang, marketing."
/doi/10.1287/mnsc.2021.4032," This paper estimates the heterogeneity in peer effects among research scientists in terms of network position. I propose a new measure, brokerage degree , that determines the extent to which a scientist depends on a coauthor to provide him unique access to other scientists further away. I apply this measure to the coauthorship network of medical scientists. I show that network position is crucial for productivity by facilitating access to nonredundant knowledge. Identification results from variation in brokerage degree among coauthors linked to a star scientist who dies. A one standard deviation increase in the brokerage degree of a deceased star is associated with a 10% decrease in annual publications of his coauthor. By applying brokerage degree to topics, I provide evidence that access to knowledge flows embodied in scientists further away can account for a large proportion of the identified heterogeneity effect. This paper was accepted by Toby Stuart, entrepreneurship and innovation."
/doi/10.1287/deca.2013.0282," When multiple redundant probabilistic judgments are obtained from subject matter experts, it is common practice to aggregate their differing views into a single probability or distribution. Although many methods have been proposed for mathematical aggregation, no single procedure has gained universal acceptance. The most widely used procedure is simple arithmetic averaging, which has both desirable and undesirable properties. Here we propose an alternative for aggregating distribution functions that is based on the median cumulative probabilities at fixed values of the variable. It is shown that aggregating cumulative probabilities by medians is equivalent, under certain conditions, to aggregating quantiles. Moreover, the median aggregate has better calibration than mean aggregation of probabilities when the experts are independent and well calibrated and produces sharper aggregate distributions for well-calibrated and independent experts when they report a common location-scale distribution. We also compare median aggregation to mean aggregation of quantiles."
/doi/10.1287/mnsc.2018.3125," Empirically, bank equity value is decreasing in the interest rate. Yet (i) many banks do not hedge interest rate risk, and (ii) more than 50% of hedging banks use derivatives to increase exposure. I model a bank’s capital structure and show that these facts are consistent with optimal hedging under financial frictions. Novel predictions on the characteristics of banks taking long or short interest rate derivative positions are tested and supported by the data. Therefore, banks’ derivatives exposures are not necessarily evidence of excessive risk taking. More broadly, the results challenge the view that “hedging” and “speculative” positions can be identified from a positive comovement between derivatives payoffs and equity value. This paper was accepted by Gustavo Manso, finance."
/doi/10.1287/mnsc.2018.3147," We provide the first large-sample evidence on the behavior and impact of nonpracticing entities (NPEs) in the intellectual property space. We find that, on average, NPEs appear to behave as opportunistic “patent trolls.” NPEs sue cash-rich firms and target cash in business segments unrelated to alleged infringement at essentially the same frequency as they target cash in segments related to alleged infringement. By contrast, cash is neither a key driver of intellectual property lawsuits by practicing entities (e.g., IBM and Intel) nor of any other type of litigation against firms. We find further suggestive evidence of NPE opportunism: targeting of firms that have reduced ability to defend themselves, repeated assertions of lower-quality patents, increased assertion activity nearing patent expiration, and forum shopping. We find, moreover, that NPE litigation has a real negative impact on innovation at targeted firms: firms substantially reduce their innovative activity after settling with NPEs (or losing to them in court). Meanwhile, we neither find any markers of significant NPE pass-through to end innovators, nor of a positive impact of NPEs on innovation in the industries in which they are most prevalent. This paper was accepted by Tyler Shumway, finance."
/doi/10.1287/mksc.2018.1095," The interplay between innovation and the stock market has been extensively studied by scholars across all business disciplines. However, one phenomenon remains understudied: the association between innovation and stock market bubbles. Bubbles—defined as rapid increases and subsequent declines in stock prices—have been primarily examined by economists who generally do not focus on individual characteristics of innovations or on the consequences of bubbles for their parent firms. We set out to fill this gap in our paper. Using a sample of 51 major innovations introduced between 1825 and 2000, we test for bubbles in the stock prices of parent firms subsequent to the commercialization of these innovations. We identify bubbles in 73% of the cases. The magnitude of these bubbles increases with the radicalness of innovations, with their potential to generate indirect network effects, and with their public visibility at the time of commercialization. Moreover, we find that parent firms typically raise new equity capital during bubble periods and that the amount of equity raised is proportional to the magnitude of the bubble. Finally, we show that the buy-and-hold abnormal returns of parent firms are significantly positive between the beginning and the end of the bubble, suggesting that these innovations add value to their firm and to the economy, in spite of the bubble. Our findings have important implications for managers interested in commercializing innovations and for policy makers concerned with the stability of the financial system. Data and the online appendix are available at https://doi.org/10.1287/mksc.2018.1095 ."
