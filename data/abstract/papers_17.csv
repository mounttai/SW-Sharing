link,abstract
/doi/10.1287/orsc.2014.0947," This paper shows how mesolevel structures support effective coordination in temporary groups. Prior research on coordination in temporary groups describes how roles encode individual responsibilities so that coordination between relative strangers is possible. We extend this research by introducing key tenets from team effectiveness research to theorize when role-based coordination might be more or less effective. We develop these ideas in a multimethod study of a hospital emergency department (ED) redesign. Before the redesign, people coordinated in ad hoc groupings, which provided flexibility because any nurse could work with any doctor, but these groupings were limited in effectiveness because people were not accountable to each other for progress, did not have shared understanding of their work, and faced interpersonal risks when reaching out to other roles. The redesign introduced new mesolevel structures that bounded a set of roles (rather than a set of specific individuals, as in a team) and gave them collective responsibility for a whole task. We conceptualized the mesolevel structures as team scaffolds and found that they embodied the logic of both role and team structures. The team scaffolds enabled small-group interactions to take the form of an actual team process with team-level prioritizing, updating, and helping, based on newfound accountability, overlapping representations of work, and belonging—despite the lack of stable team composition. Quantitative data revealed changes to the coordination patterns in the ED (captured through a two-mode network) after the team scaffolds were implemented and showed a 40% improvement in patient throughput time."
/doi/10.1287/isre.1060.0106," For online marketplaces to succeed and prevent a market of lemons, their feedback mechanism (reputation system) must differentiate among sellers and create price premiums for trustworthy sellers as returns to their reputation. However, the literature has solely focused on numerical (positive and negative) feedback ratings, alas ignoring the role of feedback text comments. These text comments are proposed to convey useful reputation information about a seller’s prior transactions that cannot be fully captured with crude numerical ratings. Building on the economics and trust literatures, this study examines the rich content of feedback text comments and their role in building a buyer’s trust in a seller’s benevolence and credibility. In turn, benevolence and credibility are proposed to differentiate among sellers by influencing the price premiums that a seller receives from buyers. This paper utilizes content analysis to quantify over 10,000 publicly available feedback text comments of 420 sellers in eBay’s online auction marketplace, and to match them with primary data from 420 buyers that recently transacted with these 420 sellers. These dyadic data show that evidence of extraordinary past seller behavior contained in the sellers’ feedback text comments creates price premiums for reputable sellers by engendering buyer’s trust in the sellers’ benevolence and credibility (controlling for the impact of numerical ratings). The addition of text comments and benevolence helps explain a greater variance in price premiums ( R 2 = 50%) compared to the existing literature ( R 2 = 20%–30%). By showing the economic value of feedback text comments through trust in a seller’s benevolence and credibility, this study helps explain the success of online marketplaces that primarily rely on the text comments (versus crude numerical ratings) to differentiate among sellers and prevent a market of lemon sellers. By integrating the economics and trust literatures, the paper has theoretical and practical implications for better understanding the nature and role of feedback mechanisms, trust building, price premiums, and seller differentiation in online marketplaces."
/doi/10.1287/ijoc.2020.0958," Apiculture has gained worldwide interest because of its contributions to economic incomes and environmental conservation. In view of these, migratory beekeeping, as a high-yielding technique, is extensively adopted. However, because of the lack of an overall routing plan, beekeepers who follow the experiential migratory routes frequently encounter unexpected detours and suffer losses when faced with problems such as those related to nectar source capacities and the production of bee products. The migratory beekeeping routing problem (MBRP) is proposed based on the practical background of the commercial apiculture industry to optimize the global revenue for beekeepers by comprehensively considering nectar source allocation, migration, production and sales of bee products, and corresponding time decisions. The MBRP is a new variant of the vehicle routing problem but with significantly different production time decisions at the vertices (i.e., nectar sources). That is, only the overlaps between residence durations and flowering periods generate production benefits. Different sales visits cause different gains from the same products; in turn, these lead to different production time decisions at previously visited nectar source locations and even change the visits for production. To overcome the difficulty resulting from the complicated time decisions, we utilize the Dantzig–Wolfe decomposition method and propose a revised labeling algorithm for the pricing subproblems. The tests, performed on instances and a real-world case, demonstrate that the column generation method with the revised labeling algorithm is efficient for solving the MBRP. Compared with traditional routes, a more efficient overall routing schedule for migratory beekeepers is proposed. Summary of Contribution. Based on the practical background of commercial apiculture industry, this paper proposes a new type of routing problem named the migratory beekeeping routing problem (MBRP), which incorporates the selection of productive nodes and sales nodes as well as the production time decision at the productive nodes on a migratory beekeeping network. To overcome the difficulty resulting from the complicated time decisions, we utilize the Dantzig–Wolfe decomposition method and propose a revised labeling algorithm for the pricing subproblems. The tests, performed on instances and a real-world case, demonstrate that the column generation method with the revised labeling algorithm is efficient for solving the MBRP. Compared with traditional routes, a more efficient overall routing schedule for migratory beekeepers is proposed. Therefore, this paper is congruent with, and contributes to, the scope and mission of INFORMS Journal on Computing , especially the area of Network Optimization: Algorithms & Applications."
/doi/10.1287/inte.8.1pt2.82," New product decisions often must be made with considerable uncertainty relating to sales, product and process development outcomes, manufacturing costs, etc. Purchasing commitments (long and short-term) and product and process development decisions are required at early points in the product life-cycle and usually involve large expenditures. The authors describe how Management Science techniques have been used to assist in new product purchasing and development decision-making, where the new product required significant technological innovation and was being introduced into a market in which there was little previous experience. The project approach consisted of: (1) formulating deterministic economic and capacity models to simulate the consequences of alternative outcomes in the market and technical areas; (2) working closely with engineering, procurement, marketing and planning organizations to determine the range and likelihood of the input variables; (3) using the models to determine the sensitive variables and to place probabilistic ranges on the outcomes of interest; and (4) presenting the results to management so that decisions could be made relative to plant construction, purchase quantities, and alternative components/processes. Emphasis is placed on methodology and the way management scientists can effectively work with and assist decision-makers, rather than on the models and techniques employed."
/doi/10.1287/ijoc.15.3.284.16077," Many auctions involve the sale of a variety of distinct assets. Examples are airport time slots, delivery routes, network routing, and furniture. Because of complementarities or substitution effects between the different assets, bidders have preferences not just for particular items but for sets of items. For this reason, economic efficiency is enhanced if bidders are allowed to bid on bundles or combinations of different assets. This paper surveys the state of knowledge about the design of combinatorial auctions and presents some new insights. Periodic updates of portions of this survey will be posted to this journal's Online Supplements web page at http://joc.pubs.informs.org/OnlineSupplements.html"
/doi/10.1287/deca.1120.0241," This paper presents and compares four models of games and risk analyses designed to support strategic and policy decisions, three focusing on national security issues and one on project management. They share a common core of probability, linked decisions among the parties involved, and risks to a principal decision maker. Their structure is based on systems and decision analysis. Their level of complexity depends on the strategies, the environment, and assumptions of variation over time of probabilities, preferences, and options. They are part of the field of analytics and some of its real-life applications. The first model is based on a one-move game, in which the United States faces risks of terrorist attacks by several possible groups using various types of weapons. The result is a probabilistic ranking, at a given time, of the threat posed by these weapons. The second model is a dynamic simulation of counterterrorism scenarios in an alternate game between a government and a terrorist group. The objective is to compare the stabilizing effects of different short- and long-term government strategies. The third model is a dynamic evaluation of nuclear counterproliferation strategies involving an analysis of the weapon development program of a particular country with evolving intent and capabilities and of the effectiveness of different U.S. strategies to prevent or delay its success. The fourth model is a principal–agent representation of the development of an engineered system, in which an agent in charge of part of the project may consider meeting a deadline by cutting corners if he falls behind schedule, generally increasing the system failure probability. The goal is to support the decisions of the manager in setting constraints and incentives. This paper shows how a set of similar game and risk analysis models at different levels of complexity can provide valuable insights to decision makers, both in national security and management situations, and help them avoid mistakes such as excessive focus on the short term and underestimation of dependencies. It compares their capabilities, including the number of moves, dynamics of the underlying situation, possible changes of context, actors' preferences and strategic options, and risk characterization."
/doi/10.1287/mnsc.2021.4038," Many phenomena of preference construction demonstrate a violation of the rationality premise in classical economic theories. One of the most well-known examples of preference construction is the compromise effect. This puzzling anomaly can be rationalized by contextual deliberation (i.e., endogenous information retrieval/acquisition that can partially resolve utility uncertainty before choice). In this research, we investigate the empirical validity of this explanation by performing falsification tests for its necessary predictions and identifying it from other potential accounts. We conduct five experiments with more than 1,000 participants and show that the compromise effect can be positively mediated by response time and cannot be eliminated by context information, but it can be moderated by manipulating the level of deliberation (i.e., time constraint, preference articulation, task order). These findings are consistent with the predictions of the theory of contextual deliberation. We also show that, on average, contextual deliberation (as proxied by response time) can uniquely account for about half of the total compromise effect. This paper was accepted by Yan Chen, behavioral economics and decision analysis"
/doi/10.1287/trsc.2020.1026," Understanding the characteristics of air-traffic delays and disruptions is critical for developing ways to mitigate their significant economic and environmental impacts. Conventional delay-performance metrics reflect only the magnitude of incurred flight delays at airports; in this work, we show that it is also important to characterize the spatial distribution of delays across a network of airports. We analyze graph-supported signals, leveraging techniques from spectral theory and graph-signal processing to compute analytical and simulation-driven bounds for identifying outliers in spatial distribution. We then apply these methods to the case of airport-delay networks and demonstrate the applicability of our methods by analyzing U.S. airport delays from 2008 through 2017. We also perform an airline-specific analysis, deriving insights into the delay dynamics of individual airline subnetworks. Through our analysis, we highlight key differences in delay dynamics between different types of disruptions, ranging from nor’easters and hurricanes to airport outages. We also examine delay interactions between airline subnetworks and the system-wide network and compile an inventory of outlier days that could guide future aviation operations and research. In doing so, we demonstrate how our approach can provide operational insights in an air-transportation setting. Our analysis provides a complementary metric to conventional aviation-delay benchmarks and aids airlines, traffic-flow managers, and transportation-system planners in quantifying off-nominal system performance."
/doi/10.1287/orsc.2018.1231," A fundamental question in corporate strategy is how headquarters in multibusiness firms can create value above and beyond the burden of its own overhead. The leading theories from Chandler and Williamson hold that this is possible through resource allocation across businesses. Yet, there are multibusiness firms for whom reallocation opportunities are limited—e.g., chains. Accordingly, we propose, model, and test an alternative theory, one in which headquarters facilitates market-like dynamics between businesses that fuel innovation and growth. Whereas Chandler’s and Williamson’s theories involve the visible hand of managers, ours involves an invisible hand of managers. We construct an interacting agent model of the theory, which yields three propositions relating multibusiness structure to firm growth. We test those propositions in the banking industry and obtain results consistent with the model’s predictions. In particular, knowledge growth increases in the number of units and heterogeneity in their knowledge, and increases then decreases in their geographic distance. Interestingly, once we account for these structural elements, scale and hierarchy both suppress innovation. Thus, neither Williamson’s nor Chandler’s theories hold in our setting (consistent with the argument motivating the need for an additional theory)."
/doi/10.1287/inte.29.6.29," The roots of good strategic decision making are in cultural and organizational norms and patterns. One principle, which we call the outside-in strategic perspective, is essential for excellent strategy. This perspective led a company to recognize that its current strategy was counterproductive and that it must make almost a 180-degree turn. While many companies start with themselves and project market shares, earnings, and so forth out into the environment, the outside-in strategic perspective reverses this to start with the environment and work inwards to the company. In this case, we used a framework that starts with consumer spending in various entertainment areas and divided revenues along a simple value chain of retailers, wholesalers, and producers. An influence-diagram-based model led to counter-intuitive insights about the most valuable segments."
/doi/10.1287/isre.2013.0477," Universal access (UA) to the Internet and the associated information infrastructure has become an important economic and societal goal. However, UA initiatives tend to focus on issues such as physical access and geographical ubiquity, and they measure adoption through penetration rates. In this paper, we apply an interpretive case study approach to analyze the Philadelphia wireless initiative to provide insights into the nature of UA and extend this concept to also consider universal use (UU). UU is important because simply providing access does not guarantee use. UU is presented as a conceptual goal that starts with the challenge of physical access, but which necessarily also leads to considerations of use. The results show that the human and technological elements underlying individual access and use are deeply embedded within various institutional elements and collectives that enable but also constrain meaningful use. We integrate our findings into a multilevel framework that shows how access and use are influenced by both micro and macro factors. This framework provides new insights into the study of the information infrastructure, digital divide, and public policy."
/doi/10.1287/trsc.2019.0952," This paper considers a carpool matching (CaMa) problem in which participants price shared rides based on both operating cost and schedule displacement (i.e., the absolute difference between the desired and actual arrival times). By reporting their valuation of this displacement, each participant in effect bids for every possible shared ride that generates a unique value to her. The CaMa problem can be formulated as a mixed integer program (MIP) that maximizes the social welfare by choosing matching pairs and a departure time for each pair. We show the optimal departure time can be determined for each pair a priori, independent of the matching problem. This result reduces the CaMa problem to a standard bipartite matching problem. We prove that the classical Vickrey-Clarke-Groves (VCG) pricing policy ensures no participant is worse off or has the incentive to misreport their valuation of schedule displacement. To control the large deficit created by the VCG policy, we develop a single-side reward (SSR) pricing policy, which only compensates participants who are forced by the system to endure a schedule displacement. Under the assumption of overpricing tendency (i.e., no participant would want to underreport their value), we show the SSR policy not only generates substantial profits, but also retains the other desired properties of the VCG policy, notably truthful reporting. Even though it cannot rule out underreporting, our simulation experiments confirm that the SSR policy is a robust and deficit-free alternative to the VCG policy. Specifically, we find that (1) underreporting is not a practical concern for a carpool platform as it never reduces the number of matched pairs and its impact on profits is largely negligible; and (2) participants have very little to gain by underreporting their value."
/doi/10.1287/orsc.2017.1126," Although existing research has demonstrated the importance of attaining legitimacy for new market categories, few scholars have considered the trade-offs associated with such actions. Using the U.S. organic food product category as a context, we explore how one standards-based certification organization—the California Certified Organic Farmers (CCOF)—sought to balance efforts to legitimate a nascent market category with retaining a shared, distinctive identity among its members. Our findings suggest that legitimacy-seeking behaviors undertaken by the standards organization diluted the initial collective identity and founding ethos of its membership. However, by shifting the meaning of “organic” from the producer to the product, CCOF was able to strengthen the categorical boundary, thereby enhancing its legitimacy. By showing how the organization managed the associated trade-offs, this study highlights the double-edged nature of legitimacy and offers important implications for the literatures on legitimacy and new market category formation. The online appendix is available at https://doi.org/10.1287/orsc.2017.1126 ."
/doi/10.1287/mnsc.1120.1523," Based on a supply chain framework, we study the stocking decision of a downstream buyer who receives private demand information and has the incentive to influence her capital market valuation. We first characterize a market equilibrium under a general, single buyback contract. We show that the buyer's stocking decision can be distorted in equilibrium. Such a downstream stocking distortion hurts the buyer firm's own performance, and it also influences the performances of the supplier and the supply chain. We further reveal scenarios where full supply chain efficiency cannot be reached under any single buyback contract. Then, focusing on contract design, we characterize conditions under which a menu of buyback contracts can prevent downstream stocking distortion and restore full efficiency in the supply chain. Our study demonstrates that in a supply chain context, a firm's incentive to undertake real economic activities to influence capital market valuation can potentially be resolved through operational means. This paper was accepted by Yossi Aviv, operations management."
/doi/10.1287/isre.1090.0276," Many successful open-source projects have been developed by programmers who were employed by firms but worked on open-source projects on the side because of economic incentives like career improvement benefits. Such side work may be a good thing for the employing firms, too, if they get some strategic value from the open-source software and if the productivity of the programmers on these projects improves through learning-by-doing effects. However, the programmers may work more or less on these projects than what is best for the firms. To manage the programmers' efforts, the firms set appropriate employment policies and incentives. These policies and career concerns then together govern the programmers' effort allocation between the open-source and proprietary projects. We examine this relationship using a variant of the principal/agent model. We derive and characterize optimal employment contracts and show that firms either offer a bonus for only one of the two projects or do not offer any bonuses. However, if attractive alternate employment opportunities are available, they change their strategy and may offer bonuses for both projects simultaneously."
/doi/10.1287/mnsc.1060.0620," The recorded transactions of venture capital investments permit a direct examination of the Braudel hypothesis that regional markets evolve dynamically and interdependently in reference to a global system. This hypothesis contradicts the popular belief that regional financial development is anchored in dense clusters. Using methods of complex graphs, we analyze 159,561 transactions over nearly 45 years to demonstrate the rapid emergence of a national network of syndications. A giant component emerges early in the history of the industry, which subsumes the regional and sectoral subgraphs. The results confirm the Braudel hypothesis over the role of regional clusters, rejects preferential attachment in favor of repeated ties among trusted partners, and emphasizes the importance of dynamics and complex weighted graphs for the analysis of social and economic behavior."
/doi/10.1287/orsc.2021.1515," Organizations are riddled with cooperation problems, that is, instances in which workers need to voluntarily exert effort to achieve efficient collective outcomes. To sustain high levels of cooperation, the experimental literature demonstrates the centrality of reciprocal preferences but has also overlooked some of its negative consequences. In this paper, we ran lab-in-the-field experiments in the context of open-source software development teams to provide the first field evidence that highly reciprocating groups are not necessarily more successful in practice. Instead, the relationship between high reciprocity and performance can be more accurately described as U-shaped. Highly reciprocal teams are generally more likely to fail and only outperform other teams conditional on survival. We use the dynamic structure of our data on field contributions to demonstrate the underlying theoretical mechanism. Reciprocal preferences work as a catalyst at the team level: they reinforce the cooperative equilibrium in good times but also make it harder to recover from a negative signal (the project dies). Our results call into question the idea that strong reciprocity can shield organizations from cooperation breakdowns. Instead, cooperation needs to be dynamically managed through relational contracts."
/doi/10.1287/mnsc.1060.0648," This paper examines an economic theory of when employees become entrepreneurs. It jointly addresses the two fundamental questions of when employees generate innovations, and whether these innovations are developed as internal ventures or outside the firm. The model shows that if generating innovations distracts employees from their assigned tasks, firms may discourage innovation. Firms may reject profitable opportunities that fall outside of their core activities. If employees own the intellectual property (IP), they may leave to do a start-up. The allocation of IP rights also affects the generation of innovation. The external entrepreneurial environment is a complement to firm-internal innovation. If the external environment is particularly good, firms may embrace employee innovation and take advantage of it through spin-offs."
/doi/10.1287/trsc.2017.0786," Robotic compact storage and retrieval systems (RCSRS) have seen many implementations over the last few years. In such a system, the inventory items are stored in bins, organized in a grid. In each cell of the grid, a certain number of bins are stored on top of each other. Robots with transport and lifting capabilities move on the grid roof to transport bins between manual workstations and storage stacks. We estimate performance and evaluate storage policies of RCSRS, considering both dedicated and shared storage policies coupled with random and zoned storage stacks. Semi-open queuing networks (SOQNs) are built to estimate the system performance, which can handle both immediate and delayed reshuffling processes. We approximate the models by reduced SOQNs with two load-dependent service nodes and use the matrix-geometric method to solve them. Both simulations and a real case are used to validate the analytical models. Assuming a given number of stored products, our models can be used to optimize not only the length-to-width ratio of the system but also the stack height, depending on the storage strategy used. For a given inventory and optimal system configuration, we demonstrate that the dedicated storage policy outperforms the shared storage policy when the objective is to minimize dual command throughput time. However, from a cost perspective, with a maximum dual command throughput time as a constraint, we show that shared storage substantially outperforms dedicated storage. The annualized costs of dedicated storage are up to twice as large as those of shared storage, as a result of the larger number of storage positions required by dedicated storage and the relatively lower filling degree of storage stacks. The online appendix is available at https://doi.org/10.1287/trsc.2017.0786 ."
/doi/10.1287/mnsc.1110.1469," We study the impact of yield uncertainty (supply side) and self-interested consumers (demand side) on the inefficiency in the influenza vaccine supply chain. Previous economic studies, focusing on demand side, find that the equilibrium demand is always less than the socially optimal demand because self-interested individuals do not internalize the social benefit of protecting others via reduced infectiousness (positive externality). In contrast, we show that the equilibrium demand can be greater than the socially optimal demand after accounting for the limited supply due to yield uncertainty and manufacturer's incentives. The main driver for this result is a second (negative) externality: Self-interested individuals ignore that vaccinating people with high infection costs is more beneficial for the society when supply is limited. We show that the extent of the negative externality can be reduced through more efficient and less uncertain allocation mechanisms. To investigate the relative effectiveness of government interventions on supply and demand sides under various demand and supply characteristics, we construct two partially centralized scenarios where the social planner (i.e., government) intervenes either on the demand side or the supply side, but not both. We conduct an extensive numerical analysis. This paper was accepted by Yossi Aviv, operations management."
/doi/10.1287/trsc.2019.0915," We develop a numerical model using both artificial and empirical inputs to analyse taxi dynamics in an urban setting. More specifically, we quantify how the supply and demand for taxi services, the underlying road network, and the public acceptance of taxi ridesharing (TRS) affect the optimal number of taxis for a particular city and commuters’ average waiting time and trip time. Results reveal certain universal features of the taxi dynamics with real-time taxi booking: that there is a well-defined transition between the oversaturated phase when demand exceeds supply and the undersaturated phase when supply exceeds demand. The boundary between the two phases gives the optimal number of taxis a city should accommodate, given the specific demand, road network, and commuter habits. Adding or removing taxis may affect commuter experience very differently in the two phases revealed. In the oversaturated phase, the average waiting time is exponentially affected, whereas in the undersaturated phase it is affected sublinearly. We analyse various factors that can shift the phase boundary and show that an increased level of acceptance for TRS universally shifts the phase boundary by reducing the number of taxis needed. We discuss some of the useful insights for the benefits and costs of TRS, especially how, under certain situations, TRS not only economically benefits commuters but can also save the shared parties in overall travel time by significantly reducing the time commuters spend on waiting for taxis. Simulations also suggest that elementary artificial taxi systems can capture most of the universal features of the taxi dynamics. We give detailed methodologies of the microscopic simulations we employed. The relevance of the assumptions and the overall methodology are also illustrated using comprehensive empirical road network and taxi demand in the city-state of Singapore."
/doi/10.1287/mnsc.1070.0706," Research on industry life cycles suggests that competitive pressures are more severe during the shakeout stage, which could be associated with the emergence of a dominant design, than at other stages. Transaction-cost theory, on the other hand, assumes generally competitive markets and does not address the industry life cycle. It therefore implies that transaction-cost economizing is a superior firm strategy regardless of the stage of the life cycle. This paper seeks to reconcile these two streams of research by investigating whether aligning transactions with governance modes in accordance with transaction-cost prescriptions has a differential effect on firm survival in preshakeout versus shakeout stages of the industry life cycle. Analyzing data from the early U.S. auto industry (1917–1933), we find that while transaction misalignment did not have a significant impact on firm survival during the preshakeout stage or during the period as a whole, it did have a significantly larger negative impact on survival during the shakeout stage than during the preshakeout stage. We also find that the negative effects of misalignment on survival were significantly weaker for larger firms during the shakeout stage. This suggests that applications of transaction-cost theory which assume uniformly severe selection pressures across the industry life cycle and uniform effects of misalignment across firms of different sizes could be misleading. It also suggests that theories of the industry life cycle could usefully take transaction costs into account along with production costs in their analyses of competition over the life cycle."
/doi/10.1287/mnsc.2018.3199," When entering into a negotiation, individuals have the choice to enact a variety of communication styles. We test the differential impact of being “warm and friendly” versus “tough and firm” in a distributive negotiation when first offers are held constant and concession patterns are tracked. We train a natural language processing algorithm to precisely quantify the difference between how people enact warm and friendly versus tough and firm communication styles. We find that the two styles differ primarily in length and their expressions of politeness (Study 1). Negotiators with a tough and firm communication style achieved better economic outcomes than negotiators with a warm and friendly communication style in both a field experiment (Study 2) and a laboratory experiment (Study 3). This was driven by the fact that offers delivered in tough and firm language elicited more favorable counteroffers. We further find that the counterparts of warm and friendly versus tough and firm negotiators did not report different levels of satisfaction or enjoyment of their interactions (Study 3). Finally, we document that individuals’ lay beliefs are in direct opposition to our findings: participants believe that authors of warmly worded negotiation offers will be better liked and will achieve better economic outcomes (Study 4). This paper was accepted by Yuval Rottenstreich, judgment and decision making."
/doi/10.1287/mnsc.45.11.1479," The Virtual Design Team (VDT) extends and operationalizes Galbraith's (1973) information-processing view of organizations. VDT simulates the micro-level information processing, communication, and coordination behavior of participants in a project organization and predicts several measures of participant and project-level performance. VDT-1 (Cohen 1991) and VDT-2 (Christiansen 1993) modeled project organizations containing actors with perfectly congruent goals engaged in complex but routine engineering design work within static organization structures. VDT-3 extends the VDT-2 work process representation to include measures of activity flexibility, complexity, uncertainty, and interdependence strength. It explicitly models the effects of goal incongruency between agents on their information processing and communication behavior while executing more flexible tasks. These extensions allow VDT to model more flexible organizations executing less routine work processes. VDT thus bridges rigorously between cognitive and social psychological micro-organization theory and sociological and economic macro-organization theory for project teams. VDT-3 has been used to model and simulate the design of two major subsystems of a complex satellite launch vehicle. This case study provides initial evidence that the micro-contingency theory embodied in VDT-3 can be used to predict organizational breakdowns, and to evaluate alternative organizational changes to mitigate identified risks. VDT thus supports true “organizational engineering” for project teams."
/doi/10.1287/msom.1060.0097," We examine the competition between procurement auctions and long-term relational contracts that emerges from the increased usage of electronic marketplaces. Procurement auctions create supply chain efficiencies by selecting the least costly bidder, and long-term relational contracts ensure the quality of the procured products or services when these have nonverifiable attributes. The following two-layer supply chain model is analyzed: Suppliers of an industrial part with nonverifiable quality trade with several manufacturers that utilize that part in the production of an end product. A price-based reverse auction is used for the procurement of low-quality parts, and a relational long-term contract is used for high-quality parts. A formal model of the competition between the two procurement models identifies conditions under which the two coexist, and conditions under which one will push the other out of the market. Market and product parameters that increase the relative economic appeal of the relational contract are determined. It is demonstrated that the competition from the auction market can either facilitate or undermine the relational contract compared with a benchmark case of a monopolist supplier. This implies that competition between the two procurement models plays an important role in the supply of high-quality products."
/doi/10.1287/isre.1110.0384," In this study, we examine how consumers respond to firms' use of two types of information for personalization: product preferences and name. We collect a unique data set of over 10 million e-mail advertisements sent by a website to over 600,000 customers who could buy the advertised products from the online merchant. We estimate a two-stage hierarchical model using Bayesian analysis to account for observable and unobservable consumer heterogeneity. Our analysis suggests several interesting results regarding consumers' responses to firms' use of information. When firms use product-based personalization (where the use of information is not explicitly mentioned), consumers respond positively. On the other hand, consumers respond negatively when firms are explicit in their use of personally identifiable information (i.e., a personalized greeting). We also find that negative responses to personalized greetings are moderated by consumers' familiarity with firms. The main contribution of this study is that it not only indicates the economic benefits of personalization in e-mails but also highlights consumers' concerns over the use of information in personalization."
/doi/10.1287/mnsc.2019.3324," We construct an event-based outcome measure of firm-level environmental, social, and governance (ESG) impact for public and private firms globally from 2007 to 2015 using data from RepRisk. Then we measure the societal impact of corporate social responsibility (CSR) engagements using participation in the United Nations Global Compact (UNGC) as a proxy. We demonstrate a robust and striking difference between public and private firms: whereas private firms significantly reduce their negative ESG incident levels after UNGC engagements, public firms fail to do so and are more likely to engage in decoupled CSR actions—actions with no subsequent real impact. We then conduct a series of in-depth analyses to examine possible economic mechanisms. Our results are most consistent with shareholder–stakeholder conflicts of interest being the main moderator of decoupling. The intensity of this conflict is further moderated by three factors: ownership type, proximity to final consumers on the value chain, and specific ESG incident types. Other possible mechanisms, such as selective entry into UNGC and heterogeneities in media exposure, country representation, and entry timing, do not survive our analysis. Our results suggest that existing CSR engagements and one-size-fits-all CSR policy mandates might not necessarily lead to better societal outcomes, and a multi-tiered policy targeting different ownership and industry types might be more efficient at maximizing ex post ESG benefits."
/doi/10.1287/orsc.8.1.23," Computer networks are an increasingly important technology for improving the efficiency of information processing and providing shared access to information resources. Because computer networks are increasingly being used to support the flow of information between and within organizations, their use both influences and has consequences for interorganizational relationships. An important and widespread application of interorganizational computer networks is Electronic Data Interchange (EDI), which refers to the computer-based exchange of standardized business-related information between buyer and supplier firms. The following theoretical framework addresses the role that power and trust play in EDI adoption and use. Firms with greater power can influence their trading partners to adopt EDI. But power can be exercised in different ways. Because computer networks provide a way for certain information to be more accessible to outside parties, their use makes organizational boundaries more permeable. When firms use coercive power to force trading partners to adopt EDI, less powerful partners may be left more vulnerable. And, over time this perceived vulnerability becomes a constraint in interorganizational relationships that prevents improvements in coordination through expanded use of EDI. On the other hand, when the event of EDI adoption is viewed as an opportunity to build and reinforce trust between firms, the relationship is able to support organizational changes (e.g., restructuring operational processes or new modes of distribution) related to EDI use which contribute to improving interorganizational coordination. The role of power and trust in EDI adoption has important implications for interorganizational theory. Their role may be especially helpful in understanding how technology, and, in particular, electronic media support strategic alliances that firms create to advance mutual goals."
/doi/10.1287/msom.1090.0282," We study a profit-maximizing firm providing a service to price and delay sensitive customers. We are interested in analyzing the scale economies inherent in such a system. In particular, we study how the firm's pricing and capacity decisions change as the scale, measured by the potential market for the service, increases. These decisions turn out to depend intricately on the form of the delay costs seen by the customers; we characterize these decisions up to the dominant order in the scale for both convex and concave delay costs. We show that when serving customers on a first-come, first-served basis, if the customers' delay costs are strictly convex, the firm can increase its utilization and extract profits beyond what it can do when customers' delay costs are linear. However, with concave delay costs, the firm is forced to decrease its utilization and makes less profit than in the linear case. While studying concave delay costs, we demonstrate that these decisions depend on the scheduling policy employed as well. We show that employing the last-come, first-served rule in the concave case results in utilization and profit similar to the linear case, regardless of the actual form of the delay costs."
/doi/10.1287/mnsc.2020.3586," Platform businesses are typically resource-intensive and must scale up their business quickly in the early stage to compete successfully against fast-emerging rivals. We study a critical question faced by such firms in the novel context of multicategory two-sided platforms: how to optimally make investment decisions across two sides, multiple categories, and different time periods to achieve fast and sustainable growth. We first develop a two-category two-period theoretical model and propose optimal resource allocation strategies that account for heterogeneous within-category direct and indirect network effects and cross-category interdependence. We find that the proposed strategy shares the spirit of the allocation rules for multiproduct nonplatform firms and single-product platform firms, yet it does not amount to a simple combination of the existing rules. Interestingly, the business model that platforms adopt crucially determines the optimal strategy. Platforms that charge by user should adopt a “reinforcing” rule for both within- and cross-category allocations by allocating more resources toward the stronger growth driver. Platforms that charge by transaction should also adopt the reinforcing rule for within-category allocation, but follow a “compensatory” rule for cross-category and intertemporal allocations by allocating more resources toward the weaker growth driver. We use data from the daily deals industry to empirically identify the network effects, propose alternative allocation strategies stemming from our theoretical findings, and use simulations to show the benefits of these strategies. For instance, we show that reallocating 10% of the average observed investment from Fitness to Beauty can increase profits by up to 15.5% for some cities. This paper was accepted by Matthew Shum, marketing."
/doi/10.1287/orsc.2018.1215," The relationship between slack resources and innovation is complex, with the literature linking slack to both breakthrough innovations and resource misallocation. We reconcile these conflicting views by focusing on a novel mechanism: the role slack time plays in the endogenous allocation of time and effort to innovative projects. We develop a theoretical model that distinguishes between periods of high- (work weeks) versus low- (break weeks) opportunity costs of time. Low-opportunity cost time during break weeks may induce (1) lower quality ideas to be developed (a selection effect); (2) more effort to be applied for any given idea quality (an effort effect); and (3) an increase in the use of teams because scheduling is less constrained (a coordination effect). As a result, the effect of an increase in slack time on innovative outcomes is ambiguous, because the selection effect may induce more low-quality ideas, whereas the effort and coordination effect may lead to more high-quality, complex ideas. We test this framework using data on college breaks and on 165,410 Kickstarter projects across the United States. Consistent with our predictions, during university breaks, more projects are posted in the focal regions, and the increase is largest for projects of either very high or very low quality. Furthermore, projects posted during breaks are more complex, and involve larger teams with diverse skills. We discuss the implications for the design of policies on slack time. The online appendices are available at https://doi.org/10.1287/orsc.2018.1215 ."
/doi/10.1287/isre.2018.0810," To benefit from the wisdom of the crowd in ideation contests, seekers should understand how their involvement affects solvers’ ideation and the ensuing ideas. This present study addresses this need by examining the antecedents and consequences of solvers’ exemplar adoption (i.e., use of solution exemplars that the seekers provide) in such contests. We theorize how the characteristics of seekers’ exemplars (specifically, quantity and variability) and prizes jointly influence exemplar adoption. We also consider how exemplar adoption affects the effectiveness of the resulting ideas, conditional on solvers’ experience with the problem domain of the contests. The results from a company naming contest and an ad design contest show that exemplar quantity and exemplar variability both positively affect exemplar adoption, but the effects are strengthened and attenuated, respectively, by prize attractiveness. The outcomes of a campaign using the ads from the design contest further show that greater exemplar adoption improves ad effectiveness (in terms of click-through performance) although this is negatively moderated by solvers’ domain experience. We discuss the theoretical and practical contributions of this research to ideation contests. The online appendix is available at https://doi.org/10.1287/isre.2018.0810 ."
/doi/10.1287/mnsc.17.10.B658," Persuaded that management information systems will help them achieve efficiency of operation and attain organizational goals, public planners, like those in the private sector, are eagerly embarking on ambitious feasibility studies and contracting for elaborate hardware and software systems. Since this effort is being undertaken in the service of the public, it is important to assess the social costs and benefits. The research focus of the work on which this paper is based is on information systems as entities in themselves and as components of a larger systems design. After analyzing the three discretely defined but operationally joined concepts, information, system , and the information system , we examine the four assumptions underlying the general acceptance of the information system as a management tool: (1) that more information leads to better plans or decisions; (2) that more and faster-moving information necessarily enhances “efficiency” of operation; (3) that greater “efficiency” is identical with better public service; and (4) that information systems are best conceived, designed, and controlled by “information experts,” whose talents are movable and ubiquitous. Information systems in public welfare, criminal justice, and land use are reviewed as cases in point, and the conclusion drawn that while there is no gainsaying the fact that in each area a body of organized information is essential to systematic analysis and planning, there exists considerable confusion between quantity and quality, between the necessary and the busy. So far, there is a lack of clarification not only as to the proper constitution of the information system but also about the qualifications of the “experts” designing them. Unfortunate as these matters are in raising the costs and lowering the benefits (economic and social, as well), they have ominous implications when viewed in the light of the many-fronted encroachments by computerized information systems on individuals' right to privacy. The data bank and the dossier may be rationalized as means to efficiency, but they cannot be reconciled with democratic process and freedom from cradle-to-grave surveillance."
/doi/10.1287/orsc.2018.1244," We develop and test a model that extends the understanding of how people react to news of organizational unethical behavior and how such reactions impact stock performance. We do so by taking into account the interplay between the features of specific unethical acts and the features of the organizational context within which unethical acts occur. We propose a two-stage model in which the first stage predicts that unethical acts that benefit the organization are judged less harshly than are unethical acts that benefit the actor, when the organization is seen as pursuing a moral goal (e.g., producing inexpensive medicine rather than tobacco products). In such cases, the motives behind the unethical act are construed as an individual’s intentions to pursue a moral end. The second stage of our model connects moral judgment to action against the organization as a whole. We propose that moral judgments of an unethical act are more likely to translate into negative economic consequences for the organization when the unethical act is seen as benefiting the organization, because in such cases the organization is construed as an accomplice. Study 1 is an event study of stock market reactions to organizational unethical behavior in which the features of organizational unethical behavior were operationalized by coding media coverage of unethical acts. Study 2 is an experiment that used news stories to manipulate features of unethical behavior and measured participants’ estimates of stock performance, while incentivizing participants for accuracy. Both studies found support for our model. The online appendix is available at https://doi.org/10.1287/orsc.2018.1244 ."
/doi/10.1287/mnsc.49.11.1546.20582," Web-based group-buying mechanisms are being widely used for both business-to-business (B2B) and business-to-consumer (B2C) transactions. We survey currently operational online group-buying markets, and then study this phenomenon using analytical models. We build on the literatures in information economics and operations management in our analytical model of a monopolist offering Web-based group-buying under different kinds of demand uncertainty. We derive the monopolist's optimal group-buying schedule under varying conditions of heterogeneity in the demand regimes, and compare its profits with those that obtain under the more conventional posted-price mechanism. We further study the impact of production postponement by endogenizing the timing of the pricing and production decisions in a two-stage game between the monopolist and buyers. Our results have implications for firms' choice of price-discovery mechanisms in e-markets, and for the scheduling of production and pricing decisions in the presence (and absence) of scale economies of production."
/doi/10.1287/mnsc.1100.1239," Why do firms exist? What is their function? What do managers do? What is the role, if any, of social motivation in the market? In this paper, we address these questions with a new theory of the firm, which unites some major themes in management, principal-agent theory, and economic sociology. We show that although the market is a superior incentive mechanism, the firm has a comparative advantage with respect to social motivation. We then show that the market is efficient in environments that favor the provision of incentives, such as when subjective risk is low and performance is easy to measure. The firm is efficient in other environments where incentives are costly and/or ineffective. We compare our model and results with the views of Durkheim (Durkheim, E. 1984. The Division of Labor in Society . Free Press, New York) and Granovetter (Granovetter, M. 1985. Economic action and social structure: The problem of embeddedness. Amer. J. Sociol . 91 (3) 481–510)."
/doi/10.1287/mnsc.1090.1125," Companies in a variety of industries (e.g., airlines, hotels, theaters) often use last-minute sales to dispose of unsold capacity. Although this may generate incremental revenues in the short term, the long-term consequences of such a strategy are not immediately obvious: More discounted last-minute tickets may lead to more consumers anticipating the discount and delaying the purchase rather than buying at the regular (higher) prices, hence potentially reducing revenues for the company. To mitigate such behavior, many service providers have turned to opaque intermediaries, such as Hotwire.com, that hide many descriptive attributes of the service (e.g., departure times for airline tickets) so that the buyer cannot fully predict the ultimate service provider. Using a stylized economic model, this paper attempts to explain and compare the benefits of last-minute sales directly to consumers versus through an opaque intermediary. We utilize the notion of rational expectations to model consumer purchasing decisions: Consumers make early purchase decisions based on expectations regarding future availability, and these expectations are correct in equilibrium. We show that direct last-minute sales are preferred over selling through an opaque intermediary when consumer valuations for travel are high or there is little service differentiation between competing service providers, or both; otherwise, opaque selling dominates. Moreover, contrary to the usual belief that such sales are purely mechanisms for disposal of unused capacity, we show that opaque selling becomes more preferred over direct last-minute selling as the probability of having high demand increases. When firms randomize between opaque selling and last-minute selling strategies, they are increasingly likely to choose the opaque selling strategy as the probability of high demand increases. When firms with unequal capacities use the opaque selling strategy, consumers know more clearly where the opaque ticket is from and the efficacy of opaque selling decreases."
/doi/10.1287/mnsc.2020.3823," Diversification is a basic economic principle that helps to hedge against uncertainty. It is, therefore, intuitive that both risk aversion and ambiguity aversion should positively affect the value of diversification. In this paper, we show that this intuition (1) is true for risk aversion but (2) is not necessarily true for ambiguity aversion. We derive sufficient conditions, showing that, contrary to the economic intuition, ambiguity and ambiguity aversion may actually reduce the diversification value. This paper was accepted by Manel Baucells, decision analysis."
/doi/10.1287/isre.2018.0813," The 2009 Health Information Technology for Economic and Clinical Health (HITECH) Act is landmark legislation that places electronic health record (EHR) technologies at the center of health system reform in the United States. However, despite their promises, studies in the EHR evaluation literature have found mixed evidence of EHRs’ quality benefits. In contrast to existing research that has focused on EHR investments or adoption, we propose that its actual use should be the focus in evaluating the advantages of EHRs. We leveraged the meaningful use (MU) provisions of the HITECH Act to quantify different degrees of EHR use in a large and heterogeneous set of hospitals. The results provided evidence of EHRs’ positive effects on quality of care and reconciled earlier mixed findings by showing that their benefits vary according to different levels of use and hospital characteristics. Specifically, we found that, although adopting EHRs had no significant quality impact, attaining MU of EHRs yielded a significant 0.19–0.43 percentage point increase in process quality of care, which further translates into significant societal benefits. The effect sizes were larger in disadvantaged (i.e., small and rural) hospitals, suggesting the potential of EHRs in mitigating the disparities in the quality of healthcare. This study contributes to this ongoing discussion and the literature on EHR evaluations and use of information systems. Implications for research, policy, and practice are discussed. The online appendices are available at https://doi.org/10.1287/isre.2018.0813 ."
/doi/10.1287/mnsc.1090.1006," We study a dynamic asset allocation problem in which stock returns exhibit short-run momentum and long-run mean reversion. We develop a tractable continuous-time model that captures these two predictability features and derive the optimal investment strategy in closed form. The model predicts negative hedging demands for medium-term investors, and an allocation to stocks that is nonmonotonic in the investor's horizon. Momentum substantially increases the economic value of hedging time variation in investment opportunities. These utility gains are preserved when we impose realistic borrowing and short-sales constraints and allow the investor to trade on a monthly frequency."
/doi/10.1287/inte.33.3.24.16009," Supply-chain management has become a prominent area for teaching and research. Academics and managers realize that communication and coordination among members of a supply chain enhance its effectiveness, creating financial benefits to be shared by the members. We have collected numerical examples covering (1) location decisions, (2) centralized warehousing, (3) lot sizing with deterministic demand, (4) demand forecasting, (5) pricing, and (6) lot sizing with stochastic demand in a newsvendor environment. The examples are suitable for classroom use, and they illuminate the rewards supply-chain members can obtain by eliminating naturally occurring supply-chain inefficiencies and the costs of not doing so."
/doi/10.1287/inte.2015.0808," We developed an innovative technology that uses analytics to promote sustainability as a central purchase consideration for organizations with large fleets of vehicles. Working with Ford’s fleet customers over the past several years, we witnessed their strong and increasing desire to adopt greener vehicle technologies, and their unmet need to financially justify the higher initial investment costs associated with adopting those more fuel-efficient technologies. We responded by developing the Ford Fleet Purchase Planner ™ —a set of tools that begin with simple calculators and gradually transition to highly precise full-fleet optimization tools. These tools enable fleet customers to invest strategically in greener vehicles."
/doi/10.1287/mnsc.46.2.217.11923," Vendor-managed inventory (VMI) is a supply-chain initiative where the supplier is authorized to manage inventories of agreed-upon stock-keeping units at retail locations. The benefits of VMI are well recognized by successful retail businesses such as Wal-Mart. In VMI, distortion of demand information (known as bullwhip effect) transferred from the downstream supply-chain member (e.g., retailer) to the upstream member (e.g., supplier) is minimized, stockout situations are less frequent, and inventory-carrying costs are reduced. Furthermore, a VMI supplier has the liberty of controlling the downstream resupply decisions rather than filling orders as they are placed. Thus, the approach offers a framework for synchronizing inventory and transportation decisions. In this paper, we present an analytical model for coordinating inventory and transportation decisions in VMI systems. Although the coordination of inventory and transportation has been addressed in the literature, our particular problem has not been explored previously. Specifically, we consider a vendor realizing a sequence of random demands from a group of retailers located in a given geographical region. Ideally, these demands should be shipped immediately. However, the vendor has the autonomy of holding small orders until an agreeable dispatch time with the expectation that an economical consolidated dispatch quantity accumulates. As a result, the actual inventory requirements at the vendor are partly dictated by the parameters of the shipment-release policy in use. We compute the optimum replenishment quantity and dispatch frequency simultaneously. We develop a renewaltheoretic model for the case of Poisson demands, and present analytical results."
/doi/10.1287/mnsc.11.4.B48," Two major aspects of the difficulty of implementing O.R. results are described: first, the difficulty in assessing the cost of implementation; and secondly, difficulties in successful performance of this phase. It is argued that O.R. should be approached as a continuum of effort, starting with basic research and leading up to implementation or development. This process is described as the Operations Research and Development Process. A procedure for establishing an OR&D program and criteria for initial project selection are described. It is suggested that the projects making up a program, in OR&D be packaged and scrutinized regularly for their contributions to the objectives of the organization. It is stated that such an approach will increase the utility and effectiveness of operations research without destroying its research nature. Further, procedures for developing an operations research program and pre-planning the implementation phase exist and can be applied. It is suggested that the ability to effectively implement operations research results may have a most important bearing on our national economic well-being, as well as on the competitive position of individual industrial organizations. It is suggested that the O.R. group and individuals that face up to the challenge of defining a program through the implementation phase, securing management's continuing review and participation in defining and supporting the OR&D program, will find that a greater percentage of projects will produce meaningful results."
/doi/10.1287/mnsc.1070.0763," The people living and working around the roads used for hazardous material (hazmat) shipments face the risk of suffering undesirable consequences of an accident. The main responsibility to mitigate the hazmat transport risk at a population zone belongs to the government agency with jurisdiction over that region. One of the common policy tools is to close certain road links to vehicles carrying hazmats. In effect, the road network available to dangerous goods carriers can be determined by the regulator. The transport risk in the region, however, is determined by the carriers' routing decisions over the available road network. Thus, the regulator needs to make the road closure decisions so that the total risk resulting from the carriers' route choices is minimized. We provide a path-based formulation for this network design problem. Alternative solutions can be generated by varying the routing options included in the model for each shipment. Each solution corresponds to a certain compromise between the two parties in terms of transport risk and economic viability. The proposed framework can be used for identifying mutually agreeable hazmat transport policies. We present two applications of the methodology to illustrate the insights that can be gained through its use: The first application focuses on hazmat shipments through the highway network of Western Ontario, Canada, whereas the second application studies the problem in a much larger geographical region that covers the provinces of Ontario and Quebec."
/doi/10.1287/orsc.13.6.601.499," Drawing on neoclassical economic, internal labor market, and devaluation theories, we examine how the sex composition of jobs and the sex of individual workers affect earnings, depending upon the formalization of the pay type. Using personnel data for over 8,000 employees, we confirm the existence of a negative relationship between earnings and the proportion female in a job. We also find that for less-formalized pay types (cash incentive bonuses), sex-composition and individual-sex effects are larger than for more formalized pay (merit raises and base salary). Together, these findings support devaluation explanations, suggest that incentive bonuses may widen the earnings gap between women and men, and have implications for the design of pay structures in organizations."
/doi/10.1287/deca.2015.0312," We experimentally examined the relationships between the measurable value and utility functions of a nonmonetary multidimensional decision situation for a number of subjects. We found that value and utility were not equivalent constructs. We tested five families of functions and found the sigmoid function performed best as a transform from value to utility. Constant relative risk aversion was not observed. The methods of probability equivalent and certainty equivalent utility elicitation provided similar results, which differs from previous work using economic decisions."
/doi/10.1287/inte.1120.0659," Intel Corporation spends over $5 billion annually on manufacturing equipment. With increasing lead times from equipment suppliers and increasing complexity in forecasting market demand, optimizing capital investment decisions is a significant managerial challenge. In response to this challenge, we developed a capital supply chain velocity program for ordering, shipping, and installing production equipment. At the core of this velocity program is a new and additional procurement framework that enables Intel to purchase options from its equipment suppliers for a faster delivery of some equipment. The framework seamlessly combines statistical forecasting with Monte Carlo simulation and stochastic programming to determine the number of options Intel should procure and exercise, and it includes built-in scenario and sensitivity analysis capabilities to support Intel’s contract selection, options reservation, and equipment procurement decisions. The velocity program and the framework provided Intel with hundreds of millions of dollars in cost savings and at least $2 billion in revenue upside during a recent period of global economic crisis."
/doi/10.1287/mnsc.45.7.980," Stochastic Economic Lot Scheduling Problems (ELSPs) involve settings where several items need to be produced in a common facility with limited capacity, under significant uncertainty regarding demands, unit production times, setup times, or combinations thereof. We consider systems where some products are made-to-stock while another product line is made-to-order. We present a rich and effective class of strategies for which a variety of cost and performance measures can be evaluated and optimized efficiently by analytical methods. These include inventory level and waiting-time distributions, as well as average setup, holding, and backlogging costs. We also characterize how strategy choices are affected by the system parameters. The availability of efficient analytical evaluation and optimization methods permits us to address the impact of product line diversification or standardization on the performance of the manufacturing system, in particular the logistical implications of adding low-volume specialized models to a given make-to-stock product line."
/doi/10.1287/mnsc.2018.3241," The underrepresentation of minorities in cultural industries is a widely publicized problem with far-reaching economic and social significance. It is also one of many industries in which employers suggest that the locus of bias is not within the organization but with the consumer. The empirical challenge of relating consumer behavior to employee composition has constrained prior efforts to test their claim and to test the theory of consumer discrimination more broadly. As a result, employers have gradually expanded the scope of the customer discrimination theory from one rooted in direct interaction to include an aversion to simply seeing employees of a different ethnicity. We explore how consumers respond to employee composition by evaluating the performance of films released in the United States as a function of the racial diversity of their cast. We find that films with a single black actor do not differ from those with zero black actors, and that films with multiple black actors in the principal cast actually achieve significantly higher domestic box-office revenues than either. To distinguish between competing explanations for this result, we conduct a vignette-based experiment that allows us to identify a positive influence of diversity on consumers’ assessments of quality, controlling for differences in film or actor appeal. Collectively, these results help discredit one rationale for unequal hiring in cultural industries and also suggest an important qualification to the theory of consumer discrimination: in settings where employee race is visible but the consumer is physically distant, diversity is more profitable than costly. This paper was accepted by Greta Hsu, organizations."
/doi/10.1287/orsc.2016.1072," This paper addresses why customers at times prefer traditional practices deemed more authentic to a domain, particularly where these practices had previously been discarded as inferior. I argue that customer demand for authenticity can be triggered when extrinsic rewards (i.e., fame or money) increase in prominence in a market, causing audiences to doubt the motives of the market’s producers. I examine this dynamic in the context of Major League Baseball, where appreciation for traditional stadium features seemingly arose after the advent of free agency heightened awareness and coverage of the economic rewards in the sport. Experimental analysis validates the proposed mechanism, whereby increased fan exposure to extrinsic rewards increases concern about player inauthenticity, which increases preference for traditional stadium features. Quantitative analysis of attendance patterns provides external validation for these experimental findings by showing that authenticity was more highly preferred, in the form of higher relative attendance in traditional-style ballparks, by those fans more exposed to free agency. Conclusions are drawn about the role that perceptions about motives play in market perceptions of authenticity and valuation of authentic cultural objects."
/doi/10.1287/moor.2021.1136," We derive new prox-functions on the simplex from additive random utility models of discrete choice. They are convex conjugates of the corresponding surplus functions. In particular, we explicitly derive the convexity parameter of discrete choice prox-functions associated with generalized extreme value models, and specifically with generalized nested logit models. Incorporated into subgradient schemes, discrete choice prox-functions lead to a probabilistic interpretations of the iteration steps. As illustration, we discuss an economic application of discrete choice prox-functions in consumer theory. The dual averaging scheme from convex programming adjusts demand within a consumption cycle."
/doi/10.1287/opre.2017.1592," In this paper, we investigate the optimal dynamic auction design for the display advertising industry. Currently, display advertising is sold through two markets side by side. In the traditional guaranteed market, the publisher commits to deliver a prespecified number of impressions within a fixed time frame through a guaranteed contract. In the spot market, the publisher runs an auction to allocate the impressions every period, and the supply of heterogeneous impressions is highly uncertain and nonstorable. Thus, the publisher must solve a dynamic capacity allocation problem of heterogeneous impressions across different contracts and markets, taking into account the uncertainties from both the demand and supply sides. We characterize the precise trade-offs between extracting the revenue from the spot markets, materializing the instantaneous benefit shared with the guaranteed advertisers, and releasing the pressure of paying the penalty related to guaranteed contracts. Furthermore, we identify the dual role of the publisher as a system designer and as a bidder on behalf of the guaranteed advertisers. With heterogeneous due dates of guaranteed contracts, we demonstrate the inherent scheduling issue embedded in this dynamic revenue management problem, and completely solve the joint scheduling and capacity allocation problem for some special cases. The online appendix is available at https://doi.org/10.1287/opre.2017.1592 ."
/doi/10.1287/mnsc.2017.2756," Online labor marketplaces facilitate the efficient matching of employers and workers across geographical boundaries. The exponential growth of this nascent online phenomenon holds important social and economic implications, as the hiring decisions made on these online platforms implicate the incomes of millions of workers worldwide. Despite this importance, limited effort has been devoted to understanding whether potential hiring biases exist in online labor platforms and how they may affect hiring outcomes. Using a novel proprietary data set from a leading online labor platform, we investigate the impact of gender-based stereotypes on hiring outcomes. After accounting for endogeneity via a holistic set of job and worker controls, a matched sample approach, and a quasi-experimental technique, we find evidence of a positive hiring bias in favor of female workers. An experiment was used to uncover the underlying gender-specific traits that could influence hiring outcomes. We find that the observed hiring bias diminishes as employers gain more hiring experience on the platform. In addition, the female hiring bias appears to stem solely from the consideration of applicants from developing countries, and not those from developed countries. Subanalyses show that women are preferred in feminine-typed occupations while men do not enjoy higher hiring likelihoods in masculine-typed occupations. We also find that female employers are more susceptible to the female hiring bias compared to male employers. Our findings provide key insights for several groups of stakeholders including policy makers, platform owners, hiring managers, and workers. Managerial and practical implications are discussed. The online appendix is available at https://doi.org/10.1287/mnsc.2017.2756 . This paper was accepted by Chris Forman, information systems."
/doi/10.1287/mksc.1080.0440," Prior marketing literature has overlooked the role of regulatory regimes in explaining international sales growth of new products. This paper addresses this gap in the context of new pharmaceuticals (15 new molecules in 34 countries) and sheds light on the effects of regulatory regimes on new drug sales across the globe. Based on a time-varying coefficient model, we find that differences in regulation substantially contribute to cross-country variation in sales. One of the regulatory constraints investigated, i.e., manufacturer price controls, has a positive effect on drug sales. The other forms of regulation such as restrictions of physician prescription budgets and the prohibition of direct-to-consumer advertising (DTCA) tend to hurt sales. The effect of manufacturer price controls is similar for newly launched and mature drugs. By contrast, regulations on physician prescription budgets and DTCA have a differential effect for newly launched and mature drugs. Whereas the former hurts mature drugs more, the latter has a larger effect on newly launched drugs. In addition to these regulatory effects, we find that national culture, economic wealth, and lagged sales also affect drug sales. Our findings may be used as input by managers for international launch and marketing decisions. They may also be used by public policy administrators to assess the role of regulatory regimes in pharmaceutical sales growth."
/doi/10.1287/mksc.20.1.42.10196," In a competitive marketplace, the effectiveness of any element of the marketing mix is determined not only by its absolute value, but also by its relative value with respect to the competition. For example, the effectiveness of a price cut in increasing demand is critically related to competitors' reaction to the price change. Managers therefore need to know the nature of competitive interactions among firms. In this paper, we take a theory-driven empirical approach to gain a deeper understanding of the competitive pricing behavior in the U.S. auto market. The ability-motivation paradigm posits that a firm needs both the ability and the motivation to succeed in implementing a strategy (Boulding and Staelin 1995). We use arguments from the game-theoretic literature to understand firm motivation and abilities in different segments of the auto market. We then combine these insights from the game-theoretic literature and the ability-motivation paradigm to develop hypotheses about competition in different segments of the U.S. auto market. To test our hypotheses of competitive behavior, we estimate a structural model that disentangles the competition effect from the demand and cost effects on prices. The theory of repeated games predicts that firms with a long-run profitability objective will try to sustain cooperative pricing behavior as a stable equilibrium when conditions permit. For example, markets with high concentration and stable market environments are favorable for sustaining cooperative behavior and therefore provide firms with the ability to cooperate. The theory of switching costs suggests that in markets in which a firm's current customers tend to be loyal, firms have a motivation to compete very aggressively for new customers, recognizing the positive benefits of loyalty from the customer base in the long run. As consumer loyalty in the market increases, the gains from increasing market share by means of aggressive competitive behavior are more than offset by losses in profit margins. Firms therefore have the motivation to price cooperatively. Empirically, we find aggressive behavior in the minicom-pact and subcompact segments, cooperative behavior in the compact and midsize segments, and Bertrand behavior in the full-size segment. These findings are consistent with our theory-based hypotheses about competition in different segments. In estimating a structural model of the auto market, we address several methodological issues. A particular difficulty is the large number of car models in the U.S. auto market. Existing studies have inferred competitive behavior only in markets with two to four products. They also use relatively simple functional forms of demand to facilitate easy estimation. Functional forms of demand, however, impose structure on cross-elasticities between products. Such structure, when inappropriate, can bias the estimates of competitive interaction. We therefore use the random coefficients logit demand model to allow flexibility in cross-elasticities. We also use recent advances in New Empirical Industrial Organization (NEIO) to extend structural estimation of competitive behavior to markets with a large number of products. We use the simulation-based estimation approach developed by Berry et al. (1995) to estimate our model. A frequent criticism of the NEIO approach is that its focus on industry-specific studies limits the generalizability of its findings. In this study, we retain the advantages of NEIO methods but partially address the issue of generalizability by analyzing competitive behavior in multiple segments within the auto industry to see whether there is a consistent pattern that can be explained by theory. Theoretical modelers can use our results to judge the appropriateness of their models in predicting competitive outcomes for the markets that they analyze. A by-product of our analysis is that we also get estimates of demand and cost apart from competitive interactions for the market. Managers can use these estimates to perform “what-if” analysis. They can answer questions about what prices to charge when a new product is introduced or when an existing product's characteristics are changed."
/doi/10.1287/mnsc.2015.2358," In some strategic alliances, a firm shares its manufacturing capacity with another, and the latter shares its distribution capacity with the former. Even though such bidirectional alliances have become more common, they remain challenging to manage because of the frequent disputes over capacity allocation, especially when demand is uncertain. In this paper, we investigate whether there exists a contractual mechanism that can mitigate the extent of these disputes while improving the profits of all participating firms. We consider two types of bidirectional contracts, namely, the ex post transfer payment contract and the ex ante capacity reservation contract . By modeling the capacity allocation and the bidirectional contract design as a noncooperative game between two firms with noncompeting product lines, we show that, relative to a situation with no contract, either contract can improve the alliance’s total profit in equilibrium. In terms of distribution of the total surplus, we find that capacity reservation contracts always make both firms better off, whereas ex post transfer payment contracts may make one firm worse off. Hence, capacity reservation contracts are more likely to be implemented in practice in such bidirectional alliances. This paper was accepted by Gad Allon, operations management ."
/doi/10.1287/mnsc.1100.1220," Successfully predicting that something will become a big hit seems impressive. Managers and entrepreneurs who have made successful predictions and have invested money on this basis are promoted, become rich, and may end up on the cover of business magazines. In this paper, we show that an accurate prediction about such an extreme event, e.g., a big hit, may in fact be an indication of poor rather than good forecasting ability. We first demonstrate how this conclusion can be derived from a formal model of forecasting. We then illustrate that the basic result is consistent with data from two lab experiments as well as field data on professional forecasts from the Wall Street Journal Survey of Economic Forecasts."
/doi/10.1287/isre.1070.0151," Iterative combinatorial auctions (ICAs) are IT-based economic mechanisms where bidders submit bundle bids in a sequence and an auctioneer computes allocations and ask prices in each auction round. The literature in this field provides equilibrium analysis for ICAs with nonlinear personalized prices under strong assumptions on bidders' strategies. Linear pricing has performed very well in the lab and in the field. In this paper, we compare three selected linear price ICA formats based on allocative efficiency and revenue distribution using different bidding strategies and bidder valuations. The goal of this research is to benchmark different ICA formats and design and analyze new auction rules for auctions with pseudodual linear prices. The multi-item and discrete nature of linear price iterative combinatorial auctions and the complex price calculation schemes defy much of the traditional game theoretical analysis in this field. Computational methods can be of great help in exploring potential auction designs and analyzing the virtues of various design options. In our simulations, we found that ICA designs with linear prices performed very well for different valuation models even in cases of high synergies among the valuations. There were, however, significant differences in efficiency and in the revenue distributions of the three ICA formats. Heuristic bidding strategies using only a few of the best bundles also led to high levels of efficiency. We have also identified a number of auction rules for ask price calculation and auction termination that have shown to perform very well in the simulations."
/doi/10.1287/opre.1060.0379," We study a new class of decentralized algorithms for discrete optimization via simulation, which is inspired by the fictitious play algorithm applied to games with identical interests. In this approach, each component of the solution vector of the optimization model is artificially assumed to have a corresponding “player,” and the interaction of these players in simulation allows for exploration of the solution space and, for some problems, ultimately results in the identification of the optimal solution. Our algorithms also allow for correlation in players’ decision making, a key feature when simulation output is shared by multiple decision makers. We first establish convergence under finite sampling to equilibrium solutions. In addition, in the context of discrete network flow models, we prove that if the underlying link cost functions are convex, then our algorithms converge almost surely to an optimal solution."
/doi/10.1287/mnsc.2015.2225," We study how leader compensation affects public goods provision. We report from a lab experiment with four treatments, where the base treatment was a standard public goods game with simultaneous contribution decisions, and the three other treatments allowed participants to volunteer to be the leader in their group and make their contribution before the others. In the three leader treatments, we manipulated the level of compensation given to the leader. Our main finding is that a moderate compensation to the leader is beneficial; it increases the average contribution relative to both a situation where the leader is not compensated and a situation without a leader. A further increase in the leader compensation, however, is detrimental to public goods provision; it attracts more free riders and creates a social crowding-out effect. Finally, we report from a survey showing that the social crowding-out effect is also present in the population at large. We argue that the main findings of the paper are important in many real-life settings where we would like to use economic incentives to encourage people to lead by example. This paper was accepted by Uri Gneezy, behavioral economics ."
/doi/10.1287/mnsc.48.10.1350.272," Consumer reservation price is a key concept in marketing and economics. Theoretically, this concept has been instrumental in studying consumer purchase decisions,competitive pricing strategies,and welfare economics. Managerially,knowledge of consumer reservation prices is critical for implementing many pricing tactics such as bundling,tar get promotions,nonlinear pricing,and one-to-one pricing,and for assessing the impact of marketing strategy on demand. Despite the practical and theoretical importance of this concept, its measurement at the individual level in a practical setting proves elusive. We propose a conjoint-based approach to estimate consumer-level reservation prices. This approach integrates the preference estimation of traditional conjoint with the economic theory of consumer choice. This integration augments the capability of traditional conjoint such that consumers' reservation prices for a product can be derived directly from the individuallevel estimates of conjoint coefficients. With this augmentation,we can model a consumer's decision of not only which product to buy,but also whether to buy at all in a category. Thus, we can simulate simultaneously three effects that a change in price or the introduction of a new product may generate in a market: the customer switching effect,the cannibalization effect,and the market expansion effect. We show in a pilot application how this approach can aid product and pricing decisions. We also demonstrate the predictive validity of our approach using data from a commercial study of automobile batteries."
/doi/10.1287/mnsc.1050.0493," Internet technology has allowed for a higher degree of decoupling between the information-intensive sales process and the physical process of inventory management than its brick-and-mortar counterpart. As a result, some Internet retailers choose to outsource inventory and back-end operations to focus on the sales/marketing aspects of e-commerce. Nonetheless, many retailers keep fulfillment capabilities in-house. In this paper, we identify and empirically test factors that persuade firms to integrate inventory and fulfillment capabilities with virtual storefronts. Based on the extant literature and previous research in e-commerce, we formulate nine theoretical predictions. We then use data from a sample of over 50 public Internet retailers to test whether empirical data are consistent with these hypotheses. Finally, given the strategic importance and financial magnitude of the inventory investment decision, we analyze the effect of this decision on the economic success of Internet retailers during the period of study. We find that there are many circumstances in which it is prudent to own fulfillment capabilities and inventory. Empirical data are consistent with hypotheses that this tendency is higher for older firms selling small, high-margin products, offering lower levels of product variety, and facing lower demand uncertainty. We also discover that firms making inventory ownership decisions that are consistent with an empirical benchmark derived from environmental and strategic factors are less likely to go bankrupt than those making inconsistent inventory choices."
/doi/10.1287/orsc.2021.1471," Drawing on the Coase theorem, we consider a firm’s decision to transfer patent ownership to another firm in the markets for innovation. We deem that the proximity of a patent’s technology structure to that of a firm’s patent portfolio will generally result in greater marginal productivity of the patent, leading to enhanced prospects for the firm’s economic return. We thus predict that firms are more likely to trade patents when the technology structure of a patent is closer to the technology stock of a potential buyer compared with that of its original assignee. However, such a relationship will be weaker when a potential buyer and the original assignee have greater product-market overlap or when the assignee has superior technological capability. We test these predictions by employing a dyad-level analysis of transactional decisions during the 1987–2016 period on 40,110 U.S. patents assigned to 57 major biopharmaceutical firms. Our study provides novel insights on factors that facilitate or inhibit patent trade in the markets for innovation."
/doi/10.1287/mnsc.2016.2658," We study the empirical relevance of the participation externality between liquidity suppliers (makers) and demanders (takers), i.e., whether liquidity demand attracts or reduces liquidity supply, and vice versa. We use exogenous shocks to exchange fees and technology as experiments to identify cross-sided complementarities between liquidity suppliers and demanders in the U.S. equity market. We find that the externality is large and positive, on average. However, the externality is negative in periods of high adverse selection. We quantify the economic significance of the externality by evaluating an exchange’s revenue after a fee change. The Internet appendix is available at https://doi.org/10.1287/mnsc.2016.2658 . This paper was accepted by Lauren Cohen, finance."
/doi/10.1287/msom.1110.0357," Cap and trade programs impose limits on industry emissions but offer individual firms the flexibility to choose among different operational levers toward compliance, including inputs, process changes, and the use of allowances to account for emissions. In this paper, we examine the relationships among (1) levers for compliance (at-source pollution prevention, end-of-pipe pollution control, and the use of allowances); (2) environmental performance; and (3) firm market performance for the context of stringent cap and trade regulation with allowance grandfathering (i.e., the allocation of allowances for free). To investigate these relationships, we use data on publicly traded utility firms operating coal-fired generating units regulated by the U.S. Acid Rain Program from three principal sources: the U.S. Energy Information Administration, the U.S. Environmental Protection Agency, and the Compustat database. Our results indicate a significant relationship between better environmental performance and lower firm market performance over at least a three-year period. From a regulatory perspective, our results show a negative association between allowance grandfathering and firm environmental performance. Overall, by explicitly considering the context of stringent regulation, we find a counter-example to the view that better environmental performance generally associates with better economic performance."
/doi/10.1287/mnsc.2021.4012," Does a bank’s dependence on different external funding sources shape its voluntary disclosure of information? We evaluate whether economic shocks that increase the supply of bank deposits alter the cost–benefit calculations of bank managers concerning voluntary information disclosure. We measure information disclosure using 10-K filings, 8-K filings, and earnings guidance. As for the funding shock, we use unanticipated technological innovations that triggered shale development and booms in bank deposits. Further analyses suggest that greater exposure to shale development reduced information disclosure by relaxing the incentives for managers to disclose information to attract funds from external capital markets. This paper was accepted by Kay Giesecke, finance."
/doi/10.1287/trsc.1100.0316," This paper introduces a new variant of the one-to-many-to-one single vehicle pickup and delivery problems (SVPDP) that incorporates the handling cost incurred when rearranging the load at the customer locations. The simultaneous optimization of routing and handling costs is difficult, and the resulting loading patterns are hard to implement in practice. However, this option makes economical sense in contexts where the routing cost dominates the handling cost. We have proposed some simplified policies applicable to such contexts. The first is a two-phase heuristic in which the tour having minimum routing cost is initially determined by optimally solving an SVPDP, and the optimal handling policy is then determined for that tour. In addition, branch-and-cut algorithms based on integer linear programming formulations are proposed, in which routing and handling decisions are simultaneously optimized, but the handling decisions are restricted to three simplified policies. The formulations are strengthened by means of problem specific valid inequalities. The proposed methods have been extensively tested on instances involving up to 25 customers and hundreds of items. Our results show the impact of the handling aspect on the customer sequencing and indicate that the simplified handling policies favorably compare with the optimal one."
/doi/10.1287/mnsc.2019.3339," Changing economic conditions over the past two decades have created incentives for sell-side analysts to both provide their institutional clients tiered services and to streamline their written research process. One manifestation of these changes is an increased likelihood of analysts’ issuing earnings forecasts for multiple firms on the same day. We identify this bundling property and show that bundling has increased steadily over time. We provide field evidence that the practice is a cost-saving measure, a natural by-product of analysts focusing on thematic research, and a reflection of forecast updating that occurs in advance of important events. Our empirical analyses show that bundled forecasts are less accurate, less bold, and less informative to investors than nonbundled forecasts. We also find that analysts who produce bundled forecasts provide valuable specialized services to their institutional clients. Our findings ultimately demonstrate that forecast bundling has important implications for the properties of analysts’ forecasts. This paper was accepted by Shiva Rajgopal, accounting."
/doi/10.1287/mnsc.2015.2399," It has been argued that servicizing business models, under which a firm sells the use of a product rather than the product itself, are environmentally beneficial. The main arguments are as follow. First, under servicizing the firm charges customers based on the product usage. Second, the quantity of products required to meet customer needs may be smaller because the firm may be able to pool customer needs. Third, the firm may have an incentive to offer products with higher efficiency. Motivated by these arguments, we investigate the economic and environmental potential of servicizing business models. We endogenize the firm’s choice between a pure sales model, a pure servicizing model, and a hybrid model with both sales and servicizing options; the pricing decisions; and the resulting customer usage. We consider two extremes of pooling efficacy, i.e., no pooling versus strong pooling. We find that under no pooling servicizing leads to higher environmental impact due to production but lower environmental impact due to use. In contrast, under strong pooling, when a hybrid business model is more profitable, it is also environmentally superior. However, a pure servicizing model is environmentally inferior for high production costs because it leads to a larger production quantity even under strong pooling. We also examine the product efficiency choice and find that the firm offers higher efficiency products only under servicizing models with strong pooling. This paper was accepted by Serguei Netessine, operations management ."
/doi/10.1287/msom.2018.0762," Problem definition: We explore the coordination of operational and financial decisions of proportional investment agricultural marketing cooperatives, where members’ (farmers’) equity is required to be in proportion to their patronage (i.e., produce supplied). Academic/practical relevance: In a cooperative (co-op), operational and financial decisions are inseparable because the co-op’s investment capital is linked to its economic transactions with members. We include unique features of co-ops into an analytical model and derive some key results that are different from those for investor-owned corporations. Methodology: In the presence of yield and market uncertainty, we model this situation using a Markov decision process wherein the decisions of processing quantity interact with the financial decisions of retained earnings and short-term loans. The objective is to maximize the expected present value of the aggregated farmers’ payments over a finite horizon. Results: (1) Characterization of the properties of the value function and the optimal policy; (2) explicit expressions for the deterministic yield dynamic program, wherein a myopic policy is optimal; and (3) identification of financial risks associated with uncertain market and yield. Managerial implications: The results provide insight into a co-op’s decision making, cash position, and risk management."
/doi/10.1287/mnsc.1100.1188," We use unique data from 245 stores of a UK retailer to study links among middle (store) manager skills, sales, and manager pay. We find that, of the six management practice areas surveyed, the most important is “commercial awareness,” where abler managers achieve up to 13.9% higher sales per worker. We find that many stores have poor managers on this indicator. However, the company is careful to incentivize managers, operating a scheme giving shares (approximately 20%) in both positive and negative deviations of actual sales from expected. Abler managers do not receive higher pay, implying that their skills are company specific."
/doi/10.1287/mksc.2020.1235," Mobile in-app advertising is now the dominant form of digital advertising. Although these ads have excellent user-tracking properties, they have raised concerns among privacy advocates. This has resulted in an ongoing debate on the value of different types of targeting information, the incentives of ad networks to engage in behavioral targeting, and the role of regulation. To answer these questions, we propose a unified modeling framework that consists of two components—a machine learning framework for targeting and an analytical auction model for examining market outcomes under counterfactual targeting regimes. We apply our framework to large-scale data from the leading in-app ad network of an Asian country. We find that an efficient targeting policy based on our machine learning framework improves the average click-through rate by 66.80% over the current system. These gains mainly stem from behavioral information compared with contextual information. Theoretical and empirical counterfactuals show that although total surplus grows with more granular targeting, the ad network’s revenues are nonmonotonic; that is, the most efficient targeting does not maximize ad network revenues. Rather, it is maximized when the ad network does not allow advertisers to engage in behavioral targeting. Our results suggest that ad networks may have economic incentives to preserve users’ privacy without external regulation."
/doi/10.1287/mksc.1080.0398," Most supermarket firms choose to position themselves by offering either everyday low prices (EDLP) across several items or offering temporary price reductions (promotions) on a limited range of items. While this choice has been addressed from a theoretical perspective in both the marketing and economic literature, relatively little is known about how these decisions are made in practice, especially within a competitive environment. This paper exploits a unique store level data set consisting of every supermarket operating in the United States in 1998. For each of these stores, we observe the pricing strategy the firm has chosen to follow, as reported by the firm itself. Using a system of simultaneous discrete choice models, we estimate each store's choice of pricing strategy as a static discrete game of incomplete information. In contrast to the predictions of the theoretical literature, we find strong evidence that firms cluster by strategy by choosing actions that agree with those of its rivals. We also find a significant impact of various demographic and store/chain characteristics, providing some qualified support for several specific predictions from marketing theory."
/doi/10.1287/inte.31.3s.8.9675," Over 25 years, we have developed many sales-force and modeling insights through over 2,000 projects with several hundred selling organizations in over 50 countries. Content insights are useful in making sales-force decisions. Examples are that profitability is flat for a wide range of sales-force sizes; phased sales-force growth is rarely optimal; focused strategies dominate scattered strategies; most sales territories (55 percent) are too large or too small; and no compensation plan satisfies everyone. Implementation insights concern model building, use, and implementation, for example, a model's economic value can come from such sources as reduced uncertainty, accuracy, increased speed, objectivity, and stakeholder involvement; theory and practice have different and complementary perspectives; experience and wisdom are sometimes better than models; and models provide insights, while people make decisions."
/doi/10.1287/mnsc.2013.1826," We conducted a field experiment with the American Red Cross (ARC) to study the effects of economic incentives on volunteer activities. The experiment was designed to assess local and short-term effects as well as spatial and temporal substitution, heterogeneity, and spillovers. Subjects offered $5, $10, and $15 gift cards to give blood were more likely to donate and more so for the higher reward values. The incentives also led to spatial displacement and a short-term shift in the timing of donation activity, but they had no long-term effects. Many of the effects were also heterogeneous in the population. We also detected a spillover effect whereby informing some individuals of rewards through official ARC channels led others who were not officially informed to be more likely to donate. Thus, the effect of incentives on prosocial behavior includes not only the immediate local effects but also spatial displacement, social spillovers, and dramatic heterogeneity. We discuss the implications of these findings for organizations with activities that rely on volunteers for the supply of key inputs or products as well as for government agencies and public policy. This paper was accepted by Uri Gneezy, behavioral economics ."
/doi/10.1287/mnsc.2019.3386," Safety alerts are announcements made by health regulators warning patients and doctors about new drug-related side effects. However, not all safety alerts are equally effective. We provide evidence that the day of the week on which the safety alerts are announced explains differences in safety alert impact. Specifically, we show that safety alerts announced on Fridays are less broadly diffused: they are shared 34% less on social media, mentioned in 23% to 66% fewer news articles, and are 12% to 51% less likely to receive any news coverage at all. As a consequence of this, we propose Friday alerts are less effective in reducing drug-related side effects. We find that moving a Friday alert to any other weekday would reduce all drug-related side effects by 9% to 12%, serious drug-related complications by 6% to 15%, and drug-related deaths by 22% to 36%. This problem is particularly important because Friday was the most frequent weekday for safety alert announcements from 1999 to 2016. We show that this greater prevalence of Friday alerts might not be random: firms that lobbied the U.S. Food and Drug Administration in the past are 49% to 56% more likely to have safety alerts announced on Fridays. This paper was accepted by Stefan Scholtes, healthcare management."
/doi/10.1287/mksc.1090.0553," Despite the economic significance of the theme park industry and the huge investments needed to set up new attractions, no marketing models exist to guide these investment decisions. This study addresses this gap in the literature by estimating a response model for theme park attendance. The model not only determines the contribution of each attraction to attendance, but also how this contribution is distributed within and across years. The model accommodates saturation effects, which imply that the impact of a new attraction is smaller if similar attractions are already present. It also captures reinforcement effects, meaning that a new attraction may reinforce the drawing power of similar extant attractions, especially when these were introduced recently. The model is calibrated on 25 years of weekly attendance data from the Efteling, a leading European theme park. Our return on investment calculations show that it is more profitable to invest in multiple smaller attractions than in one big one. This finding is in remarkable contrast with the current “arms race” in the industry. Furthermore, even though thrill rides tend to be more effective than theme rides, there are conditions under which one should consider to switch to the latter."
/doi/10.1287/mnsc.1110.1345," In this paper, we focus on modeling and predicting the loss distribution for credit risky assets such as bonds and loans. We model the probability of default and the recovery rate given default based on shared covariates. We develop a new class of default models that explicitly accounts for sector specific and regime dependent unobservable heterogeneity in firm characteristics. Based on the analysis of a large default and recovery data set over the horizon 1980–2008, we document that the specification of the default model has a major impact on the predicted loss distribution, whereas the specification of the recovery model is less important. In particular, we find evidence that industry factors and regime dynamics affect the performance of default models, implying that the appropriate choice of default models for loss prediction will depend on the credit cycle and on portfolio characteristics. Finally, we show that default probabilities and recovery rates predicted out of sample are negatively correlated and that the magnitude of the correlation varies with seniority class, industry, and credit cycle. This paper was accepted by Wei Xiong, finance."
/doi/10.1287/ijoc.2015.0676," We consider a bilevel integer programming model that extends the classic 0–1 knapsack problem in a very natural way. The model describes a Stackelberg game where the leader’s decision interdicts a subset of the knapsack items for the follower. As this interdiction of items substantially increases the difficulty of the problem, it prevents the application of the classical methods for bilevel programming and of the specialized approaches that are tailored to other bilevel knapsack variants. Motivated by the simple description of the model, by its complexity, by its economic applications, and by the lack of algorithms to solve it, we design a novel viable way for computing optimal solutions. Finally, we present extensive computational results that show the effectiveness of the new algorithm on instances from the literature and on randomly generated instances."
/doi/10.1287/mksc.1070.0305," There is substantial literature documenting the presence of state-dependent utility with packaged goods data. Typically, a form of brand loyalty is detected whereby there is a higher probability of purchasing the same brand as has been purchased in the recent past. The economic significance of the measured loyalty remains an open question. We consider the category pricing problem and demonstrate that the presence of loyalty materially affects optimal pricing. The prices of higher quality products decline relative to those of lower quality when loyalty is introduced into the model. Given the well-known problems with the confounding of state dependence and consumer heterogeneity, loyalty must be measured in a model which allows for an unknown and possibly highly nonnormal distribution of heterogeneity. We implement a highly flexible model of heterogeneity using multivariate mixtures of normals in a hierarchical choice model. We use an Euler equations approach to the solution of the dynamic pricing problem which allows us to consider a very large number of consumer types."
/doi/10.1287/mksc.2015.0908," A vexing challenge when using the utility-maximization framework to estimate consumers’ decisions on which set of goods to purchase and how much quantity to buy is obtaining a functional form of the utility that satisfies three criteria: tractability, flexibility, and global regularity. Flexibility refers to the ability of a utility function to impose minimal prior restrictions on demand elasticities. Global regularity refers to the ability of a utility function to satisfy regularity properties required by economic theory in the entire feasible space of variables. The tractable utility functions used so far are either inflexible, which could yield inaccurate estimates of underlying elasticities, or do not satisfy global regularity, which can result in invalid expressions of likelihood and invalid policy simulations. I tackle this problem by deriving necessary and sufficient conditions for global regularity of Basic Translog utility. Using simulated and scanner data, I show that the proposed demand system yields better model fit, more accurately captures underlying elasticities, and yields substantially different results in counterfactuals compared to alternatives used in prior literature. Specifically, unlike the alternatives used so far, the proposed demand system allows for complementarities between goods, and more accurately captures the extent of their inferiority, the extent of their substitutability, and asymmetries in cross price effects."
/doi/10.1287/msom.2018.0770," Problem definition : We analyze a resource allocation problem faced by medical surplus recovery organizations (MSROs) that recover medical surplus products to fulfill the needs of underserved healthcare facilities in developing countries. The objective of this study is to identify implementable strategies to support recipient selection decisions to improve MSROs’ value provision capability. Academic/practical relevance : MSRO supply chains face several challenges that differ from those in traditional for-profit settings, and there is a lack of both academic and practical understanding of how to better match supply with demand in this setting where recipient needs are typically private information. Methodology : We propose a mechanism design approach to determine which recipient to serve at each shipping opportunity based on recipients’ reported preference rankings of different products. Results : We find that when MSRO inventory information is shared with recipients, the only truthful mechanism is random selection among recipients, which defeats the purpose of eliciting information. Subsequently, we show that (1) eliminating inventory information provision enlarges the set of truthful mechanisms, thereby increasing the total value provision; and (2) further withholding information regarding other recipients leads to an additional increase in total value provision. Finally, we show that under a class of implementable mechanisms, eliciting recipient valuations has no value added beyond eliciting preference rankings. Managerial implications : (1) MSROs with large recipient bases and low inventory levels can significantly improve their value provision by appropriately determining the recipients to serve through a simple scoring mechanism; (2) to truthfully elicit recipient needs information to support the recipient selection decisions, MSROs should withhold inventory and recipient-base information; and (3) under a set of easy-to-implement scoring mechanisms, it is sufficient for MSROs to elicit recipients’ preference ranking information. Our findings have already led to a change in the practice of an award-winning MSRO."
/doi/10.1287/isre.2017.0755," Service Level Agreements (SLA) for cloud services entail complex trade-offs between interrelated variables such as price, penalty, and service availability (uptime) guarantee, with resource management strategies affecting fulfillment of the SLA. In this study, we address three key components of the SLA-based cloud resource management and pricing problem, from the service-provider’s perspective: (1) availability-aware backup resource provisioning; (2) price-penalty schedule determination; and (3) penalty-deferred pricing over two periods. Using the convexity of the provider’s expected total cost over the number of backup resources, we present a dichotomous search algorithm to derive the total cost minimizing number of backup resources for a given level of SLA-specified service availability guarantee. Next, we derive closed-form solutions for the lower bound of the feasible price range, yielding a schedule of breakeven price-penalty combinations, which establishes the baseline required in the economic modeling of the service contracts and related negotiation processes, and may also elicit client preference information. We then model a two-period pricing problem specifically designed to incentivize penalty deferrals in the event of an SLA violation. Detailed experimental studies of the proposed models have been carried out using real-world datacenter log data. The computational study validates the convexity of the probability density function of SLA violations over the number of backup resources. The results demonstrate significant interaction effects between the SLA parameters (price, penalty rate, and provisioning cost) and the backup resource provisioning decisions made by the provider, leading to key practical managerial implications for SLA design and resource deployment in the availability-aware cloud. The online appendix is available at https://doi.org/10.1287/isre.2017.0755 ."
/doi/10.1287/serv.2017.0186," For a couple of decades, information technology (IT) as well as its management have been evolving toward more agility. Cloud computing and service-oriented computing have enabled increases in the agility of, respectively, the hardware and the software components of IT services. Similarly, companies more and more often use agile methods for managing their IT projects. This means that many IT organizations can follow the values and principles of the Agile theory , which shares many similarities with service science . However, regarding the management of IT operations, existing solutions are largely process oriented and focus on the control and respect of the initial commitments. Therefore, these solutions, called IT service management (ITSM) methods, are not aligned with the agile values and principles. In response, we propose the basics of a future agile IT service management framework. To do so, we revisit the agile values and principles applied in the software development to best suit the ITSM context. We also identify some practices applied in the current ITSM methods that (partially) block the evolution toward more agility in ITSM. These practices are discussed and rewritten accordingly."
/doi/10.1287/isre.1080.0207," Peer production phenomena such as open source software (OSS) have been posited as a viable alternative to traditional production models. However, community-based development often falls short of creating software “products” in the sense that consumers understand. Our research identifies an emerging business network archetype in the OSS sector, the open source service network (OSSN), which seeks to address the “productization” challenge. To do so, OSSNs must overcome the problems associated with exchanging resources between firms. We demonstrate that OSSNs overcome exchange problems by primarily relying on social, rather than legal, mechanisms; similar to the OSS communities from which they emerged. This is made possible because OSSNs use IT infrastructures that provide high visibility for primary value-creating activities. The research utilizes a multimethod theory-building approach, deriving a model from extant research, refining the model through qualitative case study analysis, and further refining the model through quantitative analysis of survey data. The paper reveals the manifestation of social mechanisms in OSSNs and how these are used for coordinating and safeguarding exchanges between firms. Specifically, we illustrate the primary importance of a shared macroculture (goals and norms) and collective sanctions for punishing firms who violate these goals/norms. Furthermore, our research highlights the interplay between digital and social networks within OSSNs, demonstrating that the use of social mechanisms is inherently dependent upon the underlying IT infrastructure."
/doi/10.1287/mnsc.2014.2074," We run a series of controlled field experiments on eBay where buyers are rewarded for providing feedback. Our results provide little support for the hypothesis of buyers’ rational economic behavior: the likelihood of feedback barely increases as we increase feedback rebate values; also, the speed of feedback, bid levels, and the number of bids are all insensitive to rebate values. By contrast, we find evidence consistent with reciprocal buyer behavior. Lower transaction quality leads to a higher probability of negative feedback as well as a speeding up of such negative feedback. However, when transaction quality is low (as measured by slow shipping), offering a rebate significantly decreases the likelihood of negative feedback. All in all, our results are consistent with the hypothesis that buyers reciprocate the sellers’ “good deeds” (feedback rebate, high transaction quality) with more frequent and more favorable feedback. As a result, sellers can “buy” feedback, but such feedback is likely to be biased. Data, as supplemental material, are available at http://dx.doi.org/10.1287/mnsc.2014.2074 . This paper was accepted by Teck-Hua Ho, behavioral economics ."
/doi/10.1287/mnsc.2014.2024," Market-based theories predict that differences in CEO skills lead to potentially large differences in pay, but it is challenging to quantify the CEO skill premium in pay. In a first step toward overcoming this empirical challenge, we code detailed biographical information for a large sample of CEOs for a panel of S&P 1500 firms between 1993 and 2005 to identify specific reputational, career, and educational credentials that are indicative of skills. Newly appointed CEOs earn up to a 5% or $280,000 total pay premium per credential decile, which is concentrated among CEOs with better reputational and career credentials, those with the very best credentials, and those who run large firms. Consistent with the unique economic mechanism of market-based theories, CEO credentials have a positive impact on firm performance. The performance differential for newly appointed CEOs is up to 0.5% per credential decile and is also concentrated among CEOs with better reputational and career credentials and those at large firms. Credentials are positively correlated with unobserved CEO heterogeneity in pay and performance, which further validates our hypothesis that boards use them as publicly observable signals of otherwise hard-to-gauge CEO skills. In all, our results offer direct evidence in support of market-based explanations of the overall rise in CEO pay. This paper was accepted by Itay Goldstein, finance ."
/doi/10.1287/mnsc.2017.2755," We study the optimal pricing problem of a monopolistic firm facing customers with limited attention and capability to process information about the value (quality) of a single offered product. We model customer choice based on the theory of rational inattention in the economics literature, which enables us to capture not only the impact of true quality and price, but also the intricate effects of customer’s prior beliefs and cost of information acquisition and processing. We formulate the firm’s price optimization problem assuming that the firm can also use the price to signal the quality of the product to customers. To delineate the economic incentives of the firm, we first characterize the pricing and revenue implications of customer’s limited attention without signaling, and then use these results to explore perfect Bayesian equilibria of the strategic pricing signaling game. As an extension, we consider heterogeneous customers with different information costs as well as prior beliefs. We discuss the managerial implications of our key findings and prescribe insights regarding information provision and product positioning. This paper was accepted by Gad Allon, operations management."
/doi/10.1287/msom.2020.0869," Problem definition : We study a special form of group buying: the group buying succeeds only if the number of sign-ups reaches a preset threshold, with no duration constraint. Customers with heterogeneous valuations arrive sequentially and decide between signing up for the group buying or purchasing a regular product. To decide whether to join the group buying, customers need to estimate their expected waiting time, which varies depending on the cumulative sign-ups by the time of their arrival. The firm decides on the prices for the group-buying product and regular product, with the product quality levels and group-buying size exogenously determined. Academic/practical relevance : This type of group buying is often adopted for a special edition of the product and offered alongside a constantly available regular product. Methodology : We study the product line design with the group-buying sign-up behavior of customers characterized by the rational expectations equilibrium in a random pledging process. Results : We show that group buying with flexible duration can result in intertemporal customer segmentation, as different segments might be admitted at different times in the dynamic sign-up process. Such intertemporal segmentation is a natural discrimination scheme and has nontrivial implications. First, the efficiency loss due to waiting for enough sign-ups may decrease when a larger batch size is required for economic production. Second, as valuation heterogeneity in the market increases, the firm may not always benefit from offering group buying along with the regular product. Third, group buying can achieve a win-win-win situation for both high-end and low-end customers as well as the firm. Managerial implications : In addition to demonstrating the profitability of flexible-duration group buying, we show that the firm can strengthen its profitability by contingently setting prices or concealing sign-up information in group buying. We also confirm the robustness of our main insights by considering customers’ heterogeneous patience levels and horizontally differentiated products, among other factors."
/doi/10.1287/isre.9.1.1," This paper specifies a generalizable model of exchange processes and develops a process-stakeholder analysis framework to evaluate alternative market designs. This framework is applied to analyze a number of information technology initiatives in the Dutch flower markets. The Dutch flower auctions are the world's leading centers for trading cut flowers and potted plants. We undertake a cross-case analysis and apply our framework to analyse successes and failures in the introduction of new IT-based trading mechanisms in these markets. Based on our study, we develop a number of testable propositions on: the separation of physical and informational processes in trading, the responses of stakeholders to changes in available information due to IT initiatives, and economic and incentive conditions required for adoption of new trading processes. Finally, our detailed cases illustrate the institutional and incentive constraints, and complexities encountered in the introduction of new electronic markets."
/doi/10.1287/mnsc.2019.3526," Risk is an integral part of many economic decisions and is vitally important in finance. Despite extensive research on decision making under risk, little is known about how risks are actually perceived by financial professionals, the key players in global financial markets. In a large-scale survey experiment with 2,213 finance professionals and 4,559 laypeople in nine countries representing ~50% of the world’s population and more than 60% of the world’s gross domestic product, we expose participants to return distributions with equal expected return, and we systematically vary the distributions’ next three higher moments. Of these, skewness is the only moment that systematically affects financial professionals’ perception of financial risk. Strikingly, variance does not influence risk perception, even though return volatility is the most common risk measure in finance in both academia and the industry. When testing other, compound risk measures, the probability to experience losses is the strongest predictor of what is perceived as being risky. Analyzing professionals’ propensity to invest, skewness and loss probability also have strong predictive power, while volatility and kurtosis have some additional effect. Our results are very similar for laypeople, and they are robust across and within countries with different cultural backgrounds, as well as for different job fields of professionals. This paper was accepted by Yuval Rottenstreich, decision analysis."
/doi/10.1287/mnsc.2020.3879," Social media platforms for healthcare services are changing how patients choose physicians. The digitization of healthcare reviews has been providing additional information to patients when choosing their physicians. On the other hand, the growing online information introduces more uncertainty among providers regarding the expected future demand and how different service features can affect patient decisions. In this paper, we derive various service-quality proxies from online reviews and show that leveraging textual information can derive useful operational measures to better understand patient choices. To do so, we study a unique data set from one of the leading appointment-booking websites in the United States. We derive from the text reviews the seven most frequently mentioned topics among patients, namely, bedside manner, diagnosis accuracy, waiting time, service time, insurance process, physician knowledge, and office environment, and then incorporate these service features into a random-coefficient choice model to quantify the economic values of these service-quality proxies. By introducing quality proxies from text reviews, we find the predictive power of patient choice increases significantly, for example, a 6%–12% improvement measured by mean squared error for both in-sample and out-of-sample tests. In addition, our estimation results indicate that contextual description may better characterize users’ perceived quality than numerical ratings on the same service feature. Broadly speaking, this paper shows how to incorporate textual information into an econometric model to understand patient choice in healthcare delivery. Our interdisciplinary approach provides a framework that combines machine learning and structural modeling techniques to advance the literature in empirical operations management, information systems, and marketing. This paper was accepted by David Simchi-Levi, operations management."
/doi/10.1287/isre.2021.1066," There is increasing interest in information systems research to model information flows from different sources (e.g., social media, news) associated with a network of assets (e.g., stocks, products) and to study the economic impact of such information flows. This paper employs a design science approach and proposes a new composite metric, eigen attention centrality (EAC), as a proxy for information flows associated with a node that considers both attention to a node and coattention with other nodes in a network. We apply the EAC metric in the context of financial market where nodes are individual stocks and edges are based on coattention relationships among stocks. Composite information from different channels is used to measure attention and coattention. To evaluate the effectiveness of the EAC metric on predicting outcomes, we conduct an in-depth performance evaluation of the EAC metric by (1) using multiple linear and nonlinear prediction methods and (2) comparing EAC with a benchmark model without EAC and models with a set of alternative network metrics. Our analysis shows that EAC significantly outperforms other measures in predicting the direction and magnitude of abnormal returns of stocks. Besides, our EAC specification has better predictive performance than alternative specifications, and EAC outperforms direct attention in predicting abnormal returns. Using the EAC metric, we derive a stock portfolio and develop a trading strategy that provides significant and positive excess returns. Lastly, we find that composite information has significantly better predictive performance than separate information sources, and such superior performance owes to information from social media instead of traditional media."
/doi/10.1287/mnsc.1080.0920," We provide large sample evidence that past price extremes influence investors' trading decisions. Volume is strikingly higher, in both economic and statistical terms, when the stock price crosses either the upper or lower limit of its past trading range. This increase in volume is more pronounced the longer the time since the stock price last achieved the price extreme, the smaller the firm, the higher the individual investor interest in the stock, and the greater the ambiguity regarding valuation. These results are robust across model specifications and controls for past returns and news arrival. Volume spikes when price crosses either the upper or lower limit of the past trading range, then gradually subsides. After either event, returns are reliably positive and, among small investors, trades classified as buyer-initiated are elevated. Overall, results are more consistent with bounded rationality than with other candidate explanations."
/doi/10.1287/mnsc.1110.1499," In the pharmaceutical industry, measuring the importance of informative and persuasive roles of detailing is crucial for both drug manufacturers and policy makers. However, little progress has been made in disentangling these two roles of detailing in empirical research. In this paper, we provide a new identification strategy to address this problem. Our key identification assumptions are that the informative component of detailing is chemical specific and the persuasive component is brand specific. Our strategy is to focus on markets where some drug manufacturers engage in a comarketing agreement, under which two or more companies market the same chemical using their own brand names. With our identification assumptions, the variation in the relative market shares of these two brands, together with their brand specific detailing efforts, would allow us to measure the persuasive component of detailing. The variation in the market shares of chemicals, and the detailing efforts summed across brands made of the same chemical, would allow us to measure the informative component of detailing. Using the data for angiotensin-converting enzyme inhibitor with diuretic in Canada, we find evidence that our identification strategy can help disentangle these two effects. Although both effects are statistically significant, we find that the persuasive function of detailing plays a very minor role in determining the demand at the chemical level—the informative role of detailing is mainly responsible for the diffusion patterns of chemicals. In contrast, the persuasive role of detailing plays a crucial role in determining the demand for brands that comarket the same chemical. This paper was accepted by Pradeep Chintagunta, marketing."
/doi/10.1287/inte.10.1.61," The field of investments presents a large and fertile area for the application of both the theory and the practice of Management Science. There is an obvious economic requirement in investing to make theory and practice meet. This emphasis on practicality has also led to the adoption in the investment community of sophisticated analytical methods from many sources. With this background in mind and in the hope of stimulating new interest in financial problems among Management Scientists, I have prepared the following brief overview of a topic of intense current interest in the investment community. The topic is stock options."
/doi/10.1287/serv.1120.0012," Three frameworks are recommended to analyze multilevel governance across a spectrum of complex human systems, including nations, states, cities, universities, hospitals, hotels, and homes, with which service researchers are concerned. This spectrum of complex human systems can be seen as instances of nested, networked holistic service systems that provision whole service to the people inside them and depend heavily on shared systems of rules to change over time. Increasingly, service researchers benefit from improved analysis/design frameworks for complex human systems that (1) improve multilevel governance, making it more likely that local optimizations contribute to global resilience and sustainability, and (2) can integrate across diverse disciplines, systems, and cultures. Three frameworks are considered: service science, management, engineering, and design (SSME+D); viable systems approach (VSA); and institutional analysis and development (IAD). Each framework has a focal building block (rule-rich entity architectures)—namely, a service system (SSME+D), a viable system (VSA), and a polycentric system (IAD). Our goals are to (1) provide a conceptual foundation and recommended methodology to illustrate the type of future empirical work that might someday provide more efficient and effective ways to compare, contrast, and search for improved service research frameworks and entity architectures, and (2) encourage service researchers to move beyond dyads, be they provider-to-customer, business-to-business, or even government-to-citizen, and toward a view of multilevel rule-rich nested, networked systems in the wild."
/doi/10.1287/mnsc.49.12.1684.25112," Opportunism is a central construct in exchange theory. Economists contend that despite the firm's best efforts to erect governance structures that reduce opportunism and preserve outcomes, there is always some opportunism that remains once the transaction is in place. Despite this, there are few studies that systematically investigate the safeguarding efficacy of relationship attributes in the presence of such ex post opportunism. In this research, we develop a theoretical framework and provide a longitudinal test of the ability of various relationship safeguards to preserve performance outcomes and future expectations given varying levels of ex post opportunism in the relationship. Our survey results from over 300 buyers and suppliers indicates that given lower levels of opportunism, bilateral idiosyncratic investments and interpersonal trust enhance performance outcomes and future expectations, while goal congruence has no discernable effect. However, at higher levels of opportunism, goal congruence becomes a more powerful safeguard, while interpersonal trust becomes less effective. Bilateral idiosyncratic investments continue to preserve performance outcomes and future expectations even at higher levels of opportunism. Implications for the long-term management of interorganizational alliances are discussed."
/doi/10.1287/orsc.2020.1360," Despite substantial scholarly attention to workforce demographic diversity, existing research is limited in understanding whether or in what contexts firm-level racial diversity relates to performance and workforce outcomes of the firm. Drawing on social interdependence theory along with insights from social exchange and psychological ownership theories, we propose that the use of broad-based stock options granted to at least half the workforce creates the conditions supporting a positive relationship between workforce racial diversity and firm outcomes. We examine this proposition by analyzing panel data from 155 companies that applied for the “100 Best Companies to Work For” competition with responses from 109,314 employees over the five-year period from 2006 to 2010 (354 company-year observations). Findings revealed that racial diversity was positively related to subsequent firm financial performance and individual affective commitment and was not significantly associated with subsequent voluntary turnover rates, when accompanied by a firm’s adoption of broad-based stock options. However, under the nonuse of broad-based stock options, racial diversity was significantly related to higher voluntary turnover rates and lower employee affective commitment, with no financial performance gains. By documenting the beneficial effects of financial incentives in diverse workplaces, this paper extends theory asserting the value of incentives for performance."
