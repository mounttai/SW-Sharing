link,abstract
/doi/10.1287/isre.2019.0855," Capacity is the maximum short-run output with capital in place under normal operations, and capital investment increases capacity. Excess capacity can be used as an economic strategy for entry deterrence by lowering average costs over a greater range of output, and as an operations strategy by providing value through flexibility to manage demand fluctuations and production disturbances. Our primary focus is to study the way that information technology (IT) can contribute to a strategy of holding excess capacity by comparing the relationship between IT capital and capacity with that of non-IT capital and capacity. Using production theory–based empirical analyses, we find that increases in IT capital yield almost fourfold greater expansion in capacity than do increases in non-IT capital. Thus, as both types of capital are constraints on capacity, for a strategy of holding excess capacity IT capital is a more valuable constraint to relax than non-IT capital. In addition, since the late 1990s, IT capital, and to a lesser extent, non-IT capital, has reduced capacity utilization (output/capacity), meaning increasing levels of excess capacity are being held across manufacturing industries and utilities across the economy."
/doi/10.1287/mnsc.2021.4153," Ignorance enables individuals to act immorally. This is well known in policy circles, in which there is keen interest in lowering moral ignorance. In this paper, we study how the demand for moral ignorance responds to monetary incentives and how the demand curve for ignorance reacts to social norm messages. We propose a simple behavioral model in which individuals suffer moral costs when behaving selfishly in the face of moral information. In several experiments, we find that moral ignorance decreases by more than 30 percentage points with small monetary incentives, but we find no significant change with social norm messages, and we document strong persistence of ignorance across moral contexts. Our findings indicate that rather simple messaging interventions may have limited effects on ignorance. In contrast, changes in incentives could be highly effective. This paper was accepted by Yan Chen, behavioral economics and decision analysis."
/doi/10.1287/mnsc.2015.2277," We study how a bank’s willingness to lend to a previously exclusive firm changes once the firm obtains a loan from another bank (“outside loan”) and breaks an exclusive relationship. Using a difference-in-difference analysis and a setting where outside loans are observable, we document that an outside loan triggers a decrease in the initial bank’s willingness to lend to the firm, i.e., outside loans are strategic substitutes. Consistent with concerns about coordination problems and higher indebtedness, we find that this reaction is more pronounced the larger the outside loan and it is muted if the initial bank’s existing and future loans retain seniority and are protected with valuable collateral. Our results give a benevolent role to transparency enabling banks to mitigate adverse effects from outside loans. The resulting substitute behavior may also act as a stabilizing force in credit markets limiting positive comovements between lenders, decreasing the possibility of credit freezes and financial crises. This paper was accepted by Itay Goldstein, finance ."
/doi/10.1287/mnsc.1120.1559," This paper examines the contribution to price discovery by electronic and voice-based trading systems in the U.S. Treasury market. Evidence shows that the electronic trading system has more price discovery and that trading automation increases the speed of incorporating information into prices. However, human trading generates significant price discovery, though its volume is low. The relative contribution of a trading system to price discovery depends on liquidity, volatility, volume, trade size, and order imbalance. The voice-based trading system contributes more to price discovery when trade size is large and liquidity is low. These findings provide important implications for the design of electronic markets for securities with different characteristics and trading environments. This paper was accepted by Wei Xiong, finance."
/doi/10.1287/opre.1050.0211," We consider three models of investments in generation capacity in restructured electricity systems that differ with respect to their underlying economic assumptions. The first model assumes a perfect, competitive equilibrium. It is very similar to the traditional capacity expansion models even if its economic interpretation is different. The second model (open-loop Cournot game) extends the Cournot model to include investments in new generation capacities. This model can be interpreted as describing investments in an oligopolistic market where capacity is simultaneously built and sold in long-term contracts when there is no spot market. The third model (closed-loop Cournot game) separates the investment and sales decision with investment in the first stage and sales in the second stage—that is, a spot market. This two-stage game corresponds to investments in merchant plants where the first-stage equilibrium problem is solved subject to equilibrium constraints. We show that despite some important differences, the open- and closed-loop games share many properties. One of the important results is that the prices and quantities produced in the closed-loop game, when the solution exists, fall between the prices and quantities in the open-loop game and the competitive equilibrium."
/doi/10.1287/isre.2018.0822," Building on recent work suggesting that objects and boundaries coevolve in practice, this paper theorizes the mechanisms for such coevolution. We argue that users in organizations choose objects to use for crossboundary collaboration, because they believe that they will afford certain types of communication. Over time, use of the object changes collaboration, which alters the constitution of the boundary at which the object was originally used. When the object’s materiality makes it difficult to achieve collaboration goals, users change objects. New objects provide new affordances for communication, which help to transfer new knowledge across the boundary. As knowledge changes people’s work in practice, the boundary that separates them changes, often requiring the use of a new object with new affordances useful for communicating across the new boundary. We illustrate our emerging theoretical perspective that highlights the role of materiality and affordances in the coevolution of objects and boundaries through a longitudinal study of a global product development organization. We discuss how our findings can lead to novel theorizing about the coevolution of objects and boundaries, the role of affordances as the mechanism for this coevolution, and the use of objects in communicating knowledge across boundaries."
/doi/10.1287/mnsc.2015.2291," This paper reports the results from a controlled field experiment designed to investigate the causal effect of unannounced, public recognition on employee performance. We hired more than 300 employees to work on a three-hour data-entry task. In a random sample of work groups, workers unexpectedly received recognition after two hours of work. We find that recognition increases subsequent performance substantially, and particularly when recognition is exclusively provided to the best performers. Remarkably, workers who did not receive recognition are mainly responsible for this performance increase. Our results are consistent with workers having a preference for conformity and being reciprocal at the same time. Data, as supplemental material, are available at http://dx.doi.org/10.1287/mnsc.2015.2291 . This paper was accepted by John List, behavioral economics ."
/doi/10.1287/orsc.2019.1308," We examine how the introduction of a technology that automates research tasks influences the rate and type of researchers’ knowledge production. To do this, we leverage the unanticipated arrival of an automating motion-sensing research technology that occurred as a consequence of the introduction and subsequent hacking of the Microsoft Kinect system. To estimate whether this technology induces changes in the type of knowledge produced, we employ novel measures based on machine learning (topic modeling) techniques and traditional measures based on bibliometric indicators. Our analysis demonstrates that the shock associated with the introduction of Kinect increased the production of ideas and induced researchers to pursue ideas more diverse than and distant from their original trajectories. We find that this holds for both researchers who had published in motion-sensing research prior to the Kinect shock (within-area researchers) and those who did not (outside-area researchers), with the effects being stronger among outside-area researchers."
/doi/10.1287/mnsc.2015.2388," We characterize the consistency of a large class of nonexpected utility preferences (including mean-variance preferences and prospect theory preferences) with stochastic orders (for example, stochastic dominances of different degrees). Our characterization rests on a novel decision theoretic result that provides a behavioral interpretation of the set of all derivatives of the functional representing the decision maker’s preferences. As an illustration, we consider in some detail prospect theory and choice-acclimating preferences, two popular models of reference dependence under risk, and we show the incompatibility of loss aversion with prudence. This paper was accepted by James Smith, decision analysis ."
/doi/10.1287/isre.12.3.322.9710," In today's networked economy, ideas that challenge existing business models and paradigms are becoming more important. This study investigated how individual differences, groupware-based creativity techniques, and ideas from others influenced the type of ideas that individuals generated. While individual differences were important (in that some individuals were inherently more likely to generate ideas that followed the existing problem paradigm while others were more likely to generate paradigm-modifying ideas that attempted to change the problem paradigm), the exposure to paradigm-modifying ideas from others and the use of intuitive groupware-based creativity techniques rather than analytical groupware-based creativity techniques were found to increase the number of paradigm-modifying ideas produced."
/doi/10.1287/mnsc.1080.0911," Can investors with incorrect beliefs survive in financial markets and have a significant impact on asset prices? My paper addresses this issue by analyzing a dynamic general equilibrium model where some investors have rational expectations, whereas others have incorrect beliefs concerning the mean growth rate of the economy. The main result is that an investor can survive if and only if he has the lowest survival index, which is a function of his belief accuracy, patience parameter, and relative risk aversion coefficient. If preferences are held constant across all investors, then those with incorrect beliefs cannot survive in the limit, although calibrations reveal that the selection process is excessively slow. However, if preferences vary across investors, even slightly, it becomes possible for an irrational investor to dominate the market even if his beliefs persistently and substantially deviate from the truth."
/doi/10.1287/orsc.2018.1202," As the economy becomes more information based, firms are increasingly using crowdsourced public goods as inputs for innovation and production. Counterintuitively, some firms pay their employees to contribute to the creation of these goods, which can be used freely by their competitors. This study argues that such firms learn by contributing as they receive feedback from the crowd of more experienced users and are therefore able to better capture value from using the goods. Data on firm contributions to open source software (OSS), an important crowdsourced public good, is used to test the theoretical predictions. Using matching and panel data methods to help address endogeneity concerns, this study shows that contributing firms capture up to 100% more productive value from usage of OSS than their free-riding peers. Furthermore, this paper examines what types of contributions are most beneficial and in what technological environments such learning can best be applied."
/doi/10.1287/mnsc.2020.3910," To prevent the spread of an infection, an organization obeys social distancing restrictions and thus limits the number of its members physically present on a given day. We study rotation schemes in which mutually exclusive groups are active on different days. The frequency of rotation affects risk over the duration of diffusion prior to the time the organization is able to react to the infection. If this reaction time is speedy, then such risk is undesirable because prevalence is initially convex in time. In this case, frequent rotation acts as insurance against exposure-time risk and is optimal. Infrequent rotation becomes optimal if the organization reacts slowly. Cross-mixing of the rotating subpopulations is detrimental because it increases contacts between sick and healthy individuals. However, the effect of mixing is small if the terminal prevalence is low in the absence of mixing. This paper was accepted by Joshua Gans, business strategy."
/doi/10.1287/mnsc.2020.3920," Entrepreneurs must choose between alternative strategies for bringing their idea to market. They face uncertainty regarding both the quality of their idea as well as the efficacy of each strategy. Although entrepreneurs can reduce this uncertainty by conducting tests, any single test conflates the signal of the efficacy of the particular strategy and the quality of the idea. Resolving this conflation requires exploring multiple strategies. Consequently, entrepreneurial choice is enhanced by finding ways to lower the cost of testing multiple strategies, receiving guidance as to the types of tests likely to reduce signal conflation, and optimally sequencing tests based on previous beliefs. This creates a role for judgment that may be provided by trusted third parties such as mentors and investors. We hypothesize that institutions that lower the cost of transmitting and aggregating judgment spur entrepreneurial performance. This paper was accepted by David Simchi-Levi, Special Section of Management Science: 65th Anniversary."
/doi/10.1287/isre.11.2.105.11780," Prior research has generated considerable knowledge about the design of effective IT organizational architectures. Today, however, increasing signs have accumulated that this wisdom might be inadequate in shaping appropriate insights for contemporary practice. This essay seeks to direct research attention toward the following question: How should firms organize their IT activities in order to manage the imperatives of the business and technological environments in the digital economy? We articulate the platform logic as a conceptual framework for both viewing the organizing of IT management activities as well as for framing important questions for future research. In articulating this logic, we aim to shift thinking away from the traditional focus on governance structures (i.e., choice of centralized, decentralized, or federal forms) and sourcing structures (i.e., insourcing, outsourcing) and toward more complex structures that are reflective of contemporary practice. These structures are designed around important IT capabilities and network architectures."
/doi/10.1287/mnsc.2020.3645," Using a multitier mapping of supply-chain relationships constructed from granular global, firm-to-firm supplier–customer linkages data, we quantify the degree of financial risk propagation from the supply network beyond firms’ direct supply-chain connections and isolate structural network properties serving as significant moderators of risk propagation. We first document a baseline fact: a significant proportion of tier-2 suppliers are shared by tier-1 suppliers. We then construct two simple metrics to capture the degree of tier-2 sharing and disentangle its effect from tier-2 suppliers’ own risks. We show that the focal firms’ risk levels are significantly related to the proportion of shared tier-2 suppliers in their supply network, and the effect becomes monotonically stronger as their tier-2 suppliers become more highly shared. Finally, we uncover causal relationships behind these associations using a new source of exogenous, idiosyncratic risk events in an event study setting. We show that, as tier-2 suppliers are impacted by these events, focal firms experience negative abnormal returns, the magnitude of which is significantly larger when the impacted tier-2 suppliers are more heavily shared. Overall, our study uncovers the subtier network structure as an important risk source for the focal firm, with the degree of tier-2 sharing as the main moderator. Our results also provide the microfoundation for a common structure in idiosyncratic risks and suggest the importance of incorporating the effect of subtier supply network structure in the portfolio-optimization process. This paper was accepted by Vishal Gaur, operations management."
/doi/10.1287/inte.1060.0274," The United States Commercial Aviation Partnership (USCAP), a group of government and industry stakeholders, combined several operations research methods in an analytical process and model that encompasses the US commercial aviation industry, including travelers, airlines, airports, airline and airport suppliers, government agencies, and travel and tourism entities. With input from these stakeholders, the model, combining system dynamics and econometrics, evaluates the effects of proposed security measures over 25 years. It enables all stakeholders to share a common understanding of these effects and helps government decision makers to improve security without undue and unforeseen operational and economic impact. The model uses linear and nonlinear programming, single and multivariate regression, system dynamics, econometrics, and Monte Carlo simulation. Since 2004, the government has considered the model results in determining policies for screening and credentialing airport employees, screening passengers and cargo, determining security staffing levels, and charging security fees. All participating stakeholders reviewed each analysis for acceptability. Based on the model’s success, they envision extending its use to include nonsecurity policy issues. September 11, 2001, the day commercial airplanes became weapons of mass destruction, is personal to many of us and has changed our perspectives on our lives and our world. The official death toll in the attacks was 2,986, including the airline passengers and airline crew members, workers and visitors in the World Trade Center and the Pentagon, the police and firefighters, and the 19 hijackers. The US Federal Aviation Administration (FAA) halted all flight operations at the nation’s airports for the first time in US history and swiftly grounded the approximately 5,000 commercial aircraft that were in flight. Only military aircraft were flying over the US for the rest of that and the next few days. The events of that day left the airline industry and its supporting companies financially devastated."
/doi/10.1287/mnsc.2014.2003," This paper examines voluntary disclosures in a repeated oligopoly and their association with price-setting behavior and industry profits along industrial fluctuations. The analysis focuses on the collectively optimal equilibrium among oligopoly firms. We show that, in industries that are highly concentrated or feature low cost of capital, nondisclosure is prevalent and results in stable product prices and high profit margins. Otherwise, firms may selectively disclose to soften competition in the product market. Under partial disclosure, firms withhold information during sharp industry expansions or declines. Consequently, the disclosure policy dampens the dissemination of shocks to the industry. This paper was accepted by Mary Barth, accounting ."
/doi/10.1287/opre.2016.1565," We consider a family of discrete time multihop switched queueing networks where each packet moves along a fixed route. In this setting, BackPressure is the canonical choice of scheduling policy; this policy has the virtues of possessing a maximal stability region and not requiring explicit knowledge of traffic arrival rates. BackPressure has certain structural weaknesses because implementation requires information about each route, and queueing delays can grow super-linearly with route length. For large networks, where packets over many routes are processed by a queue, or where packets over a route are processed by many queues, these limitations can be prohibitive. In this article, we introduce a scheduling policy for first-in, first-out networks, the ProportionalScheduler, which is based on the proportional fairness criterion. We show that, like BackPressure, the ProportionalScheduler has a maximal stability region and does not require explicit knowledge of traffic arrival rates. The ProportionalScheduler has the advantage that information about the network’s route structure is not required for scheduling, which substantially improves the policy’s performance for large networks. For instance, packets can be routed with only next-hop information and new nodes can be added to the network with only knowledge of the scheduling constraints."
/doi/10.1287/mnsc.44.6.812," This paper argues that it is wrong to require that regressing the outputs of a trace-driven simulation on the observed real outcomes should give a 45° (unit slope) line through the origin (zero intercept). This note proposes instead an alternative requirement: the responses of the simulated and the real systems should have the same means and the same variances. To test statistically whether this requirement is satisfied, a novel procedure is derived: regress the differences between simulated and real responses on their associated sums, and test whether the resulting intercept and slope are both zero. This novel but simple test assumes identically, independently, and normally distributed outputs of the real system and the simulated system. The old and the new procedures are investigated in extensive Monte Carlo experiments that simulate M / M /1 queueing systems. The conclusions are: (i) the naive intuitive test rejects a valid simulation model substantially more often than the novel test does; (ii) the naive test shows “perverse” behavior within a certain domain: the worse the simulation model, the higher its estimated probability of acceptance; and (iii) the novel test does not reject a valid simulation model too often (its type I error probability is correct), provided the queueing response is transformed appropriately to obtain (nearly) normally distributed responses."
/doi/10.1287/isre.2019.0873," The underlying premise of referral marketing is to target existing, ostensibly delighted customers to spread awareness and influence adoption of a focal product among their friends who are also likely to benefit from adopting the product. In other words, referral programs are designed to accelerate organic word-of-mouth (WOM) exposure using financial incentives. This poses a challenge, in that it mixes an intrinsically motivated process (stemming from the desire to share a customer’s delight with a product or a service) with an extrinsic trigger in the form of a financial incentive. Prior research has shown that mixing intrinsic and extrinsic motivations can lead to suboptimal outcomes, which, in turn, presents a conceptual dilemma in the design of referral programs. In this paper, we demonstrate how firms can benefit from framing calls-to-action for referral programs in such a way as to move closer to the original intent of organic, intrinsically motivated WOM marketing and yet at the same time reap the benefits of using a financial incentive to increase referral rates. In particular, given a fixed incentive scheme, ceteris paribus , we show the efficacy of a prosocial call-to-action over some of the more commonly used calls-to-action observed in practice. We posit, and causally demonstrate via a large-scale randomized field experiment involving 100,000 customers, that an intrinsically prosocial element in framing the call-to-action to initiate the referral process is a necessary condition for success. When contrasted with egoistic and equitable framing of calls-to-action, the prosocial framing yields a significantly higher propensity to initiate a referral, as well as a significantly higher number of successful referrals. Additional mechanism-level analysis that interacts the treatments with customer characteristics such as repeat purchase, net promoter score, and time since last purchase, an additional field experiment with more attractive referral reward and an Amazon Mechanical Turk experiment confirm the importance of an altruistic element in generating a higher quality of advocacy and reducing referral frictions. Subjects in the prosocial group report lower levels of guilt associated with sending a referral and are more able to identify family and friends’ benefit as a motive for sharing referrals and therefore are more selective in sharing the referral message."
/doi/10.1287/serv.2014.0086," Information-intensive service (IIS) is a type of service in which information interactions have the most effect on service value creation. Recent innovations of information and communication technology have created various types of IISs, and the literature argues that IIS should be a research priority in this information economy. This research proposes a new service blueprinting framework specialized to IISs, called the Information Service Blueprint. The framework user can succinctly capture the big-picture and key points of the complex IIS process in question by blueprinting an IIS. The Information Service Blueprint has served as a basis for blueprinting IISs in IIS design projects with industry and government. An experiment to compare the Information Service Blueprint with the conventional service blueprint also confirms its utility for blueprinting IISs. This research would serve as a basis for analyzing and designing IISs."
/doi/10.1287/mnsc.2015.2181," This paper examines the performance of new online lending markets that rely on nonexpert individuals to screen their peers’ creditworthiness. We find that these peer lenders predict an individual’s likelihood of defaulting on a loan with 45% greater accuracy than the borrower’s exact credit score (unobserved by the lenders, who only see a credit category). Moreover, peer lenders achieve 87% of the predictive power of an econometrician who observes all standard financial information about borrowers. Screening through soft or nonstandard information is relatively more important when evaluating lower-quality borrowers. Our results highlight how aggregating over the views of peers and leveraging nonstandard information can enhance lending efficiency. This paper was accepted by Amit Seru, finance."
/doi/10.1287/opre.2016.1490," We study decentralized markets involving producers and consumers that are facilitated by middlemen. We do this by analyzing a noncooperative networked bargaining game. We assume a complete information setup wherein all the agents know the structure of the network, the values of the consumers, and the transaction costs involved but allow for some search friction when either producers or consumers trade with middlemen. In such a setting, we show that sunk cost problems and a heterogeneous network can give rise to delay or failure in negotiation, and therefore reduce the total trade capacity of the network. In the limiting regime of extremely patient agents, we provide a sharp characterization of the trade pattern and the segmentation of these markets."
/doi/10.1287/orsc.2013.0871," We apply the exploitation/exploration dichotomy faced by organizations in business strategy to the decisions of individual executives as to whether to continue in their current organization and exploit career opportunities there or explore new ones through the avenue of job search. Specifically, we observe whether executives pursue offers from an executive search firm to be considered for positions at other organizations. Insights from the multi-armed bandit problem help explain who searches and who does not, focusing on the structural attributes of each individual’s situation. Individuals are more likely to search where their current roles are less certain and where broader career experience makes search more useful because the array of possible opportunities is greater. The results also shed light on the operations of executive search firms, who are central actors in executive careers."
/doi/10.1287/mnsc.2018.3196," When complex procurement projects are conducted, it is often not possible to write complete contracts. As a consequence, the relationship between buyer and supplier is important for the success of the project. In this paper we investigate the claim that auctions in procurement can be detrimental for the buyer–supplier relationship, which is in line with the observation that reverse auctions are less frequently conducted if projects are complex. A poor relationship can result in a decrease in trust on the part of the buyer during the sourcing process and an increase in the supplier’s opportunistic behavior following sourcing. We consider a setting in which the winning supplier decides on the level of quality to provide to the buyer, and we compare a standard reverse auction and a buyer-determined reverse auction, both analytically and in the laboratory. We find that the buyer-determined reverse auction can perform better than the standard reverse auction from both the buyer’s and the suppliers’ perspective. In a buyer-determined reverse auction, it may be optimal for the buyer to select the supplier who submitted a higher bid, which may in turn induce this supplier to deliver higher quality. Standard auctions, however, yield lower prices but reduce cooperation. The degree of trust, as reflected by a larger number of transactions and a higher average efficiency of trade, is significantly higher in buyer-determined reverse auctions. Theoretical reasoning based on other-regarding preferences organizes our data well. This paper was accepted by Serguei Netessine, operations management."
/doi/10.1287/inte.2018.0942," Omnichannel distribution, which blends brick-and-mortar retailing and e-commerce, is a key challenge for today’s supply chains. In this paper, we report on a study to design an omnichannel distribution system for Total Hockey, a growing U.S. sporting goods retailer in a competitive environment. Management strongly believes that e-commerce success will depend on high service levels characterized by one- or two-day delivery and initially thought that a new omnichannel warehouse located on the East Coast could support its expansion plans. To study the situation, we developed a profit-maximizing optimization model for locating omnichannel warehouses that supports both e-commerce and store shipments. The model uses estimates of e-commerce demand by metropolitan statistical area (MSA) across the United States, while incorporating management’s sales expectations regarding the value of high service levels, e-commerce sales lost to competitors’ stores, and reverse cannibalism from Total Hockey’s own retail stores. Multiple warehouse sizes allow modeling of nonlinear inventory costs. The facility-location optimization model allows exploration of multiple solutions and an assessment of the impact of higher service levels. The results of the study were contrary to management expectations and suggested a significant redesign of the distribution system. We report results for several analyses, implementation details, and managerial insights for omnichannel distribution."
/doi/10.1287/trsc.2019.0928," This paper studies the economic desirability of unmanned aerial vehicle (UAV) parcel delivery and its effect on e-retailer distribution networks while taking into account technological limitations, government regulations, and customer behavior. We consider an e-retailer offering multiple same-day delivery services including a fast UAV service and develop a distribution network design formulation under service-based competition where the services offered by the e-retailer not only compete with the stores (convenience, grocery, etc.) but also with each other. Competition is incorporated using the multinomial logit market share model. To solve the resulting nonlinear mathematical formulation, we develop a novel logic-based Benders decomposition approach. We build a case based on New York City, carry out extensive numerical testing, and perform sensitivity analyses over delivery charge, delivery time, government regulations, technological limitations, customer behavior, and market size. The results show that government regulations, technological limitations, and service charge decisions each play a vital role in the future of UAV delivery."
/doi/10.1287/mnsc.2018.3248," We analyze a general equilibrium model in which financial institutions generate endogenous systemic risk. Banks optimally select correlated investments and thereby expose themselves to fire-sale risk so as to sharpen their incentives. Systemic risk is therefore a natural consequence of banks’ fundamental role as delegated monitors. Our model sheds light on recent and historical trends in measured systemic risk. Technological innovations and government-directed lending can cause surges in systemic risk. Strict capital requirements and well-designed government-asset purchase programs can combat systemic risk. This paper was accepted by Gustavo Manso, finance."
/doi/10.1287/mnsc.48.7.834.2816," In this paper, we analyze the variance of accounting profitability among a broad cross-section of forms in the American economy from 1981 to 1994. The purpose of the analysis is to identify the importance of year, industry, corporate-parent, and business-specific effects on accounting profitability among operating businesses across sectors. The findings indicate that industry and corporate-parent effects are important and related to one another. As expected, business-specific effects, which arise from competitive positioning and other factors, have a large influence on performance. The analysis reconciles the results of previous studies by exploring differences in method and data. We also identify the broad contributions and limitations of the research, and suggest avenues for further study. New approaches are necessary to generate significant insights about the relationships between industry, corporate-parent, and business influences on firm profitability."
/doi/10.1287/mnsc.38.8.1154," This is a study of the economic behavior of vendors of service in competition. A simple model with two competing exponential servers and Poisson arrivals is considered. Each server is free to choose his own service rate at a cost (per time unit) that is strictly convex and increasing. There is a fixed reward to a server for each customer that he serves. The model is designed to study one specific aspect of competition, namely, competition in speed of service as a means for capturing a larger market share in order to maximize long-run expected profit per time unit. A two-person strategic game is formulated and its solutions are characterized. Depending on the revenue per customer served and on the cost of maintaining service rates, the following three situations may arise: (i) a unique symmetric strategic (Nash) equilibrium in which expected waiting time is infinite; (ii) a unique symmetric strategic equilibrium in which expected waiting time is finite; and (iii) several, nonsymmetric strategic equilibria with infinite expected waiting time. An explicit expression for the market share of each server as a function of the service rates of the two servers is also given."
/doi/10.1287/serv.2013.0060," The transition to a service economy through the transformation of social structures has become a global phenomenon that affects research and development (R&D) organizations. However, the innovation and R&D management literatures are mainly rooted in product development based on technological trajectories, which is not necessarily applicable to services. To fill this gap, the field of service marketing has introduced the service-dominant logic perspective, which does not separate services from goods. This paper proposes a new R&D model focusing on value cocreation through the study of a technology-based R&D unit in the information technology company. A set of hypotheses was developed and tested using data from R&D activities related to service innovation projects. The findings suggest that the technology developed through R&D contributes to value cocreation interactions between the R&D organization and the customer, which are facilitated by mutual organizational understanding. They also contribute to the discovery of research themes. The result is the emergence of a new type of service-oriented researcher who focuses not only on creating new technologies and adapting them to the customer site but also on discovering research themes by broadening the scope of research to the creation of new service systems. The managerial implications and limitations of these findings are discussed."
/doi/10.1287/mnsc.13.1.22," The decision of a company in the selection of a technological business area to exploit is a difficult one to make because of the many complex factors involved and the uncertainties of predicting future events. To assist the management decision processes, a mathematical model is developed which relates the many factors such as company capability, time, market, competition, investment and costs to the expected economic gain over time. The basis of the model presupposes that the markets of interest are composed of many product areas in which companies will compete for a share. Thus, the model is concerned with two opposing forces (competition versus the company) trying to penetrate the same available product area simultaneously over a given time period. In addition to the model formulation several basic types of markets are analyzed as to their effect on the various economic factors. Also, the effect of the investment program in the market penetration is exhibited as well as the effect of loss in market shares on the maximum economic gain."
/doi/10.1287/serv.2016.0162," Our aim in this paper is to develop a specialized model of service engagement in the design of services. We build on some widely accepted constructions of service science that have appeared in the literature to produce a model that is relevant and useful in our context: technology-enabled services. We do this by conducting a field study in the telecommunications industry in a developing economy. We believe that this context is important to study due to the rapidly increasing rate of design and delivery of such services in emerging economies. By integrating existing frameworks and incorporating the results from our own findings, we present an experience-based service system model that explicitly includes consumer participation in the service design process. The main outcome of our data analysis is the characterization of the multidimensional nature of services based on three different ontological frameworks from the literature. Our model of service engagement does not devalue any of the earlier models; however, it provides a holistic understanding of services research especially around interactions and technology-enabled service design. Our model has the potential to advance service science research in an integrated and applied manner."
/doi/10.1287/opre.7.2.145," It is shown that common-stock prices, and the value of money can be regarded as an ensemble of decisions in statistical equilibrium, with properties quite analogous to an ensemble of particles in statistical mechanics. If Y = log e [ P ( t + r )/ P 0 ( t )], where P ( t + r ) and P 0 ( t ) are the price of the same random choice stock at random times t + r and t , then the steady state distribution function of Y is , which is precisely the probability distribution for a particle in Browman motion, if σ is the dispersion developed at the end of unit time. A similar distribution holds for the value of money, measured approximately by stock-market indices. Sufficient, but not necessary conditions to derive this distribution quantitatively are given by the conditions of trading, and the Weber-Fechner law. A consequence of the distribution function is that the expectation values for price itself ℰ( P ) = ∫ 0 ∞ P φ( Y )( dY / dP ) dP increases, with increasing time interval τ, at a rate of 3 to 5 per cent per year, with increasing fluctuation, or dispersion, of P . This secular increase has nothing to do with long-term inflation, or the growth of assets in a capitalistic economy, since the expected reciprocal of price, or number of shares purchasable in the future, per dollar, increases with τ in an identical fashion."
/doi/10.1287/serv.2015.0103," Although services are often defined as co-productive of value, the concept of value is often difficult to measure. Yet measuring value is not necessarily a prerequisite for service process improvement. In this paper, we propose a general framework for the modeling and analysis of services with co-production. The framework identifies three major process stages: (i) the production stage, which involves co-production, (ii) the output sharing stage, and (iii) the consumption stage. Value realization and distribution depends on all three stages. Using our framework, we argue that process improvement efforts may often shift away from value measurement to focus on more actionable levers such as the co-production process, the rules of operation, and sharing rules. Furthermore, we use our framework to discuss a broader perspective on value measurement, the application of the gap quality model to co-productive process management, the distinction between products and services, and the impact of information and communication technologies on service processes."
/doi/10.1287/opre.2016.1544," Combinatorial allocation involves assigning bundles of items to agents when the use of money is not allowed. Course allocation is one common application of combinatorial allocation, in which the bundles are schedules of courses and the assignees are students. Existing mechanisms used in practice have been shown to have serious flaws, which lead to allocations that are inefficient, unfair, or both. A recently developed mechanism is attractive in theory but has several features that limit its feasibility for practice. This paper reports on the design and implementation of a new course allocation mechanism, Course Match, that is suitable in practice. To find allocations, Course Match performs a massive parallel heuristic search that solves billions of mixed-integer programs to output an approximate competitive equilibrium in a fake-money economy for courses. Quantitative summary statistics for two semesters of full-scale use at a large business school (the Wharton School of Business, which has about 1,700 students and up to 350 courses in each semester) demonstrate that Course Match is both fair and efficient, a finding reinforced by student surveys showing large gains in satisfaction and perceived fairness."
/doi/10.1287/mnsc.49.3.312.12739," Credit-risk evaluation is a very challenging and important management science problem in the domain of financial analysis. Many classification methods have been suggested in the literature to tackle this problem. Neural networks, especially, have received a lot of attention because of their universal approximation property. However, a major drawback associated with the use of neural networks for decision making is their lack of explanation capability. While they can achieve a high predictive accuracy rate, the reasoning behind how they reach their decisions is not readily available. In this paper, we present the results from analysing three real-life credit-risk data sets using neural network rule extraction techniques. Clarifying the neural network decisions by explanatory rules that capture the learned knowledge embedded in the networks can help the credit-risk manager in explaining why a particular applicant is classified as either bad or good. Furthermore, we also discuss how these rules can be visualized as a decision table in a compact and intuitive graphical format that facilitates easy consultation. It is concluded that neural network rule extraction and decision tables are powerful management tools that allow us to build advanced and userfriendly decision-support systems for credit-risk evaluation."
/doi/10.1287/mnsc.2017.2757," Suppose that a firm in charge of a business ecosystem is a firm in charge of a microeconomy. To achieve the highest growth rate, how open should that economy be? To encourage third-party developers, how long should their intellectual property interests last? We develop a sequential innovation model that addresses the trade-offs inherent in these two decisions: (i) Closing the platform increases the sponsor’s ability to charge for access, while opening the platform increases developer ability to build upon it. (ii) The longer third-party developers retain rights to their innovations, the higher the royalties they and the sponsor earn, but the sooner those developers’ rights expire, the sooner their innovations become a public good upon which other developers can build. Our model allows us to characterize the optimal levels of openness and of intellectual property (IP) duration in a platform ecosystem. We use standard Cobb–Douglas production technologies to derive our results. These findings can inform innovation strategy, choice of organizational form, IP noncompete decisions, and regulation policy. This paper was accepted by Chris Forman, information systems."
/doi/10.1287/orsc.2020.1392," It is well established that the effectiveness of pay-for-performance (PfP) schemes depends on employee- and organization-specific factors. However, less is known about the moderating role of external forces such as market competition. Our theory posits that competition generates two counteracting effects—the residual market and competitor response effects—that vary with competition and jointly generate a curvilinear relationship between PfP effectiveness and competition. Weak competition discourages effort response to PfP because there is little residual market to gain from rivals, whereas strong competition weakens incentives because an offsetting response from competitors becomes more likely. PfP hence has the strongest effect under moderate competition. Field data from a bakery chain and its competitive environment confirm our theory and let us refute several alternative interpretations."
/doi/10.1287/isre.1100.0320," Online participation engenders both the benefits of knowledge sharing and the risks of harm. Vigilant interaction in knowledge collaboration refers to an interactive emergent dialogue in which knowledge is shared while it is protected, requiring deep appraisals of each others' actions in order to determine how each action may influence the outcomes of the collaboration. Vigilant interactions are critical in online knowledge collaborations under ambivalent relationships where users collaborate to gain benefits but at the same time protect to avoid harm from perceived vulnerabilities. Vigilant interactions can take place on discussion boards, open source development, wiki sites, social media sites, and online knowledge management systems and thus is a rich research area for information systems researchers. Three elements of vigilant interactions are described: trust asymmetry, deception and novelty. Each of these elements challenges prevailing theory-based assumptions about how people collaborate online. The study of vigilant interaction, then, has the potential to provide insight on how these elements can be managed by participants in a manner that allows knowledge sharing to proceed without harm."
/doi/10.1287/serv.2019.0240," The tourism supply chain literature has predominantly focused on price-sensitive demand and ignored the service-sensitive demand issue. In competitive practice, price- and service-sensitive demand plays a significant role for the tourists in selecting a tour package. This paper discusses a case where two tour operators compete on price and service to offer tour packages and serve the customers through a common local operator. We develop a mathematical model for a tourism supply chain under three scenarios: (i) a decentralized scenario, (ii) an integrated channel scenario, and (iii) a global scenario. The results show that the tourism supply chain generates more profit in competition than it does without competition. Furthermore, we found that coordination among supply chain members with a surplus sharing contract improves the overall tourism supply chain profit compared with the decentralized scenario."
/doi/10.1287/msom.1040.0059," One way to organize workers that lies between traditional assembly lines, where workers are specialists, and craft assembly, where workers are generalists, are “bucket brigades.” We describe how one firm used bucket brigades as an intermediate strategy to migrate from craft assembly to assembly lines. The adoption of bucket brigades led to a narrowing of tasks for each worker and thus accelerated learning. The increased production more than compensated for the time lost when workers walk back to get more work, which was significant in this implementation. To understand the trade-offs in migrating from craft to assembly lines, we extend the standard model of bucket brigades to capture hand-off and walk-back times."
/doi/10.1287/serv.3.1.99," The paradigm of cloud computing has started a new era of service computing. While there are many research efforts on developing enabling technologies for cloud computing, few focuses on how to strategically set price and capacity and what key components are leading to success in this emerging market. In this paper, we present quantitative modeling and optimization approaches for assisting such decisions in cloud computing services. We first show that learning curve models can be helpful to capture the providers' cost reduction with economy of scale. Such models also help understand the potential market of cloud services and explain quantitatively why cloud computing is most attractive to small and medium businesses. We then present a stochastic model and a revenue management formulation to address the pricing and resource provisioning decisions for the cloud service providers. The approach enables the cloud service provider a quantitative framework to obtain management solutions and to learn and react to the critical parameters in the operation management process by gaining useful business insights. [ Service Science , ISSN 2164-3962 (print), ISSN 2164-3970 (online), was published by Services Science Global (SSG) from 2009 to 2011 as issues under ISBN 978-1-4276-2090-3.]"
/doi/10.1287/mnsc.2017.2901," Can raising awareness of racial bias subsequently reduce that bias? We address this question by exploiting the widespread media attention highlighting racial bias among professional basketball referees that occurred in May 2007 following the release of an academic study. Using new data, we confirm that racial bias persisted in the years after the study’s original sample but prior to the media coverage. Subsequent to the media coverage, though, the bias disappeared. Several potential mechanisms may have produced this result, including voluntary behavior changes by individual referees, adjustments by players to new information, and changes in referee behavior due to institutional pressure. These results suggest a new kind of Hawthorne effect in which greater scrutiny of even subtle forms of bias can bring about meaningful change. This paper was accepted by John List, behavioral economics."
/doi/10.1287/inte.32.5.74.37," One area in which experimental economics methods have been used to study operations problems is supply-chain management. We survey results from a series of human experiments based on the popular beer distribution game and find cognitive limitations on the part of managers, in particular an underweighting of the supply line. We suggest mechanisms that may alleviate this bias, including sharing inventory and point-of-sale data, and reducing ordering and shipping delays. Our research provides managerial lessons and identifies supply-chain issues that need further experimental study."
/doi/10.1287/mnsc.2018.3282," We study the optimal referral strategy of a seller and its relationship with the type of communication channels among consumers. The seller faces a partially uninformed population of consumers, interconnected through a directed social network. In the network, the seller offers rewards to informed consumers (influencers) conditional on inducing purchases by uninformed consumers (influenced). Rewards are needed to bear a communication cost and to induce word of mouth (WOM) either privately (cost per contact) or publicly (fixed cost to inform all friends). From the seller’s viewpoint, eliciting Private WOM is more costly than eliciting Public WOM. We investigate (1) the incentives for the seller to move to a denser network, inducing either Private or Public WOM, and (2) the optimal mix between the two types of communication. A denser network is found to be always better not only for information diffusion but also for seller’s profits, as long as Private WOM is concerned. Differently, under Public WOM, the seller may prefer an environment with less competition between informed consumers, and the presence of highly connected influencers (hubs) is the main driver to make network density beneficial to profits. When the seller is able to discriminate between Private and Public WOM, the optimal strategy is to cheaply incentivize the more connected people to pass on the information publicly and then offer a high bonus for Private WOM. This paper was accepted by Juanjuan Zhang, marketing."
/doi/10.1287/isre.1060.0104," Prior research suggests that supply chain collaboration has enabled companies to compete more efficiently in a global economy. We investigate a class of collaboration software for product design and development called collaborative product commerce (CPC). Drawing on prior research in media richness theory and organizational science, we develop a theoretical framework to study the impact of CPC on product development. Based on data collected from 71 firms, we test our research hypotheses on the impact of CPC on product design quality, design cycle time, and development cost. We find that CPC implementation is associated with greater collaboration among product design teams. This collaboration has a significant, positive impact on product quality and reduces cycle time and product development cost. Further analyses reveal that CPC implementation is associated with substantial cost savings that can be attributed to improvements in product design quality, design turnaround time, greater design reuse, and lower product design documentation and rework costs."
/doi/10.1287/opre.2019.1952," We propose a framework to model dependence of outages of electric power plants. Our framework allows for common factors, such as weather events and fuel shortages, to drive outages. We calibrate our model for power plants in the Electric Reliability Council of Texas and the Western Electricity Coordinating Council regions using a unique data set of actual outages from the North American Electric Reliability Corporation. We find strong evidence of dependence in power plant outages based on the input fuel of the plants and illustrate how our framework can be used to evaluate the reliability of the supply of electricity for both regions, and also the impact on reliability of building additional capacity."
/doi/10.1287/orsc.2021.1491," This paper studies philanthropy by multinational enterprises (MNEs) during institutional disruptions—the sudden and unexpected, temporary, and systemic breakdowns in market-oriented institutions. The central argument is that, under institutional disruptions, MNEs aim to restore factors that are essential for the market to function, such as infrastructure and labor markets, and the strength of the market restoration motive is positively associated with the economic importance of the affected country to the MNE. Analyses of donations from 2,000 MNEs headquartered in 63 countries in the aftermath of 265 major epidemics, natural disasters, and terrorist attacks affecting 129 countries suggest that the economic importance of the country to the firm strongly explains donations. Country market concentration, public aid, and the country’s regulatory quality moderate this effect. These associations are robust to a matching method; a vector of firm-, country-, and event-specific time-varying and -constant variables; and alternative motives, such as reputation, altruism, media salience, market standing, and poverty-gap avoidance. They offer evidence that company philanthropy in the aftermath of institutional disruptions may deviate from predicted behavior under stable conditions. Particularly, the findings contest the expectation that philanthropy rises in market competition. Monopolistic firms are comparatively large donors and may act as an economic stop-loss mechanism during large disruptions."
/doi/10.1287/mnsc.2020.3634," We study the impact of consumers’ risk perception on firm innovation. Our analysis exploits a major surge in the perceived risk of radiation diagnostic devices following extensive media coverage of a set of overradiation accidents involving computed tomography (CT) scanners in late 2009. Using data on radiation diagnostic device patents and Food and Drug Administration (FDA) product clearances, we find that the increased perception of radiation risk spurred the development of new technologies that mitigated such risk and led to a greater number of new products. Using CT scanners as a case study, we provide an in-depth characterization of two different types of risk-mitigating technologies that firms developed after the shock. Firm-level analysis shows that, although firms were similarly responsive in their patenting activities, large incumbents were significantly more responsive than smaller firms in terms of new product introductions, and, in the case of CT scanners, large incumbents were also significantly more responsive in terms of the more radical type of risk-mitigating technologies. We also provide qualitative evidence and describe patterns of equipment usage and upgrade that are consistent with increased risk perception and, consequently, a greater willingness to pay for safety. Overall, our findings suggest that changes in risk perception can be an important driver of innovation, can shape the direction of technological progress, and can impact market structure. This paper was accepted by Ashish Arora, entrepreneurship and innovation."
/doi/10.1287/mnsc.2015.2317," We estimate risk aversion from investors’ financial decisions in a person-to-person lending platform. We develop a method that obtains a risk-aversion parameter from each portfolio choice. Since the same individuals invest repeatedly, we construct a panel data set that we use to disentangle heterogeneity in attitudes toward risk across investors, from the elasticity of risk aversion to changes in wealth. We find that wealthier investors are more risk averse in the cross section and that investors become more risk averse after a negative housing wealth shock. Thus, investors exhibit preferences consistent with decreasing relative risk aversion and habit formation. Data, as supplemental material, are available at http://dx.doi.org/10.1287/mnsc.2015.2317 . This paper was accepted by Amit Seru, finance ."
/doi/10.1287/orsc.12.2.198.10116," While the recent focus on knowledge has undoubtedly benefited organizational studies, the literature still presents a sharply contrasting and even contradictory view of knowledge, which at times is described as “sticky” and at other times “leaky.” This paper is written on the premise that there is more than a problem with metaphors at issue here, and more than accounts of different types of knowledge (such as “tacit” and “explicit”) can readily explain. Rather, these contrary descriptions of knowledge reflect different, partial, and sometimes “balkanized” perspectives from which knowledge and organization are viewed. Taking the community of practice as a unifying unit of analysis for understanding knowledge in the firm, the paper suggests that often too much attention is paid to the idea of community, too little to the implications of practice. Practice, we suggest, creates epistemic differences among the communities within a firm, and the firm's advantage over the market lies in dynamically coordinating the knowledge produced by these communities despite such differences. In making this argument, we argue that analyses of systemic innovation should be extended to embrace all firms in a knowledge economy, not just the classically innovative. This extension will call for a transformation of conventional ideas coordination and of the trade-off between exploration and exploitation."
/doi/10.1287/mnsc.2016.2618," Multiplicative growth processes that are subject to random shocks often have an asymmetric distribution of outcomes. In a series of incentivized laboratory experiments, we show that a large majority of participants either strongly underestimate the asymmetry or ignore it completely. Participants misperceive the spread of the outcome distribution to be too narrowband, and they estimate the median and the mode to lie too close to the center of the distribution, failing to account for the compound nature of average growth. The observed biases are measured irrespective to risk preferences and they appear under a variety of conditions. The biases are largely consistent with a behavioral model in which geometric growth is confused with linear growth. This confusion is a possible driver of investors’ difficulties with real-world financial products like leveraged exchange-traded funds and retirement savings plans. Data and the online appendix are available at https://doi.org/10.1287/mnsc.2016.2618 . This paper was accepted by Teck-Hua Ho, behavioral economics ."
/doi/10.1287/mnsc.2016.2570," We propose and test an alternative explanation for the existence of the positive governance–return relation in the 1990s and its disappearance in the 2000s: The governance–return relation is positive under good states of the economy and negative under bad states. Corporate governance mitigates investment distortions so that firms with strong governance have more valuable investment options during booms and more valuable divestiture options during busts than the ones with weak governance. Because investment options are riskier and divestiture options are less risky than assets in place, the expected returns of strongly governed firms are higher during booms but lower during busts than the weakly governed ones. Empirical evidence is consistent with our hypothesis. This paper was accepted by Neng Wang, finance ."
/doi/10.1287/mnsc.2013.1795," Top management structures in large U.S. firms have changed significantly since the mid-1980s. The size of the executive team—the group of managers reporting directly to the CEO—doubled during this period. This growth was driven primarily by an increase in functional managers rather than general managers, a phenomenon we term “functional centralization.” Using panel data on senior management positions, we show that changes in the structure of the executive team are tightly linked to changes in firm diversification and information technology investments. These relationships depend crucially on the function involved; those closer to the product (“product” functions, e.g., marketing and R&D) behave differently from functions further from the product (“administrative” functions, e.g., finance, law, and human resources). We argue that this distinction is driven by differences in the information-processing activities associated with each function and apply this insight to refine and extend existing theories of centralization. We also discuss the implications of our results for organizational forms beyond the executive team. This paper was accepted by Bruno Cassiman, business strategy."
/doi/10.1287/mnsc.2020.3811," What is the value of pledges if they are often reneged upon? In this paper, we show—both theoretically and experimentally—that pledges can be used to screen donors and to better understand their motives for giving. In return, nonprofit managers can use the information they glean from pledges to better target future charitable giving appeals and interventions to donors, such as expressions of gratitude. In an experiment, we find that offering the option to pledge gifts induces self-selection. If expressions of gratitude are then targeted to individuals who select into pledges, reneging can be significantly reduced. Our findings provide an explanation for the potential usefulness of pledges. This paper was accepted by Yan Chen, decision analysis."
/doi/10.1287/orsc.2016.1071," A growing body of research explores how employees’ organizational context shapes their entrepreneurial activity. We add to this work by examining how “educational mismatch”—when a job does not utilize the skills an employee has acquired during education—relates to subsequent transitions into entrepreneurship. While prior research has focused on mismatch due to labor market frictions, workers may also enter mismatches for other reasons, such as family obligations or a change in career interests. Different reasons, in turn, may relate in distinct ways to wages and job satisfaction and thus to the opportunity costs of entering entrepreneurship. Moreover, mismatch may also affect human capital development, including the formation of a broader range of skills that is beneficial in entrepreneurship. Using longitudinal data from over 25,000 scientists and engineers, we document a broad range of reasons for educational mismatch and show that the relationships between educational mismatch and wages, job satisfaction, and skill variety differ significantly depending upon the reason for a mismatch. Mismatched individuals are more likely to enter into entrepreneurship in a subsequent period, an effect that goes beyond higher labor mobility per se. Both lower opportunity costs—primarily low job satisfaction—and greater skill variety appear to link educational mismatch to subsequent entrepreneurship. We discuss implications for research, managers, and policy makers."
/doi/10.1287/orsc.2017.1109," Our study presents evidence that social comparison influences both the level of pay and the degree of performance sensitivity within firms. We report pay patterns among division managers of large, multibusiness firms over a 14-year period. These patterns are consistent with employees comparing pay against both their peers (horizontal comparison) and the chief executive officer (vertical comparison) within their firm. Horizontal comparison also appears to reduce pay–performance sensitivity, in accord with prior theory proposing that performance pay can lead to perceived pay inequity among employees. Taken together, our evidence suggests that agency costs and social comparison jointly influence pay within firms. The evidence also supports the notion that managers of multibusiness firms are constrained in the degree to which they can incentivize employees, given the firm-imposed reference group. The online appendix is available at https://doi.org/10.1287/orsc.2017.1109 ."
/doi/10.1287/mnsc.2013.1756," This paper explores the impact of investor flows and financial market conditions on returns in crude oil futures markets. I argue that informational frictions and the associated speculative activity may induce prices to drift away from “fundamental” values, and may result in price booms and busts. Particular attention is given to the interplay between imperfect information about real economic activity, including supply, demand, and inventory accumulation, and speculative activity in oil markets. Furthermore, I present new evidence that there were economically and statistically significant effects of investor flows on futures prices, after controlling for returns in the United States and emerging-economy stock markets, a measure of the balance sheet flexibility of large financial institutions, open interest, the futures/spot basis, and lagged returns on oil futures. The largest impacts on futures prices were from intermediate-term growth rates of index positions and managed-money spread positions. Moreover, my findings suggest that these effects were through risk or informational channels distinct from changes in convenience yield. Finally, the evidence suggests that hedge fund trading in spread positions in futures impacted the shape of term structure of oil futures prices. This paper was accepted by Wei Xiong, finance."
/doi/10.1287/mnsc.1110.1321," To what extent are firms kept out of a market by patents covering related technologies? Do patents held by potential entrants make it easier to enter markets? We estimate the empirical relationship between market entry and patents for 27 narrowly defined categories of software products during the period 1990–2004. Controlling for demand, market structure, average patent quality, and other factors, we find that a 10% increase in the number of patents relevant to market reduces the rate of entry by 3%–8%, and this relationship intensified following expansions in the patentability of software in the mid-1990s. However, potential entrants with patent applications relevant to a market are more likely to enter it. Finally, patents appear to substitute for complementary assets in the entry process, because patents have both greater entry-deterring and entry-promoting effects for firms without prior experience in other markets. This paper was accepted by Bruno Cassiman, business strategy."
/doi/10.1287/mnsc.1100.1221," Faced with the sustained problem of piracy that costs nearly $40 billion in annual revenue losses, the software industry has adopted a number of technical, legal, and economic strategies to curb piracy and stem the resulting losses. Our work complements and contributes to the existing literature by exploring the possible effect of another economic lever—product bundling—on the relationship governing piracy and seller profits. The traditional economic rationale of demand pooling from bundling that enables sellers to extract higher surplus and its particular attractiveness for information goods with negligible marginal and bundling costs carry over to our analysis. However, the presence of piracy injects several new facets to our analysis. Bundling creates a shared level of piracy of disparate products, and under certain conditions to the detriment of one of the products. We argue that by construction of the copyright laws, the act of bundling itself can have a deterrence effect. This deterrence effect, along with shared piracy of products and demand pooling are ingredients that together dictate the overall piracy, pricing, profit, and welfare outcomes. Our analysis reveals several interesting insights. Bundling can be profitable even when the very act of bundling increases the piracy level of one of the products in the bundle. Termed phantom piracy , this represents a situation where sellers trade off higher piracy for one product in favor of lower piracy for the other product while deriving overall higher profits. Extensive simulation analysis shows that the region of phantom piracy is vastly expanded when additional products are introduced to the bundle. Conversely, under certain conditions, a profit maximizing seller opts not to bundle even when bundling can serve to lower the overall level of piracy. Price discounts that are typically offered by bundling are sharply deepened when piracy enters the equation. When piracy is a phenomenon to contend with, product bundling always increases consumer surplus even in scenarios where the seller may not realize higher profits. Unlike other forms of price discrimination that are often viewed by consumers with a jaundiced eye as they attempt to extract additional surplus from the consumers, product bundling in the software context can be a win-win scenario for both the buyers and the sellers."
/doi/10.1287/orsc.1050.0156," Studies of the sources of innovations have recognized that many innovations are developed by users. However, the fact that firms employ communities of users to strengthen their innovation process has not yet received much attention. In online firm-hosted user communities, users freely reveal innovations to a firm's product platform, which can put the firm in a favorable position (a) because these new product features become available to all users through sharing on a user-to-user basis, or (b) because it allows the firm to pick up the innovations and integrate them in future products and then benefit by selling them to all users. We study the key personal attributes of the individuals responsible for innovations, namely the innovative users, to explain creation of value in this organizational context. The main question is why such users contribute to firm-hosted user communities. Analyzing data derived from multiple sources (interviews, a Web-log, and questionnaires), we find that innovative users are likely to be (i) hobbyists, an attribute that can be assumed to (positively) affect innovators' willingness to share innovations, and (ii) responsive to “firm recognition” as a motivating factor for undertaking innovation, which explains their decision to join the firm's domain. In agreement with earlier studies, we also find that innovative users are likely to be “lead users,” an attribute that we assume to affect the quality of user innovation. Whether or not a firm-hosted user community can be turned into an asset for the firm is to a great extent conditional on the issues studied in this paper."
/doi/10.1287/mnsc.2015.2191," The sale of ideas through licensing facilitates the division of labor between the separate activities of research and development. This vertical specialization can improve the overall efficiency of the innovative process. However, these gains depend on the timing of the sale: the buyer of an innovative project should assume development at the stage at which he has an efficiency advantage. Using data from the pharmaceutical industry, we show that competition between potential buyers is related to the timing of licensing. Furthermore, the effect differs by the type of competitor. We then describe a class of models that yields predictions consistent with these empirical patterns. Our key insight is that increased competition may increase licensing delays and hence inefficiency. This paper was accepted by David Hsu, entrepreneurship and innovation ."
/doi/10.1287/inte.30.3.55.11668," Industry and the environment appear to be at odds because current methods of production, extraction, and disposal are destructive to the natural world. Conventional responses, such as eco-efficiency, focus on doing more with less, restricting industry, and curtailing growth. We view the conflict between industry and the environment as a design problem. Instead of simply reducing industry's negative effects, we suggest companies redesign products and processes for healthy, long-term prosperity. We present a new paradigm for industry, eco-effectiveness; three new design principles: waste equals food, use current solar income, and respect diversity; new decision criteria that integrate ecology, economy, and equity; and beginning steps businesses can take towards a world of abundance, rather than one of limits and constraints."
/doi/10.1287/ijoc.2021.1095," Targeted marketing strategies are of significant interest in the smartapp economy. Typically, one seeks to identify individuals to strategically target in a social network so that the network is influenced at a minimal cost. In many practical settings, the effects of direct influence predominate, leading to the positive influence dominating set with partial payments (PIDS-PP) problem that we discuss in this paper. The PIDS-PP problem is NP-complete because it generalizes the dominating set problem. We discuss several mixed integer programming formulations for the PIDS-PP problem. First, we describe two compact formulations on the payment space. We then develop a stronger compact extended formulation. We show that when the underlying graph is a tree, this compact extended formulation provides integral solutions for the node selection variables. In conjunction, we describe a polynomial-time dynamic programming algorithm for the PIDS-PP problem on trees. We project the compact extended formulation onto the payment space, providing an equivalently strong formulation that has exponentially many constraints. We present a polynomial time algorithm to solve the associated separation problem. Our computational experience on a test bed of 100 real-world graph instances (with up to approximately 465,000 nodes and 835,000 edges) demonstrates the efficacy of our strongest payment space formulation. It finds solutions that are on average 0.4% from optimality and solves 80 of the 100 instances to optimality. Summary of Contribution: The study of influence propagation is important in a number of applications including marketing, epidemiology, and healthcare. Typically, in these problems, one seeks to identify individuals to strategically target in a social network so that the entire network is influenced at a minimal cost. With the ease of tracking consumers in the smartapp economy, the scope and nature of these problems have become larger. Consequently, there is considerable interest across multiple research communities in computationally solving large-scale influence maximization problems, which thus represent significant opportunities for the development of operations research–based methods and analysis in this interface. This paper introduces the positive influence dominating set with partial payments (PIDS-PP) problem, an influence maximization problem where the effects of direct influence predominate, and it is possible to make partial payments to nodes that are not targeted. The paper focuses on model development to solve large-scale PIDS-PP problems. To this end, starting from an initial base optimization model, it uses several operations research model strengthening techniques to develop two equivalent models that have strong computational performance (and can be theoretically shown to be the best model for trees). Computational experiments on a test bed of 100 real-world graph instances (with up to approximately 465,000 nodes and 835,000 edges) attest to the efficacy of the best model, which finds solutions that are on average 0.4% from optimality and solves 80 of the 100 instances to optimality."
/doi/10.1287/mnsc.2015.2166," We show that cognitive ability influences mutual fund choice: high-IQ investors avoid funds with high management fees. Two competing stories can explain this phenomenon. One is that high-IQ consumers benefit less from costly services, as they find it easier to make informed financial decisions without external help. The alternative story is that these investors are less likely to overpay for the services they receive because they are either better judges of value or more capable of discerning the price charged for these services. A comprehensive data set of Finnish males’ fund holdings supports both stories: consistent with the first story, high-IQ investors tend to avoid funds sold via expensive service-intensive channels and prefer a mix of equity and bond funds to expensive readily packaged balanced funds. Consistent with the alternative story, IQ and fees are inversely correlated, even after controlling for many fund services, including any operating at the fund family level. This paper was accepted by Wei Jiang, finance."
/doi/10.1287/mksc.2017.1051," Instead of purchasing individual content, streaming adopters rent access to libraries from which they can consume content at no additional cost. In this paper, we study how the adoption of music streaming affects listening behavior. Using a unique panel data set of individual consumers’ listening histories across many digital music platforms, adoption of streaming leads to very large increases in the quantity and diversity of consumption in the first months after adoption. Although the effects attenuate over time, even after half a year, adopters play substantially more, and more diverse, music. Relative to music ownership, where experimentation is expensive, adoption of streaming increases new music discovery. While repeat listening to new music decreases, users’ best discoveries have higher play rates. We discuss the implications for consumers and producers of music. Data and the online appendix are available at https://doi.org/10.1287/mksc.2017.1051 ."
/doi/10.1287/inte.1030.0056," Since 2000, Menlo Worldwide Forwarding (formerly Emery Worldwide) has faced a particularly challenging business environment that has been exacerbated by a weakened economy, the events of September 11, and a decreasing demand for airfreight. To meet these challenges, the company and Menlo Worldwide Technologies developed a network-routing-optimization model to optimize Menlo Worldwide Forwarding$s North American transportation network. The project team and senior managers have repeatedly identified and applied low cost solutions to meet the changing and complex network-routing requirements. By maximizing its use of network capacity, the company has increased profitability and reduced operating costs while maintaining high service levels. In 2002 alone, Menlo Worldwide Forwarding reduced operating costs by 21 percent, increased operating margin by 41 percent, and improved financial results by $80 million in the North American aircraft transportation operation. Moreover, management used the optimization model to facilitate Menlo$s transition from a heavily asset-based, integrated airfreight company to an asset-light, freight-forwarding business. This created a flexible operating environment and a competitive advantage for future operations."
/doi/10.1287/mnsc.2019.3296," Prior work has established that the financing environment can impact firm strategy. We argue that this influence can shape the earliest strategic choices of a new venture by creating a potential trade-off between two objectives: rapid growth and reaping the benefits of a positive reputation (glory). We leverage a simple reputation-building strategic choice—naming the firm after the founder (eponymy)—that is associated with superior profitability. Next, we argue via a formal model that the availability of/dependence on external financing can explain why high-growth firms are rarely eponymous. We find empirical support for the model’s predictions using a large data set of 1 million European firms. Eponymous firms grow considerably more slowly than similarly profitable firms. Moreover, eponymy varies in accordance with the firm’s financing environment in a pattern consistent with our model. We discuss implications for the literature on new-venture strategy. This paper was accepted by Bruno Cassiman, business strategy."
/doi/10.1287/isre.1040.0013," Focus on individual outsourcing decisions in IT research has often yielded contradictory findings and recommendations. To address these contradictions, we investigate a holistic, configurational approach with the prevailing universalistic or contingency perspectives in exploring the effects of IT outsourcing strategies on outsourcing success. Based on residual rights theory, we begin by identifying three dimensions of IT outsourcing strategies: degree of integration, allocation of control, and performance period. We then develop a model of fit-as-gestalt, drawing from literatures on strategy, governance, interorganizational relationships, and outsourcing. Next, based on data from 311 firms in South Korea, we test universalistic and contingency perspectives in explaining the relationship between IT outsourcing strategies and outsourcing success. We then identify three congruent patterns, or gestalts, of IT outsourcing strategies. We term these strategies independent, arm's-length , and embedded strategies. To establish the predictive validity of these gestalts and the viability of a configurational perspective, we then explore the effects of these congruent gestalts vis-à-vis noncongruent patterns on three dimensions of outsourcing success: strategic competence , cost efficiency , and technology catalysis . We also contrast the effects of each of the three gestalts on each of the three dimensions of outsourcing success. Our findings indicate the superiority of the configurational approach over universalistic and contingency perspectives in explaining outsourcing success."
/doi/10.1287/mnsc.1090.1040," For empirical work in the resource-based view of the firm, characterizing the resources that are responsible for firm growth is difficult because valuable resources are often tacit, ambiguous, or difficult to identify. This is a particular problem for empirical assessments that rely upon the concept of relatedness between resources to characterize the direction of growth of the firm. We tackle the problem for the general case by developing a general interindustry relatedness index. The index harnesses the relatedness information embedded in the multiproduct organization decisions of every diversified firm in the U.S. manufacturing economy. The index is general in that it can be used across industry contexts without requiring explicit identification of resources and it provides a percentile relatedness rank for every possible pair of four-digit Standard Industrial Classification manufacturing industries. The general index is tested for predictive validity and found to perform as expected. Applications of the index in strategy research are suggested."
/doi/10.1287/opre.2017.1645," We consider the infinite-horizon multiple retailer joint replenishment problem with first-order interaction. In this model, the joint setup cost incurred by a group of retailers placing an order simultaneously consists of a group-independent major setup cost and retailer-specific minor setup costs. The goal is to determine an inventory replenishment policy that minimizes the long-run average system-wide cost. In this paper, we adopt a noncooperative approach to study the joint replenishment game. We consider the allocation rule in which the major setup cost is split equally among the retailers who place an order together, and each retailer pays his own holding and minor setup costs. Given the preannounced allocation rule, each retailer determines his replenishment policy to minimize his own cost anticipating the other retailers’ strategy. We show that a payoff dominant Nash equilibrium exists, and quantify the efficiency loss of the noncooperative outcome relative to the social optimum. Although the worst-case ratio between the best decentralized outcome and the social optimum is O ((ln n ) 1/2 ), where n is the number of retailers, numerical results suggest that the best equilibrium is near optimal. The online appendix is available at https://doi.org/10.1287/opre.2017.1645 ."
/doi/10.1287/orsc.2014.0958," This paper explores the dynamics of value distribution within a sector, using data on the U.S. computer industry as an illustration. It provides exploratory quantitative evidence for the way in which conditions within the segments of a sector’s value chain affect the profitability of those segments compared with the sector as a whole. To consider how value shifts from one part of the sector (such as computer assemblers) to another (such as software and microprocessor makers), we look at how conditions within a segment (such as software developers) affect changes in the value share of that segment compared with the entire sector in terms of market capitalization. We find that the presence of what we call “kingpins”—firms with superior capabilities, modeled in our study as having superior market capitalization and as being disproportionately important in terms of research and development (R&D)—is correlated with a higher share of total sector value, suggesting that kingpins can help a segment to become a “bottleneck.” Sales concentration and the level of R&D expenditure are not always reliable predictors. Kingpins exert a positive externality on their direct competitors, yet their segments display increasing internal inequality over time, making the presence of kingpins a double-edged sword for their peers. Our findings extend recent work on industry architectures, highlighting the interconnectedness of different segments within a sector. They also provide a structure to help study the dynamics of “value migration,” which has not yet attracted much academic scrutiny."
/doi/10.1287/inte.32.5.4.30," Combined-value auctions (CVAs) allow participants to make an offer of a single amount for a collection of items. These auctions provide value to both buyers and sellers of goods or services in a number of environments, but they have rarely been implemented, perhaps because of lack of knowledge and experience. Sears Logistics Services (SLS) is the first procurer of trucking services to use a CVA to reduce its costs. In 1993, it saved 13 percent over past procurement practices. Experimental economics played a crucial role in the development, sale, and use of the CVA."
/doi/10.1287/mnsc.47.1.52.10665," In their quest to manage the complexity of offering greater product variety, firms in many industries are considering platform-based product development . Product platforms, which are component and subsystem assets shared across a product-family, enable a firm to better leverage investments in product design and development. While the platform approach offers a number of benefits, it also imposes certain additional costs that have not received adequate research attention. In this paper, we use an industrial example both to illustrate some of the costs and benefits of platform-based product development and to motivate the development of a mathematical model. The model is formulated to better understand the appropriateness of product platforms and their impact on product-planning decisions. Our results indicate that platforms are not appropriate for extreme levels of market diversity or high levels of nonplatform scale economies. Also, a firm's product positioning and introduction sequence decisions made during the product-planning phase are significantly impacted by the presence of platforms. Specifically, a platform increases the separation among products and offers a multitude of product introduction strategies. We translate our model findings into a managerial framework."
/doi/10.1287/mnsc.2018.3271," A growing number of firms use incentive programs to encourage healthy behaviors, but there is little evidence about how such incentives should be structured over time. We explore this issue using a large field experiment that incentivized employees of a Fortune 500 company to use their workplace gym. We compare the effectiveness of a treatment with constant incentives over 8 weeks to two treatments that varied incentives over time. One variable treatment featured front-loaded incentives, which could, in theory, help procrastinators overcome startup costs to joining an incentive program. We find, however, that the front-loaded incentive did not increase participation on the extensive margin relative to the constant incentive and was less effective in sustaining exercise over time. The second variable incentive was designed to leverage short-term habit formation by turning incentives on and off over a longer period of time. This novel sporadic incentive showed slightly stronger effects than the constant incentive. We discuss how the nature of habit-formation processes affects the relative benefits of consistent versus periodic incentives. This paper was accepted by Uri Gneezy, behavioral economics."
/doi/10.1287/opre.2013.1185," We develop a new data envelopment analysis (DEA)-based methodology for measuring the efficiency of decision-making units (DMUs) characterized by multiple inputs and multiple outputs. The distinguishing feature of our method is that it explicitly includes information about output-specific inputs and joint inputs in the efficiency evaluation. This method contributes to opening the “black box” of efficiency measurement in two different ways. First, including information on the input allocation substantially increases the discriminatory power of the efficiency measurement. Second, it allows us to decompose the efficiency value of a DMU into output-specific efficiency values, which facilitates the identification of the outputs the manager should focus on to remedy the observed inefficiency. We demonstrate the usefulness and managerial implications of our methodology by means of a unique data set collected from the activity-based costing (ABC) system of a large service company with 290 DMUs."
/doi/10.1287/mnsc.2020.3660," Although there is ample evidence of discrimination against women in the workplace, it can be difficult to understand what factors contribute to discriminatory behavior. We use an experiment to both document discrimination and unpack its sources. First, we show that, on average, employers prefer to hire male over female workers for male-typed tasks, even when the two workers have identical résumés. Second, and most critically, we use a control condition to identify that this discrimination is not specific to gender. Employers are simply less willing to hire a worker from a group that performs worse on average, even when this group is, instead, defined by a nonstereotypical characteristic. In this way, beliefs about average group differences are the key driver of discrimination against women in our setting. We also document some evidence for in-group preferences that contribute to the gender discrimination observed. Finally, our design allows us to understand and quantify the extent to which image concerns mitigate discriminatory behavior. This paper was accepted by Yan Chen, decision analysis."
/doi/10.1287/inte.11.4.1," The development and the operation of a model-based decision-support system for ocean-borne transportation are described. For the past four years, this interactive time-sharing system has provided two sets of functions in that (a) it guides Bethlehem Steel's Marine Operations management in both annual planning and spot decision, and (b) it assists operating personnel not only in routine scheduling on a week-to-week, month-to-month basis throughout the year, but also in adjusting rapidly for emerging opportunities or requirements."
/doi/10.1287/orsc.1060.0194," The paper examines the significance of enforceability and adaptability in governing vertical alliances and their performance ramifications for suppliers. Literature on supplier relations suggests that suppliers are skeptical of close ties with their buyers (Helper 1991, Helper and Sako 1995). Such skepticism persists in spite of the fact that buyers are writing longer (enforceable) contracts with fewer suppliers. In this context, the paper develops a transaction cost economics (TCE)-based model that distinguishes between the verifiable and nonverifiable aspects of governance attributes (of safeguards, incentive intensity, and adaptability) in explaining supplier performance variations. The paper argues that the following factors prove valuable for suppliers: (1) the adaptive and collaborative orientation fostered by the original equipment manufacturer’s (OEM’s) credible commitment to the exchange and by information sharing on the part of the supplier, (2) the presence of certain nonverifiable safeguards, and (3) the incentives inherent in target pricing. These assertions have been tested using data from the home appliance industry. Results indicate that information sharing together with (1) OEM dependence and (2) target pricing does indeed enhance supplier performance. Also, results suggest that while nonverifiable safeguards can help, verifiable safeguards do not have a positive association with supplier interests. Under certain conditions then, suppliers can venture into closer relationships with buyers and benefit."
/doi/10.1287/isre.2016.0625," Logistics outsourcing has increased with the commercialization of the Internet, implying a reduction in the corresponding transaction costs. The Internet—with its universal connectivity and open standards—radically enhanced information technology (IT) capabilities, and we hypothesize this has reduced external transaction costs relatively more than internal governance costs. Using transaction cost theory as a lens, we examine whether the commercialization of the Internet coincided with a move to the market in logistics—one of the most connected industries in the economy. We estimate the relationship between IT and outsourced logistics in a production function based on two data sets from 1987 to 2008. We find that the effects of IT on outsourced logistics have changed in the post-Internet era. After the commercialization of the Internet, an industry’s own IT investment and outsourced logistics became complements, whereas they were not before. It suggests that because of the unique characteristics of the Internet as an enabler, IT reduced external transaction costs relatively more than internal governance costs. Consequently, industries favored the market form of the provision of logistics. We also find similar impacts of customers’ IT investments on a focal industry’s outsourced logistics. Previous studies argued that IT led to the shift from hierarchies to markets, or provided indirect evidence through measures of firm size or integration. Using a production theory model, our study provides systematic empirical evidence to support that the Internet enabled a move to the market in the provision of logistics."
/doi/10.1287/mnsc.2015.2194," Health information exchanges (HIEs) are healthcare information technology efforts designed to foster coordination of patient care across the fragmented U.S. healthcare system. Their purpose is to improve efficiency and quality of care through enhanced sharing of patient data. Across the United States, numerous states have enacted laws that provide various forms of incentives for HIEs and address growing privacy concerns associated with the sharing of patient data. We investigate the impact on the emergence of HIEs of state laws that incentivize HIE efforts and state laws that include different types of privacy requirements for sharing healthcare data, focusing on the impact of laws that include requirements for patient consent. Although we observe that privacy regulation alone can result in a decrease in planning and operational HIEs, we also find that, when coupled with incentives, privacy regulation with requirements for patient consent can actually positively impact the development of HIE efforts. Among all states with laws creating HIE incentives, only states that combined incentives with consent requirements saw a net increase in operational HIEs; HIEs in those states also reported decreased levels of privacy concern relative to HIEs in states with other legislative approaches. Our results contribute to the burgeoning literature on health information technology and the debate on the impact of privacy regulation on technology innovation. In particular, they show that the impact of privacy regulation on the success of information technology efforts is heterogeneous: both positive and negative effects can arise from regulation, depending on the specific attributes of privacy laws. This paper was accepted by Anandhi Bharadwaj, information systems ."
/doi/10.1287/isre.1070.0116," Researchers have widely postulated that the adoption of information technology (IT) products enhances global competitiveness and production efficiency as successful technological innovation replaces and improves traditional inputs and modes of production. This study suggests that when IT products are traded across borders, IT investment in an economy has a positive influence on the productivity of its import partner country. We provide empirical evidence for the positive effect of global IT diffusion on productivity through international trading of IT products. The results show a positive effect of foreign IT transfer on the recipient country’s productivity. In addition, we find that the effect of transferred IT is only significant when the source country is an IT-intensive or hi-tech export country. The results and implications are robust, even controlling for other important factors such as openness, innovative capacity, and IT infrastructure in addition to the transferred IT. Finally, a panel cointegration test—a recently developed advanced econometric method—is used to address the common problems of spurious relations that arise in regressions with nonstationary time-series data."
/doi/10.1287/mnsc.2017.2734," Using a comprehensive return data set and an array of 27 macroeconomic, stock, and bond predictors, we find that corporate bond returns are highly predictable based on an iterated combination model. The large set of predictors outperforms traditional predictors substantially, and predictability generated by the iterated combination is both statistically and economically significant. Stock market and macroeconomic variables play an important role in forming expected bond returns. Return forecasts are closely linked to the evolution of real economy. Corporate bond premia have strong predictive power for business cycle, and the primary source of this predictive power is from the low-grade bond premium. The Internet appendix is available at https://doi.org/10.1287/mnsc.2017.2734 . This paper was accepted by Lauren Cohen, finance."
/doi/10.1287/orsc.1050.0154," Organizational theorists have long acknowledged the importance of the formal and informal incentives facing a firm’s employees, stressing that the political economy of a firm plays a major role in shaping organizational life and firm behavior. Yet the detailed study of incentive systems has traditionally been left in the hands of (organizational) economists, with most organizational theorists focusing their attention on critical problems in culture, network structure, framing, and so on—in essence, the social context in which economics and incentive systems are embedded. We argue that this separation of domains is problematic. The economics literature, for example, is unable to explain why organizations should find it difficult to change incentive structures in the face of environmental change, while the organizational literature focuses heavily on the role of inertia as sources of organizational rigidity. Drawing on recent research on incentives in organizational economics and on cognition in organizational theory, we build a framework for the analysis of incentives that highlights the ways in which incentives and cognition—while being analytically distinct concepts—are phenomenologically deeply intertwined. We suggest that incentives and cognition coevolve so that organizational competencies or routines are as much about building knowledge of “what should be rewarded” as they are about “what should be done.” We argue that this recognition has important implications for our understanding of organizational inertia in the face of environmental change, and that it opens up important new areas for further research."
/doi/10.1287/mnsc.2020.3807," Public equity is an important source of risk capital, especially in China. The Chinese government has occasionally suspended IPOs, exposing firms already approved to IPO to indeterminate listing delays. The temporary bar on going public increases uncertainty about access to public markets for affected firms. We show that suspension-induced delay reduces corporate innovation activity both during the delay and for years after listing. Negative effects on tangible investment and positive effects on leverage are temporary, consistent with financial constraints during the suspensions being resolved after listing. Our results suggest that predictable, well-functioning IPO markets are important for firm value creation. They demonstrate that corporate innovation is cumulative and is negatively affected by policy uncertainty. This paper was accepted by Gustavo Manso, finance."
/doi/10.1287/isre.1080.0202," The information systems (IS) literature suggests that by lowering coordination costs, information technology (IT) will lead to an overall shift towards more use of markets. Empirical work in this area provides evidence that IT is associated with a decrease in vertical integration (VI). Economy-wide data, however, suggests that over the last 25 years the average level of VI has, in fact, increased. This paper studies this empirical anomaly by explicating the moderating impact of two measures of competitive environment, demand uncertainty, and industry concentration, on the relationship between IT and VI. We examine firms included in 1995 to 1997 InformationWeek 500 and the COMPUSTAT database. Consistent with the IS literature, the analysis suggests that IT is associated with a decrease in VI when demand uncertainty is high or industry concentration is low. However, contrary to the IS literature, IT is found to be associated with an increase in VI when industry concentration is high or demand uncertainty is low. Furthermore, as demand uncertainty increases, less vertically integrated firms invest more in IT, while as industry concentration increases, more vertically integrated firms invest more in IT. The analysis also suggests that firms' choice of the level of VI and IT investment, under different levels of demand uncertainty and industry concentration, are rational. When demand uncertainty is high or industry concentration is low, increase in VI may increase coordination and production costs. Thus, less VI is rational. However, when industry concentration is high or demand uncertainty is low, increase in VI may decrease coordination and production costs. Thus, firms choose more VI in such industries. The implications for research and practice are discussed."
/doi/10.1287/mnsc.2021.4131," Blockholder monitoring is central to corporate governance, but blockholders large enough to exercise significant unilateral influence are rare. Mechanisms that enable moderately sized blockholders to exert collective influence are therefore important. Existing theory suggests that engagement by moderately sized blockholders is unlikely, especially when the blocks are held by delegated asset managers who have limited skin in the game. We present a model in which multiple delegated blockholders engage target management in parallel, that is, “wolf pack activism.” Delegation reduces skin in the game, which decreases incentives for engagement. However, it also induces competition over investor capital (i.e., competition for flow). We show that this increases engagement incentives and helps ameliorate the problem of insufficient engagement, although it can also foster excess engagement. Under competition for flow, the total amount of capital seeking skilled activist managers is relevant to engagement incentives, which helps to predict when and where wolf packs arise. Flow incentives are particularly valuable in incentivizing engagement by packs with smaller members. This paper was accepted by Gustavo Manso, finance."
/doi/10.1287/inte.1060.0221," Elkem’s silicon division is the largest supplier of silicon metal and ferrosilicon in the world. With the slowdown in the global economy that started in 2000, the corporation decided to improve the efficiency of its supply chain network and evaluate its product portfolio. To help the division manage this process, we developed a strategic-planning model. This mathematical-programming model addresses decisions pertaining to future plant structure, including possible closures, new plant acquisitions, and investments in production equipment. The silicon division has used the model and its scenario analysis capabilities extensively to obtain important benefits. The company agreed to a restructuring process, which included reopening a closed furnace and investing $17 million in equipment conversion. Overall, as a result of the restructuring plan, Elkem expects a significant and sustained improvement in yearly revenue for the silicon division."
/doi/10.1287/isre.2019.0915," We study the heterogeneous effects of online video platforms on the sales volume and sales distribution of recorded music. Identification comes from two natural experiments in Germany. In 2009, virtually all music videos were blocked from YouTube as a result of a legal dispute. In 2013, the dedicated platform Vevo entered the market, making videos of a large number of artists available overnight. Our estimates suggest that restricting (enabling) access to online videos decreases (increases) recorded music sales on average by about 5%–10%. We show that the effect operates independently of the nature of video content, suggesting that user-generated content is as effective as official content. Moreover, we highlight heterogeneity in this effect: online music videos disproportionally benefit sales of new artists and sales of mainstream music."
/doi/10.1287/mnsc.2021.3967," This paper investigates empirically the effect of market power on dynamic pricing in the presence of inventories. Our setting is the auto retail industry; we analyze how automotive dealerships adjust prices to inventory levels under varying degrees of market power. We first establish that inventory fluctuations create scarcity rents for cars that are in short supply. We then show that dealers’ ability to adjust prices in response to inventory depends on their market power, that is, the quantity of substitute inventory in their selling area. Specifically, we show that the slope of the price–inventory relationship (higher inventory lowers prices) is significantly steeper when dealers find themselves in a situation of high rather than low market power. A dealership with high market power moving from a situation of inventory shortage to a median inventory level lowers transaction prices by about 0.57% ceteris paribus, corresponding to 32.5% of dealers’ average per-vehicle profit margin or $145.6 on the average car. Conversely, when competition is more intense, moving from inventory shortage to a median inventory level lowers transaction prices by about 0.35% ceteris paribus, corresponding to 20.2% of dealers’ average per-vehicle profit margin or $90.9. To our knowledge, we are the first to empirically show that market power affects firms’ ability to dynamically price. This paper was accepted by Juanjuan Zhang, marketing."
/doi/10.1287/orsc.1070.0325," Organizational theorists have built a deep understanding of the conditions affecting knowledge sharing. However, for innovation to occur, knowledge must not just be shared, but also reused, recombined, and accumulated. Such accumulation is not inherent to the innovation process but can be either supported or limited by the context in which it occurs. We propose a framework arguing that three conditions shape this context: disclosure, access, and rewards. We show how these conditions operate at the institutional, field, community, and organizational levels. Our framework highlights how when innovators encounter barriers to the accumulation of knowledge, their solutions are often organizational ones rather than legal ones. This suggests an expanding terrain for organizational scholars interested in debates often dominated by law and economics."
/doi/10.1287/mksc.1040.0087," We investigate differences in the dynamics of marketing decisions across geographic markets empirically. We begin with a linear-quadratic game involving forward-looking firms competing on prices and advertising. Based on the corresponding Markov perfect equilibrium, we propose estimable econometric equations for demand and marketing policy. Our model allows us to measure empirically the strategic response of competitors along with economic measures such as firm profitability. We use a rich dataset that combines sales, marketing mix, factor cost, and advertising cost data for eighteen geographic markets in the frozen entrée category. We find that larger markets tend to be less price-sensitive and more profitable than smaller markets. We also find evidence of positive carryover of own advertising on own demand. In terms of consumer substitution patterns, we find that the role of advertising (in our data) seems to be more category-building (complementary) than share-stealing (competitive). The complementary role is stronger in larger markets. On the supply side, we find that firms make smaller adjustments to own advertising as goodwill goes up. Consistent with cross-advertising effects on demand, firms make smaller (larger) adjustments to advertising in response to competitive goodwill in the less competitive larger (in the more competitive smaller) markets. Finally, we find that consumer welfare decreases (increases) in larger (smaller) markets when firms move to a zero-advertising regime."
/doi/10.1287/mksc.17.4.356," This paper addresses the question of how the vertical structure of a product line relates to brand equity. Does the presence of “premium” or high-quality products in a product line enhance brand equity? Conversely, does the presence of “economy” or low-quality products in a product line diminish brand equity? Economists and marketing researchers refer to variation in quality levels of products within a category as “vertical” differentiation, whereas variation in the function or “category” of the products is referred to as “horizontal” differentiation. Much of the existing research on the relationship between product line structure and brand equity has focused on the horizontal structure of the product line and has been primarily concerned with brand extensions —what happens when the product line of a brand is extended horizontally into new categories? Researchers have been concerned primarily with how the extension fares, but the effect of the extension on the core products is also important. There is an analogous question of what happens when the product line of a brand is extended vertically, either “up market” or “down market.” This question of vertical extensions is part of the more general issue of how the vertical structure of a product line relates to brand equity. The specific research questions addressed in this paper are: (1) do “premium” or high-quality products enhance the brand equity associated with the other products in the line? (2) Conversely, do “economy” or low-quality products diminish the brand equity associated with the other products in the line? These research questions are relevant to three managerial issues in product-line strategy. First, what are the costs and benefits of including “down market” products within a brand? Second, what are the implications of including high-end models within a brand? Third, when should high-end and low-end products be offered under an existing brand umbrella and when should these products be offered under separate brands? We address these research questions empirically through an analysis of the models and brands within the U.S. mountain bicycle industry. We use price premium above that which can be explained by the physical characteristics of the bicycle as a metric for brand equity. We then test several hypotheses related to the relationship between extension of the product line upward and downward and the price premium commanded by the brand. We further support this analysis with a simple laboratory experiment. The analysis reveals that price premium, in the lower quality segments of the market, is significantly positively correlated with the quality of the lowest-quality model in the brand's product line; and, that for the upper quality segments of the market, price premium is also significantly positively correlated with the quality of the highest-quality model in the brand's product line. The results of the analysis are supported by the outcome of an experiment in which 63 percent of the subjects preferred a product offered by a high-end brand to the equivalent product offered by a low-end competitor. These results imply that managers wishing only to maximize the equity of their brands would offer only high-quality products and avoid offering low-quality products. However, this result must be moderated by the overall objective of maximizing profits. Maximizing profits is likely to involve a tradeoff between preserving high brand equity (and therefore high margins) and pursuing the volume typically located in the lower end of the market. One of the most significant implications of this research is that product line managers need to be mindful not just of the incremental cannibalization or stimulation of sales of products that are immediate neighbors of an extension to the product line, but also the effect of such an extension on the brand equity in other, possibly quite different, parts of the product line."
/doi/10.1287/orsc.9.4.454," The management and processing of organizational knowledge are increasingly being viewed as critical to organizational success. By exploring how firms access and exploit alliance-based knowledge, the authors provide evidence to support the argument that the firm is a dynamic system of processes involving different types of knowledge. Using data from a longitudinal study of North American-based joint ventures (JVs) between North American and Japanese firms, they address three related research questions: (1) what processes do JV partners use to gain access to alliance knowledge; (2) what types of knowledge are associated with the different processes and how should that knowledge be classified; and (3) what is the relationship between organizational levels, knowledge types, and the transfer of knowledge? Although many generalizations have been drawn about the merits of knowledge-based resources and the creation of knowledge, few efforts have been made to establish systematically how firms acquire and manage new knowledge. Moreover, prior alliance research has not addressed in detail the nature of alliance knowledge and how knowledge is managed in the alliance context. The authors examine the processes used by alliance partners to transfer knowledge from an alliance context to a partner context. They identify four key processes—technology sharing, alliance-parent interaction, personnel transfers, and strategic integration—that share a conceptual underpinning and represent a knowledge connection between parent and alliance. Each of the four processes is shown to provide an avenue for managers to gain exposure to knowledge and ideas outside their traditional organizational boundaries and to create a connection for individual managers to communicate their alliance experiences to others. Although all of the knowledge management processes are potentially effective, the different processes involve different types of knowledge and different organizational levels. The primary types of knowledge associated with each process are identified and then linked with the organizational level affected by the transfer process. From those linkages, several propositions about organizational knowledge transfer and management are developed. The results suggest that although a variety of knowledge management strategies can be viable, some strategies lead to more effective knowledge transfer than others."
/doi/10.1287/mnsc.2014.1932," A key concern about counterfeits and weak intellectual property protection is that they may hamper innovation by displacing legitimate sales. This paper combines a natural policy experiment with randomized lab experiments to estimate the heterogeneous impacts of counterfeiting on the sales and consumer purchase intent related to branded products of various quality levels. I collect new product-line-level panel data (1993–2004) on Chinese shoe companies. I identify heterogeneous effects of counterfeit entry on sales of authentic products of three quality tiers, finding that counterfeits have both advertising effects for a brand and substitution effects for authentic products, additionally the effects linger for some years. The advertising effect dominates the substitution effect for high-end authentic product sales, and the substitution effect outweighs the advertising effect for low-end product sales. The positive effect of counterfeits is most pronounced for high-fashion products (such as women's high-leg boots and dress shoes), shoes tailored to young customers, and high-end products of brands not yet well-known at the time of counterfeiter entry. This paper was accepted by David Hsu, entrepreneurship and innovation."
/doi/10.1287/mnsc.2017.2864," Prior studies attribute analysts’ forecast superiority over time-series forecasting models to their access to a large set of firm, industry, and macroeconomic information (an information advantage), which they use to update their forecasts on a daily, weekly or monthly basis (a timing advantage). This study leverages recently developed mixed data sampling (MIDAS) regression methods to synthesize a broad spectrum of high frequency data to construct forecasts of firm-level earnings. We compare the accuracy of these forecasts to those of analysts at short horizons of one quarter or less. We find that our MIDAS forecasts are more accurate and have forecast errors that are smaller than analysts’ when forecast dispersion is high and when the firm size is smaller. In addition, we find that combining our MIDAS forecasts with analysts’ forecasts systematically outperforms analysts alone, which indicates that our MIDAS models provide information orthogonal to analysts. Our results provide preliminary support for the potential to automate the process of forecasting firm-level earnings, or other accounting performance measures, on a high-frequency basis. The online appendix is available at https://doi.org/10.1287/mnsc.2017.2864 . This paper was accepted by Mary Barth, accounting."
/doi/10.1287/inte.1110.0610," A large US retailer that procures transportation services from third-party carriers experienced an unexpected jump in fuel surcharges as the price of diesel fuel skyrocketed in the summer of 2008. As a result, it sought to limit its future exposure to diesel price risk. We collaborated with this retailer to create a lane assignment optimizer (LAO) that incorporates diesel price risk when selecting carriers for its transportation lanes. The LAO tool has significantly improved the retailer's capability to evaluate the trade-off between the two crucial components of a lane's per-shipment cost: base price and risk-adjusted fuel surcharge. The retailer can now take diesel price risk into account when selecting cost-effective carriers for its lanes, negotiating fuel surcharge limits to share diesel price risk with its carriers, and better aligning the fuel surcharges it pays with the true cost of diesel. We estimate that the more favorable contract terms the retailer negotiated for 2009–2011 translate to nearly $5 million in potential savings during years with unexpected diesel price hikes, such as 2008."
/doi/10.1287/mksc.1090.0516," During the summer of 2005, the three domestic U.S. automobile manufacturers offered a customer promotion that allowed customers to buy new cars using discount programs formerly offered only to employees. The initial months of the promotion were record sales months for each of the three firms, suggesting that customers thought that the prices offered during the promotion were particularly attractive. In reality, however, many customers paid higher prices under the employee discount pricing promotion. We propose that the promotion changed customers' beliefs about current versus future prices, convincing them to purchase during the promotion rather than delay in anticipation of future discounts. We investigate several alternative explanations for the simultaneous increase in prices and sales, including advertising, decreased financing costs, industry trends, disutility of bargaining, consumer differences, and changes in trade-in values. None of these explanations fully explains the concomitant increase in prices and sales."
