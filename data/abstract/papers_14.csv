link,abstract
/doi/10.1287/msom.2020.0912," Problem definition : This paper investigates how counterfeits influence a global supply chain and how the supply chain should effectively take anticounterfeit actions. Academic/practical relevance : The impacts of counterfeiting have been increasingly profound on global supply chains. It is critical to understand how counterfeiting impacts supply chains when supply chain members act in their own interests, and how supply chains can effectively combat counterfeiting when all the members can contribute to it. This is the first paper that offers insights into these important questions. In particular, we examine who among the supply chain members is in the best position to perform counteracting activities, how these members can cooperate in anticounterfeiting, and what economic implications the anticounterfeit actions have to the supply chain, individual firms, consumer surplus, and social welfare. Methodology : We consider a supply chain consisting of a manufacturer and a retailer, and analyze a game-theoretical framework to derive the equilibrium. Results : The manufacturer prefers to induce the retailer to combat counterfeits rather than to combat itself. Contrary to conventional wisdom, counterfeits can increase the supply chain’s profit even in the absence of network externality effects. The crux is that the manufacturer lowers wholesale price to incentivize the retailer’s counteraction and, consequently, the threat of counterfeits can mitigate double marginalization and benefit the supply chain. Managerial implications : Our results demonstrate that a sustainability risk can trigger collaborative endeavors of supply chain members and thus be advantageous to the supply chain. The findings also underscore the important role that retailers should play in anticounterfeiting. Particularly, it can be in the supply chain’s interest that the manufacturer does not execute the counteraction, either jointly with the retailer or by itself."
/doi/10.1287/trsc.1120.0415," In spite of extraordinary support programs initiated by the European Union and other national authorities, the percentage of overall freight traffic moved by train is in steady decline. This development has occurred because the macroeconomic benefits of rail traffic, such as the relief of overloaded road networks and reduced environmental impacts, are counterbalanced by severe disadvantages from the perspective of the shipper, e.g., low average delivery speed and general lack of reliability. Attracting a higher share of freight traffic on rail requires freight handling in railway yards that is more efficient, which includes technical innovations as well as the development of suitable decision support systems. This paper reviews container processing in railway yards from an operations research perspective and analyzes basic decision problems for the two most important yard types: conventional rail–road and modern rail–rail transshipment yards. Furthermore, we review the relevant literature and identify open research challenges."
/doi/10.1287/opre.1100.0810," In this paper, we examine a supply chain in which a single supplier sells to a downstream retailer. We consider a multiperiod model with the following sequence of events. In period t the supplier offers a contract to the retailer, and the retailer makes her purchasing decision in anticipation of the random demand. The demand then unravels, and the retailer carries over any excess inventory to the next period (unmet demand is lost). In period t +1 the supplier designs a new contract based on his belief of the retailer's inventory, and the game is played dynamically. We assume that short-term contracts are used, i.e., the contracting is dynamically conducted at the beginning of each period. We also assume that the retailer's inventory before ordering is not observed by the supplier. This setting describes scenarios in which the downstream retailer does not share inventory/sales information with the supplier. For instance, it captures the phenomenon of retailers distorting past sales information to secure better contracting terms from their suppliers. We cast our problem as a dynamic adverse-selection problem and show that, given relatively high production and holding costs, the optimal contract can take the form of a batch-order contract, which minimizes the retailer's information advantage. We then analyze the performance of this type of contract with respect to some useful benchmarks and quantify the value of prudent contract design and the value of inventory information to the supply chain. Markovian adverse-selection models, in which the state and action in a period affect the state in the subsequent period, are recognized as theoretically challenging and are relatively less understood. We take a nontrivial step towards a better understanding of such models under short-term contracting."
/doi/10.1287/mnsc.49.1.1.12749," The advent of e-commerce has prompted many manufacturers to redesign their traditional channel structures by engaging in direct sales. The model conceptualizes the impact of customer acceptance of a direct channel, the degree to which customers accept a direct channel as a substitute for shopping at a traditional store, on supply-chain design. The customer acceptance of a direct channel can be strong enough that an indepent manufacturer would open a direct channel to compete with its own retailers. Here, direct marketing is used for strategic channel control purposes even though it is inefficient on its own and, surprisingly, it can profit the manufacturer even when so direct sales occur. Specifically, we construct a price-setting game between a manufacturer and its independent retailer. Direct marketing, which indirectly increases the flow of profits through the retail channel, helps the manufacturer improve overall profitability by reducing the degree of inefficient price double marginalization. While operated by the manufacturer to constrain the retailer's pricing behavior, the direct channel may not always be detrimental to the retailer because it will be accompanied by a wholesale price reduction. This combination of manufacturer pull and push can benefit the retailer in equilibrium. Finally, we show that the mere threat of introducing the direct channel can increase the manufacturer's negotiated share of cooperative profits even if price efficiency is obtained by using other business practices."
/doi/10.1287/mnsc.2019.3504," Collusion is widely condemned for its negative effects on consumer welfare and market efficiency. In this paper, I show that collusion may also in some cases facilitate the creation of unexpected new sources of value. I bring this possibility into focus through the lens of a historical episode from the 19th century, when colluding railroads in the U.S. South converted 13,000 miles of railroad track to standard gauge over the course of two days in 1886, integrating the South into the national transportation network. Route-level freight traffic data reveal that the gauge change caused a large shift in market share from steamships to railroads, but did not affect total shipments or prices on these routes. Guided by these results, I develop a model of compatibility choice in a collusive market and argue that collusion may have enabled the gauge change to take place as it did, while also tempering the effects on prices and total shipments. This paper was accepted by Joshua Gans, business strategy ."
/doi/10.1287/orsc.8.5.458," We offer a revised institutional view of how new technology for information systems (IS) comes to be applied and diffused among organizations. Previous research argues that early adoption of a technological innovation is based on local, rational organizational choice, while later adoption is institutionalized and taken for granted. We suggest that institutional processes are engaged from the beginning. Specifically, a diverse interorganizational community creates and employs an organizing vision of an IS innovation that is central to its early, as well as later, diffusion. This vision serves key functions in interpretation, legitimation, and the organization and mobilization of economic roles and exchanges. The development and influence of an organizing vision is determined by a variety of institutional forces. Among these forces, the community's discourse serves as the developmental engine. Other factors—business commerce, the IS practitioners' world view, the motivating business problematic, the core technology, and material processes of adoption and diffusion—provide the discourse with its content, structure, motivation, and direction. Primary development of the organizing vision takes place during the innovation's earliest diffusion. The hesitant early majority among the prospective adopters relies on this development in its efforts to make sense of the innovation. Where the organizing vision remains underdeveloped after early adoption, later diffusion and institutionalization of the innovation is likely to be retarded."
/doi/10.1287/isre.2015.0594," Consumer review systems have become an important marketing communication tool through which consumers share and learn product information. Although there is abundant evidence that consumer reviews have a significant impact on product sales, the design of consumer review systems and its impact on review outcomes and product sales have not yet been well examined. This paper analyzes firms’ review system design and product pricing strategies. We formally model two review system design decisions—what rating scale cardinality to use and whether to offer granular review reports. We show that firms’ optimal design and pricing strategies critically depend on contextual characteristics such as product valuation, product mainstream level, and consumer misfit cost. Our results suggest that it is beneficial to host a review system only when the product valuation is higher than a threshold. Furthermore, firms should choose low rating scale cardinality for niche products and high rating scale cardinality for mainstream products. When consumers’ misfit cost is relatively high, including granular reports in the review system enables firms to attract the favorable consumer segment. Different pricing strategies should be deployed during the initial sale period for different product types. For niche products, firms are advised to adopt lower-bound pricing for high-quality products to take advantage of the positive word of mouth. For mainstream products, firms are advised to adopt upper-bound pricing for high-quality products to enjoy the direct profit from the initial sale period, even after taking into account the negative impact of high price on consumer reviews."
/doi/10.1287/isre.2020.0951," We examine content creation in a geosegmented, crowdsourced social mobile virtual community app, Waze. We conceptualize a virtual and spatial factor, virtual crowdedness (defined as the density of Waze users in a particular geospatial location), and we examine its role in encouraging user contribution. We posit that the relationship between virtual crowdedness and user contribution is driven by the tension between audience effects and bystander/content saturation effects. We analyze a panel data set of user contributions on Waze from New York City to test our hypotheses. First, our findings indicate that although virtual crowdedness has a positive influence on total number of contributions, the magnitude of the influence decreases as virtual crowdedness increases. Second, the concave-down increasing relationship is more pronounced for rush hours with high physical crowdedness than for non-rush hours with low physical crowdedness. A variety of robustness checks and alternative analyses based on matching estimators and spatial econometric models further support the main conclusions while mitigating concerns about endogeneity and spatial autocorrelation. Our findings provide several key practical implications for platform designers in that they should allow for users to visualize density of usage as well as improve the design of social features for encouraging user contribution to the mobile virtual community."
/doi/10.1287/opre.35.2.234," In facility locational models of public-service systems (for example, fire extinguishment, police and ambulance systems), the allocation of the system's operating cost and the locations of the service stations are in principle very closely related. The farther a user is from the service station, the lower is the cost share he should he willing to defray, and vice versa. We consider in this paper the problem of locating one facility in a tree network, T , and suggest a game theoretic approach for generating the facility location y in T and a corresponding cost allocation scheme q . The pairs ( y , q ) generated by our game theoretic approach are contained in a least core associated with the locational model, and they are all stable in the sense that they cannot be improved upon by any subset of users."
/doi/10.1287/orsc.1060.0217," This paper presents the results of two studies that examine the impact of both social psychological and economic concerns on organizational members’ decisions to support or oppose union formation. The studies test the predictions that procedural justice judgments and social identification—two social psychological factors that shape the nature of how people relate to their organizations—have a significant influence on people’s support for union certification and on the votes they cast in a union certification election. Importantly, it was predicted that these effects would emerge even after accounting for the influence of people’s economic concerns, which have been the primary focus of previous efforts to understand whether people support union formation. The results confirm these predictions and demonstrate that respondents’ positions on the unionization issue are shaped by procedural justice (Studies 1 and 2) and social identity (Study 2) even after accounting for economic factors. Furthermore, Study 2 shows that the impact of procedural justice judgments on union certification was partially mediated by social identity. More generally, the results highlight the importance of integrating both social psychological and economic concerns in models designed to explain organizational phenomena such as the formation of unions."
/doi/10.1287/orsc.1120.0815," Entrants are often viewed as suffering from a “liability of newness”—at founding, they rarely possess the knowledge and capabilities necessary to compete and survive. They can overcome this liability by learning vicariously from the knowledge of incumbent firms. But how can entrants learn from external knowledge when they lack the prior related knowledge that forms the basis of absorptive capacity? We theorize that the process of internal experiential learning facilitates learning from external knowledge, particularly for entrants. To test this theory, we examine learning using a comprehensive set of U.S. commercial banking firms, including a full census of entrants. Our estimates suggest that the share of vicarious learning realized in the process of experiential learning is twice as large for entrants as for incumbents. In this sense, entrants enjoy an “advantage of newness” in learning."
/doi/10.1287/isre.2013.0486," Open source software is becoming increasingly prominent, and the economic structure of open-source development is changing. In recent years, firms motivated by revenues from software services markets have become the primary contributors to open-source development. In this paper we study the role of services in open source software development and explore the choice between open source and proprietary software. Specifically, our economic model jointly analyzes the investment and pricing decisions of the originators of software and of subsequent open-source contributors. We find that if a contributor is efficient in software development, the originator should adopt an open-source strategy, allowing the contributor to offer higher total quality and capture the higher end of the market while the originator focuses on providing software services to lower end consumers. Conversely, if the contributor is not efficient in development, the originator should adopt a proprietary software development strategy, gaining revenue from software sales and squeezing the contributor out of the services market. In certain cases an increase in originator development efficiency can result in increased contributor profits. Finally, we find that, somewhat counterintuitively, an increase in contributor development efficiency can reduce overall social welfare."
/doi/10.1287/mnsc.2015.2383," Many online content providers aim to compensate for a loss in advertising revenues by charging consumers for access to content. However, such a choice is not straightforward because subscription fees typically deter customers, and a resulting decline in viewership further reduces advertising revenues. This research examines whether firms that offer both free and paid content can benefit from adjusting the amount of content offered for free. We find that firms should offer more free—and not paid—content in periods of high demand. We motivate theoretically that this policy, which we term “countercyclical offering,” may be optimal for firms when consumers are heterogeneous in their valuation of online content and this heterogeneity varies over time. Using unique data from an online content provider, we then provide empirical evidence that firms indeed engage in countercyclical offering and increase the share of free content in periods of high demand. This paper was accepted by Matthew Shum, marketing ."
/doi/10.1287/mksc.1100.0619," This paper describes the use of a marketing science model by Jetstar, a subsidiary of Australia's leading airline, Qantas, to effectively and profitably compete in the low-cost carrier marketplace. We trace the evolution of the Jetstar strategy from a baseline calibration of its initial position, to its efforts to attain price competitiveness and service parity, followed by its highly focused, cost-effective service delivery strategy. We develop a hierarchical model with parameters estimated at the individual level. This allows us to study not only how service design and pricing initiatives shift the perceived performance of Jetstar relative to its competitors but also how the airline can move market preferences toward areas in which it has competitive advantage. The contribution of the research is substantial. The Jetstar market share went from 14.0% to 18.1% during the first five quarterly waves of the research, and profits went from $79 million in 2006–2007, before the study was commissioned, to $124 million in 2008–2009."
/doi/10.1287/msom.1070.0192," Motivated by the ease with which online customers can bid simultaneously in multiple auctions, we analyze a system with two competing auctioneers and three types of bidders: those dedicated to either of the two auctions and those that participate simultaneously in both auctions. Bidding behavior is specified and proven to induce a Bayesian Nash equilibrium, and a closed-form expression for the expected revenue of each auctioneer is derived. For auctioneers selling a single item, partial pooling—i.e., the presence of some cross-auction bidders—is beneficial to both auctioneers as long as neither one dominates the market (e.g., possesses more than 60%–65% of the market share). For multi-item auctions, pooling is mutually beneficial only if both auctioneers have nearly identical ratios of bidders per items for sale; otherwise, only the auctioneer with the smaller ratio benefits from pooling. Pooling's impact on revenue decreases with the number of bidders, suggesting that popular auction sites need not be overly concerned with mitigating bidding across auctions."
/doi/10.1287/moor.24.1.106," This work develops a polynomial-time dynamic-programming algorithm for minimum-aggregate-concave-cost multicommodity flow problems in strong-series-parallel networks. Many important problems from production and inventory management, capacity planning, network design and transportation can be formulated in these terms. Our results include a characterization of extreme flows in strong-series-parallel networks and an algorithm based on this characterization that searches extreme flows efficiently to find an optimal one. The algorithm runs in time proportional to A ( N + K ), where A , N and K are respectively the numbers of arcs, nodes and commodities in the network, and appears to be the first to solve the problem in polynomial time. When applied to the dynamic economic-order-quantity problem, the algorithm matches the performance of that of Wagner and Whitin (1958). Moreover, our algorithm has broader applications, including the multi-division capacity expansion problem and the generalization of the dynamic economic-order-quantity problem to series-parallel production processes in which subassemblies are assembled into a finished product."
/doi/10.1287/orsc.2020.1390," Existing research at the nexus of institutional theory and entrepreneurship suggests that lowering institutional barriers to forming, growing, and exiting new firms can affect the types of start-ups that entrepreneurs found in a region. These institutional changes could influence entrepreneurs’ perceptions of the value of partnering with venture accelerators and potentially improve these sponsors’ capacity to select high-growth start-ups to fund and develop. This study evaluates these ideas by developing and testing three hypotheses. First, institutional reforms improve entrepreneurs’ perceived value of venture accelerators for resources that affect new venture development. Second, they reduce the average probability of being selected for new applicants, due to a surge in the number and heterogeneity of new applicants within accelerators’ local ecosystems. Third, institutional reforms increase the quality of selected cohorts for accelerator managers due to increases in the average quality and human capital of new applicants. To evaluate these hypotheses, I analyze data from 13,770 applicants to venture accelerators over multiple application cycles between 2016 and 2018 in 170 countries. I use a differences-in-differences design to estimate the effects of institutional changes on start-up selection after regulatory reforms that reduced the time and procedures to start new firms, obtain credit, and resolve bankruptcy for entrepreneurs. The findings have valuable implications for how governments, especially those in emerging and developing economies, can support high-growth entrepreneurship."
/doi/10.1287/mnsc.2016.2713," We study a multiserver queueing model of a revenue-maximizing firm providing a service to a market of heterogeneous price- and delay-sensitive customers with private individual preferences. The firm may offer a selection of service classes that are differentiated in prices and delays. Using a deterministic relaxation, which simplifies the problem by preserving the economic aspects of price-and-delay differentiation while ignoring queueing delays, we construct a solution to the fully stochastic problem that is incentive compatible and near optimal in systems with large capacity and market potential. Our approach provides several new insights for large-scale systems: (i) the deterministic analysis captures all pricing, differentiation, and delay characteristics of the stochastic solution that are nonnegligible at large scale; (ii) service differentiation is optimal when the less delay-sensitive market segment is sufficiently elastic; (iii) the use of “strategic delay” depends on system capacity and market heterogeneity—and it contributes significant delay when the system capacity is underutilized or when the firm offers three or more service classes; and (iv) connecting economic optimization to queueing theory, the revenue-optimized system has the premium class operating in a “quality-driven” regime and the lower-tier service classes operating with noticeable delays that arise either endogenously (“efficiency-driven” regime) or with the addition of strategic delay by the service provider. This paper was accepted by Gérard Cachon, stochastic models and simulation."
/doi/10.1287/isre.2016.0638," Developing countries, such as India and China, are the fastest growing economies in the world. The successful implementation of information and communication technologies (ICTs) in these countries is likely to hinge on a set of institutional factors that are shaped by the environmental tension between two competing forces, emergent catalysts, such as new economic policies and reform programs, and traditional challenges, such as infrastructure and traditional value systems. To unearth the temporal dynamics underlying the success and failure of ICT implementations in organizations in developing countries, we conducted a two-year multimethod study of an ICT implementation at a large bank in India. Based on data collected from over 1,000 employees and over 1,000 customers, we found, relative to preimplementation levels for up to two years postimplementation, that we characterized as the shakedown phase (1) operational efficiency did not improve, (2) job satisfaction declined, and (3) customer satisfaction declined. In-depth interviews of approximately 40 members of top management, 160 line employees, and 200 customers indicated that these outcomes could be attributed to the strong influence of a set of institutional factors, such as ICT-induced change, labor economics, Western isomorphism, parallel-manual system, and technology adaptation. The interplay between these institutional factors and the environmental tension posed a formidable challenge for the bank during our study that led to the poor and unintended outcomes."
/doi/10.1287/mnsc.2021.4064," In a 2010 special report, The Economist magazine termed the resurgence of state-owned, publicly listed enterprises “Leviathan Inc.” and criticized the poor governance and low efficiency of these firms. We compile a new comprehensive data set of state ownership of publicly listed firms in 44 countries over the period of 2004–2017 and show that state-owned enterprises are more responsive to environmental issues. The effect is more pronounced in economies lacking energy security and strong environmental regulation, and among firms with more local operations and higher domestic government ownership. We find a similar effect on corporate social engagement but not on governance quality. These results suggest a different role for “Leviathan Inc.,” especially in dealing with environmental externalities. This paper was accepted by Management Science Special Issue on Business and Climate Change."
/doi/10.1287/isre.12.2.121.9700," The field of information systems is premised on the centrality of information technology in everyday socio-economic life. Yet, drawing on a review of the full set of articles published in Information Systems Research ( ISR ) over the past ten years, we argue that the field has not deeply engaged its core subject matter—the information technology (IT) artifact. Instead, we find that IS researchers tend to give central theoretical significance to the context (within which some usually unspecified technology is seen to operate), the discrete processing capabilities of the artifact (as separable from its context or use), or the dependent variable (that which is posited to be affected or changed as technology is developed, implemented, and used). The IT artifact itself tends to disappear from view, be taken for granted, or is presumed to be unproblematic once it is built and installed. After discussing the implications of our findings, we propose a research direction for the IS field that begins to take technology as seriously as its effects, context, and capabilities. In particular, we propose that IS researchers begin to theorize specifically about IT artifacts, and then incorporate these theories explicitly into their studies. We believe that such a research direction is critical if IS research is to make a significant contribution to the understanding of a world increasingly suffused with ubiquitous, interdependent, and emergent information technologies."
/doi/10.1287/orsc.2021.1501," Prior research on collaboration and creativity often assumes that individuals choose to collaborate to improve the quality of their output. Given the growing role of collaboration and autonomous teams in creative work, the validity of this assumption has important implications for organizations. We argue that in the presence of a collaboration credit premium—when the sum of fractional credit allocated to each collaborator exceeds 100%—individuals may choose to work together even when the project output is of low quality or when its prospects are diminished by collaborating. We test our argument on a sample of economists in academia using the norm of alphabetical ordering of authors’ surnames on academic articles as an instrument for selection into collaboration. This norm means that economists whose family name begins with a letter from the beginning of the alphabet receive systematically more credit for collaborative work than economists whose family name begins with a letter from the end of the alphabet. We show that, in the presence of a credit premium, individuals may choose to collaborate, even if this choice decreases output quality. Thus, collaboration can create a misalignment between the incentives of creative workers and the prospects of the project."
/doi/10.1287/mnsc.46.7.912.12036," The classical newsvendor problem is one of optimally choosing a level of capacity to respond to a known demand distribution. The inverse newsvendor problem is one of optimally choosing a demand distribution with fixed capacity. The applications of the inverse problem include industrial settings where demand management is relatively less costly than capacity adjustments. Demand distributions are chosen from an opportunity set, which reflects the set of market opportunities for the firm. We analyze the firm's profit as a function of these demand alternatives, provide solution methods and insights, and identify inefficient and dominated distributions. We provide results when the opportunity set is known or only partially known. We extend the results to cases in which there are multiple prioritized customer classes that share the firm's productive capacity. This paper was motivated by an industrial application in a firm selling a semicommodity product into three prioritized industrial sectors. We review the application of our methods to this setting."
/doi/10.1287/inte.1070.0332," Pricing is a critical component in the marketing-mix plans of automobile manufacturers. Because they tend to keep their manufacturer's suggested retail prices (MSRPs) and wholesale prices fixed throughout the model year, they customize pricing to reflect supply and demand by using incentives; in the US market, they represent approximately $45 billion per year. In addition, variations in capacity utilization have immediate and substantial effects on profitability. This, together with legacy costs and inflexible labor contracts, makes the effectiveness and efficiency of price-customization decisions particularly vital for the industry. Chrysler, a pioneer in using science in its pricing decisions, engaged J. D. Power and Associates (JDPA) to implement an incentive planning model. The approach used is based on a random-effects multinomial nested logit model of product (vehicle model), acquisition (cash, finance, lease), and program-type (e.g., consumer cash rebates, reduced interest-rate financing, cash/reduced interest-rate combinations, lease-support) selection. The model uses sales transaction data that are collected daily from approximately 10,000 dealerships. It uses a hierarchical Bayes modeling structure to capture response heterogeneity at the local market level. This specification allows users to apply the model to pricing decisions at the local, regional, and national market levels. Based on implementing this model, Chrysler learned that, for any given price level, the pricing structure (e.g., a combination of retail price, interest rates, or rebates) is important. The set of the most efficient pricing structures for each price level constitutes an efficient frontier ; efficient pricing structures vary across products, price levels, and markets. The system provides three alternative approaches to identify efficient (and effective) pricing programs: (a) what-if-scenario simulations, (b) a batch scenario generator that allows users to identify and examine the profit-share/volume efficient frontier, and (c) an optimizer that, given an objective and a set of constraints, allows users to search for incentive programs rapidly. The Chrysler Corporate Economics Office estimates that Chrysler's annual savings from implementing the model are approximately $500 million."
/doi/10.1287/mnsc.2016.2619," We explore how the establishment of an industry pioneer through foreign seeding of industry knowledge can subsequently catalyze the growth of a developing country’s industry by involuntarily propagating the knowledge to subsequent entrants. As industry knowledge has tacit elements, we focus on mechanisms that enable experienced workers from the pioneer to seed the knowledge to new entrants. We examine the relationship between entrants’ characteristics and the mechanisms exploited to access the industry knowledge, and the impact of the mechanisms exploited on firm performance. Empirical findings from two historical episodes in the Bangladesh garment industry suggest that industry knowledge seeding was essential for the initial establishment and subsequent expansion of the industry. Our paper highlights the role of experienced workers’ mobility in building new firm capabilities and provides novel insights into industrialization in developing economies. This paper was accepted by Bruno Cassiman, business strategy."
/doi/10.1287/mnsc.2015.2338," This paper studies a merger between price-setting newsvendors in an oligopolistic market. It is well known that inventory pooling can greatly reduce inventory costs in a centralized distribution system because it helps reduce aggregate demand uncertainty. Although such statistical economies of scale are important benefits of a retail merger, the extant literature models cost savings from a merger only through reduction in a postmerger firm’s marginal cost. In this paper, we develop a model of a retail merger under uncertain demand that distinguishes between cost savings from conventional economies of scale and those from statistical economies of scale, and we show that these two sources of cost savings have substantially different impacts on firms’ decisions in a postmerger market. Contrary to the existing theory of mergers developed under deterministic demand, we find that although inventory pooling enables the postmerger firm to achieve cost savings, it always induces firms to raise their prices, and we find that marginal cost reduction induces firms to lower their prices only when it is substantial—consequently, larger cost synergies can benefit even nonparticipant firms. Finally, even if a merger induces all firms to raise their prices, it can still improve expected consumer welfare by increasing firms’ service levels under uncertain demand. This paper was accepted by Serguei Netessine, operations management ."
/doi/10.1287/mksc.2018.1138," When financially distressed firms have overwhelming debts, a prominent option for survival is to file for Chapter 11 bankruptcy protection. We empirically study the effect of Chrysler’s Chapter 11 bankruptcy filing on the quantity sold by its competitors in the U.S. auto industry. The demand for competitors could increase because they may benefit from the distress of the bankrupt firm (competitive effect). By contrast, competitors could experience lower sales if the bankruptcy increases consumer uncertainty about their own viability (contagion effect). A challenge to measuring the impact of bankruptcies is the coincident decline in economic conditions stemming from the Great Recession and the potential effect of the “cash for clunkers” program (among other confounding factors). To identify the effect of the bankruptcy filing, we employ a regression-discontinuity-in-time design based on a temporal discontinuity in treatment (i.e., bankruptcy filing), along with an extensive set of control variables. Such a design is facilitated by a unique data set at the dealer–model–day level that allows us to compare changes in unit sales in close temporal vicinity of the filing. We find that unit sales for an average competitor decrease by 28% following Chrysler’s bankruptcy filing. Several types of evidence suggest that this negative demand spillover effect is driven by a heightened consumer uncertainty about the viability of the bankrupt firm’s rivals. For example, we show that the sales of competitors’ vehicles that compete within the same segments as the bankrupt firm’s vehicles or that provide lower value for money are affected more negatively in response to the Chrysler filing. We also observe more web search activity for Chrysler’s competitors after the filing. Our findings are robust to different estimation strategies (global versus local), different functional forms, different estimation windows, the inclusion of various controls (e.g., “cash for clunkers,” incentives, advertising, inventory, recalls, price, and consumer confidence), the donut regression discontinuity approach, a potential serial correlation issue, a falsification exercise, and the inclusion of differential trends at various levels. Our study aims to inform policymakers and managers about unintended short-term demand consequences of Chapter 11 bankruptcy. The online appendices and data files are available at https://doi.org/10.1287/mksc.2018.1138 ."
/doi/10.1287/opre.2020.1994," We consider incentive compensation where the firm has ambiguity on the effort-contingent output distribution: The parameters of the output probability distribution are in an ellipsoidal uncertainty set. The firm evaluates any contract by its worst-case performance over all possible parameters in the uncertainty set. Similarly, the incentive compatible condition for the agent must hold for all possible parameters in the uncertainty set. The firm is financially risk neutral and the agent has limited liability. We find that when the agent is financially risk neutral, the optimal robust contract is a linear contract—paying the agent a base payment and a fixed share of the output. Moreover, the linear contract is the only type of contract that is robust to the parameter uncertainty. When there is model uncertainty over a general effort-contingent output distribution, we show that a generalized linear contract is uniquely optimal. When the agent is risk averse and has a piecewise linear utility, the only optimal contract is a piecewise linear contract that consists of progressive fixed payments and linear rewards with progressive commission rates. We also provide the analysis for the trade-off between robustness and worst-case performance and show that our results are robust to a variety of settings, including cases with general ℓ p ‐norm uncertainty sets, multiple effort levels, and so on. Our paper provides a new explanation for the popularity of linear contracts and piecewise linear contracts in practice and introduces a flexible modeling approach for robust contract designs with model uncertainty."
/doi/10.1287/mnsc.2014.1978," Competitive positioning is a central, yet understudied, topic in strategy. Understanding positioning requires understanding two distinct mappings: how underlying policies are transformed into positions, and how positions are transformed into market performance. A complete treatment of positioning requires incorporating organizational design in the presence of policy interdependence; consumer choice in the presence of trade-offs among multiple product attributes; and competitive interactions among firms. We develop a model that integrates these elements. We show that in a multiattribute setting, trade-offs have critical, nonmonotonic effects on a range of strategy questions including the relationship between positions that are operationally efficient and those that remain viable in the face of competition as well as the concentration of market share in the industry. Of particular interest are implications for firm heterogeneity. We show that increases in business policy interdependence can decrease positioning heterogeneity among firms in an industry, depending on the nature of trade-offs. We also show that the relationship between strategy heterogeneity and positioning heterogeneity is moderated by the extent of policy interdependence. This paper was accepted by Bruno Cassiman, business strategy ."
/doi/10.1287/msom.2017.0704," To scale service operations requires retrieving knowledge across the organization. However, prior work highlights that individuals on the periphery of organizational knowledge networks may struggle to access useful knowledge at work. A knowledge repository has the potential to help peripheral individuals gain access to valuable knowledge because it is universally available and can be used without social interaction. However, for it to successfully serve this equalizing function, those on the periphery of the organizational knowledge networks must actually use it, possibly overcoming barriers to doing so. In this paper, we develop a multilevel model of knowledge retrieval in teams to explore how individuals on the periphery of knowledge networks—because of their inexperience, location, lack of social capital, gender, or role—access knowledge from such a knowledge repository. Unexpectedly, we find that individuals whose experience and position already provide access to vital knowledge use a knowledge repository more frequently than individuals on the organizational periphery. We argue that this occurs because the knowledge repository—despite its appearance of equivalent accessibility—is actually more accessible to central than to peripheral players. Thus, knowledge retrieval is not driven primarily by the need to overcome limited access to other knowledge sources. Rather knowledge retrieval is facilitated when actors know how to reap value from the knowledge repository, which ironically improves with increasing access to other sources of knowledge. We conclude that a knowledge repository is unlikely to scale service operations without additional intervention. This paper has been accepted for the Manufacturing & Service Operations Management Special Issue on Value Chain Innovations in Developing Economies."
/doi/10.1287/mnsc.2019.3307," Retailers colocate with rivals to take advantage of economies of agglomeration even though colocation implies greater competition. Using data on all new car transactions registered in Ohio from 2007 to 2014, we estimate a structural model of consumer search for spatially differentiated products that explicitly captures the agglomeration and competition effects of retail colocation. Search frictions generate an average of $333 per car in dealer markups. Agglomeration implies that dealer closures could harm incumbent colocated dealers, even though the incumbent dealers would face less competition. Our results inform the recent policy debate surrounding the massive downsizing of car retail networks and highlight the role of contagion in brick-and-mortar retailing. This paper was accepted by Matthew Shum, marketing."
/doi/10.1287/opre.1060.0310," From the 1970s onwards, the OR community in Britain engaged in ongoing debate on the future of the discipline, the product of an emerging “crisis of confidence” engendered in part by the end of the “golden age of western economic growth” and the associated downsizing, or abolition, of practitioner groups in the corporate industrial sector. In addition, reservations were expressed concerning the increasing “mathematization” of academic OR in the context of the established “hard” or “classical” paradigm. In this respect, British operations researchers, aided and abetted by a number of American colleagues (notably Ackoff, Churchman, and Miser), engaged in a fundamental reappraisal of the OR methodological repertoire and its client base. Thus, in Britain, a new phase in the history of OR was inaugurated whereby the “positivist/scientist” approach bequeathed by the wartime pioneers was subject to challenge and qualification. Whilst some elements in the American OR community empathized with the emergent British critique, the response (notwithstanding Ackoff et al.) was, on the whole, relatively muted. This conservative American response provides one part of the rationale for this paper. The key issue here is to compare and contrast the tone and content of the Anglo-American debate on the future of OR after 1970: In simple terms, why did British OR practitioners and academics (especially the latter) respond so vigorously to the post-1970 OR critique in marked contrast to their American counterparts? In explaining the differential response, the paper will emphasize the interplay among an array of political, intellectual, and economic factors."
/doi/10.1287/trsc.2016.0683," Logistics is a cost sensitive industry with large and fast growing routing networks. In this paper we devise a computational, robust optimization method for the strategic routing decisions of a logistics’ customer, i.e., a company that uses the services of different freight forwarders to meet its transportation demands between several sources, sinks, and hubs. The costs of such transports are determined by tariff systems that typically show economies of scale and reward the consolidation of goods that complement each other in properties relevant for transport, such as weight and volume. In the strategic planning phase, routes and hubs have to be chosen roughly one year ahead, in particular, before the actual demand is known. Our method anticipates the fluctuation of demands by minimizing the worst-case cost over a restricted scenario set. The combination of a realistic cost function, a robust modeling of uncertainty, and large-scale networks leads to highly intractable models. We show that the corresponding adversary problem is NP-hard. To nevertheless find solutions for real instances with very good worst-case cost we derive a carefully relaxed and simplified mixed-integer linear program that solves well for large instances because of its powerful linear programming relaxation. We test the method for real-world instances. The results show that robust optimization can significantly reduce worst-case cost. Furthermore, we derive from our method two heuristic techniques to solve even larger networks and report on the corresponding computational results. Neglecting the typical uncertainty about demand values can cause significant cost in logistic routing problems. This paper provides for a practical method to avoid such costs."
/doi/10.1287/opre.2021.2107," Over-the-counter markets are at the center of the global reform of the financial system. We show how the size and structure of these markets can undergo rapid and extensive changes when participants engage in portfolio compression, which is an optimization technology that exploits multilateral netting opportunities. We find that tightly knit and concentrated trading structures, as featured by many large over-the-counter markets, are especially susceptible to reductions of notional amounts and network reconfigurations resulting from compression activities. Using a unique transaction-level data set on credit-default-swaps markets, we estimate reduction levels, suggesting that the adoption of this technology can account for a large share of the historical development observed in these markets since the global financial crisis. Finally, we test the effect of a mandate to centrally clear over the counter markets in terms of size and structure. When participants engage in both central clearing and portfolio compression with the clearinghouse, we find large netting failures if clearinghouses proliferate. Allowing for compression across clearinghouses by and large offsets this adverse effect."
/doi/10.1287/mksc.2015.0945," In this paper we study product line scope and pricing decisions in a horizontally differentiated duopoly. Past research has shown that a firm may offer a broader product line to attract higher demand or charge a higher price (or both), and benefit at the expense of its competitor. We show that such outcomes may be reversed, especially when consumers have relatively high valuation and low heterogeneity in their preferences for the line extension. We find that an equilibrium exists such that only one firm prefers to expand scope but profits may be higher for both firms, even in the absence of market size expansion. This is because a broader scope permits that firm to effectively price discriminate by raising prices for its core customers. The competitor optimally responds by lowering prices to gain share and earn a higher profit. Thus, higher prices for the firm expanding its product line translate into higher demand for the competing firm, thus increasing profit for both. We show that our results hold when firms deploy generic, offensive or defensive strategies during product line expansion."
/doi/10.1287/inte.30.6.32.11625," In spring 1996, Québec's Ministry of Natural Resources began using a descriptive mathematical programming model to support various negotiations in the wood-fiber markets. The model, which uses linear programming to solve an economic-equilibrium program, allows the representative of the ministry to come to industry roundtables with accurate scenario analyses for the wood-fiber market. The tool we developed and implemented uses the large amounts of data available to government agencies to foresee and explain the general economic trends facing both lumber and paper producers. During its development, our team of operations-research experts, economists, engineers, and civil servants developed an unprecedented understanding of the wood-fiber market. The ministry incorporated these insights in subsequent government policy aimed at improving sawmill yield and stabilizing market behavior."
/doi/10.1287/mnsc.17.10.B672," Whenever problems arise from differences of opinion, there probably exists a lack of understanding of the behavioral situations that contributed to the problems. In his interaction with others, man passes from a level of ignorance to one of awareness and seldom reaches a level of understanding. Without that understanding, however, there is no common premise for resolving problems either with regard to methods or results. Today's executive faces issues that deal not only with the familiar technical business decisions but, more significantly, with related labor, social and environmental responsibilities, and political implications both at home and abroad. Consequently, he must be equipped with the essential tools for analysis of complex behavioral interactions as a requisite to effective application of quantitative techniques. The objective here is to develop a systems approach to behavior by building a common analytical premise. This is done (1) by showing consistency between internal need and environmental resources as determinants of behavior, (2) by establishing values as explanations of these initiating forces, and (3) by then letting these values serve as standards of conduct for man's individual and group personality patterns as end-products of behavior. The basic hypothesis is that a triadic paradigm of unique combinations of need-resource qualities generates corresponding actions and interactions among individuals which are observable in the personalities defined by psychoanalysts. The relationship permits a theoretical classification of behavior patterns for identification, prediction, and resolution of problems within the specific contexts of need and environment that govern man's actions. Through this approach, the manager gains a systematic tool for behavioral analysis on an integrated basis, somewhat like the economic concept of pure competition serving as a reference parameter against which reality becomes a measurable entity. Many salient features had to be condensed in this paper, permitting only a symbolic application of the behavioral theory to cost-benefit analysis of the war in Vietnam. However, present working papers using nonmetric multi-dimensional scaling, factor analyses, and clustering techniques already indicate the applicability of such a behavioral framework."
/doi/10.1287/inte.2018.0943," The Optimization for Networked Data in Environmental Urban Waste Collection (ONDE-UWC) project is, to the best of our knowledge, the first attempt to apply the Internet of Things (IoT) paradigm to the field of waste collection. Sensors installed in dumpsters and garbage trucks share data, such as weight measurements and the number of user accesses. In this study, we schedule the weekly waste-collection activities for multiple types of waste without imposing periodic routes. An important characteristic of this project is that we consider heterogeneous stakeholders with different backgrounds and knowledge. In this context, we apply the GUEST OR methodology, highlighting how it can support the decision-making process to reduce the effects of these differences. As a result, we reduced the time required to implement the solution, increased operational efficiency, and achieved cost savings."
/doi/10.1287/trsc.1090.0273," Truckload carriers provide hundreds of billions of dollars worth of services to shippers in the United States alone each year. Internet auctions provide these shippers with a fast and easy way to negotiate potential contracts with a large number of carriers. Combinatorial auctions have the added benefit of allowing multiple lanes to be considered simultaneously in a single auction. This is important because it enables carriers to connect multiple lanes in continuous moves or tours, decreasing the empty mileage that must be driven, and therefore increasing overall efficiency. On the other hand, combinatorial auctions require bidding on an exponential number of bundles to achieve full economies of scope and scale, which is not tractable except for very small auctions. In most real-world auctions, bidding is instead typically limited to a very small subset of the potential bids. We present an implicit bidding approach to combinatorial auctions for truckload procurement that enables the complete set of all possible bids to be considered implicitly, without placing the corresponding burden of an exponential number of bids on the bidders or the auctioneer. We present the models needed to solve this problem. We then provide extensive computational results to demonstrate the tractability of our approach. Finally, we conclude with numerical analysis to assess the quality of the solutions that are generated and to demonstrate the benefits of our approach over existing bidding methods in practice."
/doi/10.1287/mnsc.2021.4125," We present a model that suggests possible explanations for the observed proliferation of “pay-per-use” (PPU) business models over the last two decades. Delivering “fractions” of a product as a service offers a cost advantage to customers with lower usage but requires extra delivery costs. Previous research focused on information goods (with negligible production costs) and predicted that PPU, when arising as a differentiation to selling in equilibrium, would fundamentally achieve lower profits than selling. We extend the theory by covering goods with any production cost in duopolistic competition. We show that PPU business models can be more profitable than selling (especially at midrange production costs), as long as their delivery costs are not too high, a requirement that is more easily fulfilled as new technologies reduce these costs. Moreover, if firms are imperfectly informed about their customers’ usage profiles, PPU’s effective pricing of customers’ varying usage offers an additional advantage over selling. This requires companies to employ accounting methods that do not inappropriately allocate production costs over stochastic usage levels. If PPU service provision suffers from queueing inefficiencies, this does not fundamentally change the relative profitability of the PPU and selling models, provided that PPU providers can attract sufficiently high demand to benefit from pooling economies. This paper was accepted by Charles Corbett, operations management."
/doi/10.1287/mnsc.2016.2449," We incorporate product demonstrations into a game theoretic model of price competition. Demonstrations may include product samples, trials, return policies, online review platforms, or any other means by which a firm allows consumers to learn about their value for a new product. In our model, demonstrations help individual consumers to learn whether they prefer an innovative product over an established alternative. The innovative firm controls demonstration informativeness. When the innovative firm commits to demonstration policies and there is flexibility in prices, the firm is best off offering fully informative demonstrations that divide the market and dampen price competition. In contrast, when a firm can adjust its demonstration strategy in response to prices, the firm prefers only partially informative demonstrations, designed to maximize its market share. Such a strategy can generate the monopoly profit for the innovative firm. We contrast the strategic role of demonstrations in our framework with the strategic role of capacity limits in models of judo economics, which also allow firms to divide a market and reduce competition. This paper was accepted by J. Miguel Villas-Boas, marketing ."
/doi/10.1287/orsc.2014.0955," A field study of 615 managers in 11 Korean manufacturing firms extends theory regarding labor contracting to the study of idiosyncratic deals (i-deals). Despite i-deals’ potential to benefit both employees and employers, economic theory asserts that employers attempt to reduce individual contracting by use of internal labor markets (ILMs). This study identifies limits to that assertion by identifying conditions under which i-deals are sought, despite employee participation in ILMs. Furthermore, we develop and test theory reconciling the roles of ILMs and firm-specific human capital in employee requests for i-deals. Employee reports of ILM practices are negatively related to i-deal requests, whereas firm-specific human capital is positively related to these requests. In addition, we find an interaction between the two such that the suppressive effects of ILM reports on i-deal requests hold largely for workers with low firm-specific human capital. Individuals with high firm-specific human capital tend to seek i-deals despite reported ILM practices. I-deal requests also increase with group-level heterogeneity in firm-specific human capital. In all, our findings suggest that ILMs function as economic theory asserts for workers with limited firm-specific human capital, but they are less able to reduce i-deal requests among workers with higher firm-specific human capital."
/doi/10.1287/orsc.1080.0366," This paper proposes a theory for why firms conduct some research activities in-house but outsource other projects to independent partners and for why firms retain different degrees of control over collaborative research projects. The focus is on the determinants of a company's choice to outsource research projects to academic organizations. Because of the different institutional missions of academic organizations, outsourcing a project to a university allows a firm to commit not to terminate or alter a scientifically valuable project before it is complete. This commitment is potentially valuable for the firm in an environment where scientific value and economic value may not coincide, and scientific workers are responsive to the incentives defined by their community of peers. An economic model that formalizes these arguments is developed. Empirical hypotheses are then formulated about the kind of research activities firms will outsource to universities and activities on which they will exert stronger control. Evidence from a sample of industry-university research agreements, as well as from other large-sample and case studies, shows patterns consistent with the predictions of the model."
/doi/10.1287/mnsc.1120.1578," It is commonly believed that piracy of information goods leads to lower profits, which translate to lower incentives to invest in innovation and eventually to lower-quality products. Manufacturers, policy makers, and researchers all claim that inadequate piracy enforcement efforts translate to lower investments in product development. However, we find many practical examples that contradict this claim. Therefore, to examine this claim more carefully, we develop a rigorous economic model of the manufacturer's quality decision problem in the presence of piracy. We consider a monopolist who does not have any marginal costs but has a product development cost quadratic in the quality level produced. The monopolist faces a consumer market heterogeneous in its preference for quality and offers a quality level that maximizes its profit. We also allow for the possibility that the manufacturer may use versioning to counter piracy. We unexpectedly find that in certain situations, lower piracy enforcement increases the monopolist's incentive to invest in quality. We explain the reasons and welfare implications of our findings. This paper was accepted by Lorin Hitt, information systems."
/doi/10.1287/mnsc.45.11.1524," The dual goals of this study are: (1) to develop an empirically valid neural model of U.S. factories in a range of industries producing discrete products, and (2) to use the model to test the effect of changes in product line width on plant performance variables. Accordingly, a neural factory was developed using 59 input and 5 output/performance variables, and was trained using field data collected from 385 U.S. manufacturing plants. The model was validated using a holdout sample before conducting sensitivity tests. The study demonstrates that, through the use of parametric sensitivity analysis, the neural factory could be used to investigate the relationship between inputs and performance of a factory. While the focused factory principle would favor a smaller product line, economies of scope theory would favor a larger product line for the good of the factory; this implies a rather complex relationship between product line width (PLW) and plant performance. The neural factory was used to study the sensitivity of output/performance variables when product line width was varied over a range extending from 10% to 200% of the average values. The sensitivity analysis of the neural factory shows that, as the product line increases, it (1) does not affect cost-of-goods-sold (COGS), (2) decreases return on investment, (3) has a negative effect on the top management's perception of manufacturing performance, (4) increases inventory turns, and (5) increases sales per employee. The explanations for these findings show how complex and intertwined the relationships between PLW and performance variables are. They enhance our understanding of PLW and provide some new directions for future empirical research."
/doi/10.1287/orsc.2019.1302," Protest raises the visibility of a social movement, and this affects all organizations affiliated with the movement’s group identity. Although the mutually beneficial relationship between protest and social movement organizations is well documented, we argue that protest does not necessarily aid other, more mundane types of affiliated organizations in the same manner. Specifically, we expect that increases in protest participation will favor the viability of organizations targeting an audience close to the group identity but not of organizations with an audience in which some members share that identity and others do not. We evaluate these claims using a data set of pro-lesbian, gay, bisexual, transgender, and queer (LGBTQ) protest events and local organizations in U.S. cities using a fixed-effects panel design with instrumental variables. Findings show that increases in protest participation decrease the presence of organizations that engage LGBTQ and non-LGBTQ audiences, especially local businesses that simultaneously bridge multiple groups of owners, customers, and clients."
/doi/10.1287/opre.1110.1012," We propose a method for estimating substitute and lost demand when only sales and product availability data are observable, not all products are displayed in all periods (e.g., due to stockouts or availability controls), and the seller knows its aggregate market share. The model combines a multinomial logit (MNL) choice model with a nonhomogeneous Poisson model of arrivals over multiple periods. Our key idea is to view the problem in terms of primary (or first-choice) demand; that is, the demand that would have been observed if all products had been available in all periods. We then apply the expectation-maximization (EM) method to this model, and we treat the observed demand as an incomplete observation of primary demand. This leads to an efficient, iterative procedure for estimating the parameters of the model. All limit points of the procedure are provably stationary points of the incomplete data log-likelihood function. Every iteration of the algorithm consists of simple, closed-form calculations. We illustrate the effectiveness of the procedure on simulated data and two industry data sets."
/doi/10.1287/opre.2019.1868," Public reporting of medical treatment outcomes is being widely adopted by policymakers in an effort to increase quality transparency and improve alignment between patient choices and provider capabilities. We examine the soundness of this approach by studying the effects of quality transparency on patient choices, hospital investments, societal outcomes (e.g., patients’ social welfare and inequality), and the healthcare market structure (e.g., medical or geographical specialization). Our results offer insights into why previous public reporting efforts have been less than fully successful and suggest ways in which future efforts can be more effective. Specifically, our analytical and simulation results calibrated with empirical data from the Centers for Medicare and Medicaid Services reveal that increasing quality transparency promotes increased medical specialization, results in decreased geographical specialization, and induces hospitals to invest in their strengths rather than their weakness. Furthermore, increasing quality transparency in the short-term typically improves social welfare and reduces inequality among patients. In the long-term, however, we find that increasing transparency can decrease social welfare, and fail to yield socially optimal outcomes, even under full transparency. Hence, a policymaker concerned with societal outcomes should accompany increasing quality transparency with other policies that correct the allocation of patients to hospitals. Among these, we find that policies that incentivize hospitals are generally more effective than policies that incentivize patients. Finally, our results indicate that, to achieve maximal benefits from increasing quality transparency, policymakers should target younger, more affluent, or urban (i.e., high hospital density area) patients, or those requiring nonemergency treatment."
/doi/10.1287/mksc.2018.1089," In various cultural and behavioral respects, emerging market consumers differ significantly from their counterparts of developed markets. They may thus derive consumption utility from different aspects of product meaning and functionality. Based on this premise, we investigate whether the economic rise of emerging markets may have begun to impact the typical one-size-fits-all design of many international product categories. Focusing on Hollywood films, and exploiting a recent relaxation of China’s foreign film importation policy, we provide evidence suggesting that these impacts may exist and be nonnegligible. In particular, we show that the Chinese society’s aesthetic preference for lighter skin can be linked to the more frequent casting of pale-skinned stars in films targeting the Chinese market. Implications for the design of international products are drawn. Data and the online appendix are available at https://doi.org/10.1287/mksc.2018.1089 ."
/doi/10.1287/mksc.1080.0421," Standardizing performance expectations across different outlets within a chain, differing in their individual features, their consumers, and the nature of competition they face, can be an onerous task. We develop an integrated, nonlinear, block group-level market share model of store expectations that draws upon the existing trade area as well as store performance literatures. By incorporating and normalizing a large number of external and internal factors impacting performance, we are able to offer a means for the retailer to determine equitable standards. The model is estimated using a variation of the maximum-likelihood estimation, on a data set fashioned from several sources and aggregated at the block group and store levels. Finally, we propose a set of indices that allows us to evaluate relative performances of stores and regions given the competitive environments they face. We find that a block group-level model offers a better fit, as well as significantly richer implications, than a traditional store-level model. Results show that a significant number of stores operate well below their expected levels, an insight not obvious from the raw numbers used to report store statistics to upper management."
/doi/10.1287/mnsc.2021.3996," We develop a model of competition between banks and a marketplace lender to motivate empirical tests using local market data on U.S. banks and the largest marketplace lending platform. Employing mergers of large, multimarket banks as an exogenous credit supply shock, we find that marketplace lending absorbs unmet demand for consumer credit following a decline in the availability of bank credit. Merger-induced bank branch closings lead to an increase in marketplace loan requests and loan acceptance rates, particularly for debt consolidation loans to lower-risk consumers. We also find that marketplace lending mitigates credit distress in local economies affected by mergers. This paper was accepted by Tomasz Piskorski, finance."
/doi/10.1287/msom.1060.0144," The classical scheduling literature considers many problems where a given set of jobs must be processed at minimum cost, subject to various resource constraints. The literature only considers the issue of revenue generation in a very limited way, by allowing a job to remain unprocessed and its revenue contribution to be lost. By contrast, we consider three diverse practical situations where efficient scheduling affects revenue in much more general and realistic ways. First, we study two make-to-order environments where efficient scheduling increases customer goodwill, thus stimulating demand in different ways. Second, we study two make-to-stock environments where efficient scheduling creates inventory, thus also stimulating demand in different ways. Third, we study new product markets where efficient scheduling leads to a company becoming the first mover, and thus acquiring a larger market share. In each case, we provide both a computationally efficient algorithm for scheduling and a proof that a much more efficient algorithm is unlikely to exist. For both the make-to-stock and make-to-order problems, we also describe heuristic approaches that are easy to implement, and we study their average performance. The results show that substantial benefits arise from considering the implications of efficient scheduling for revenue and net profit. The practical impact of our work is to demonstrate the importance of efficient scheduling, not only in controlling cost, but also in increasing revenue and net profit."
/doi/10.1287/mksc.1070.0302," How can a standardized product survive in a mass-customized world? This requires understanding that consumers often experience problems predicting their future hedonic reactions to new experiences (such as custom products), leading to feelings of regret. This form of regret occurs not because the custom product differs from specifications, but because consumers miswanted the design they ordered. Our analytic model shows that regret aversion induces consumers to design custom products to reflect the attributes of the available standard products. Consequently, regret-averse consumers may choose the standard product rather than place a custom order. The number of available standard products, however, moderates both these effects. Two experiments empirically substantiate the key predictions of the analytical model: (a) the custom product's resemblance to the standard product grows with regret aversion associated with miswanting, (b) there exists a segment of “regretfully loyal consumers” for the standard product in a mass-customized world and it expands with regret aversion, (c) both the above effects are weakened by the presence of a second standard product, and (d) the custom product can increase its market share when the number of standard products increases."
/doi/10.1287/orsc.1120.0802," Although the stylized model of industry evolution suggests that firms transform from vertical integration to specialization over time, many industries still exhibit a continued persistence of integrated firms. In exploring this puzzle, I draw on detailed firm-level data from the semiconductor industry to analyze how integrated incumbents, beyond shifting to the specialized mode, reconfigured in the face of industry’s vertical disintegration so as to coexist with the specialized firms. I propose and find that the incumbents who persist with vertical integration increase their emphasis on systemic innovations and transact with specialized firms in both upstream and intermediate markets. The value-creating opportunities associated with integrated incumbents’ leveraging (a) their relative superiority in developing systemic innovations and (b) markets to pursue a broader menu of transactional choices may offset their costs of staying integrated. These firm-level factors also determine the pattern of industry’s vertical disintegration and the extent of coexistence between integrated and specialized firms."
/doi/10.1287/serv.2015.0097," In all developed economies, there is a mounting demand for effective solutions to elderly care stemming from an aging population and the high cost of resources needed. Hence, significant investments have been made in developed countries to stimulate the growth of information and communication technology-enhanced services for the home care markets. However, digital provisioning of home care services includes major challenges. This study uses an individual longitudinal case study that explores the collaborative development of a video-based elderly care service to deepen the understanding of these challenges. The findings emphasize the importance of analyzing the contextual value for a variety of relevant stakeholders and identifying the key persons who are personally committed to the long-term collaborative development. The observed challenges also call for actions by policy makers to increase the dynamicity of service development in long-term research and development projects. Our theoretical contribution suggests integrating new service development theories with service-dominant logic and systems theories. This integration provides a means to contextualize the value of the service for individual beneficiaries, and it also contributes to coping with the complexity of new service development. For business practitioners, we translate these insights into propositions about new service development in the context of health and social care service systems."
/doi/10.1287/msom.2018.0750," Problem definition : We consider two competing electronic waste (e-waste) recovery channels, each of which consists of a collector and a recycler. Collectors obtain donated e-waste and sell the collected items to recyclers or in the secondary market, whereas recyclers process e-waste and sell the recycled material in the commodity market. Each recycler chooses for certification of one of two standards: e-Stewards or Responsible Recycling (R2). E-Stewards requires comparably more responsible handling, thus a higher processing cost, but attracts more e-waste from environmentally conscious donors. Academic/practical relevance : Despite the rapid growth of e-waste, the operations management community still understands little about e-waste processing supply chains. We add to this body of knowledge by capturing three salient features in the e-waste recovery industry: the existence of two recycling standards, the secondary market, and competition both within and between recovery channels. Methodology : We model the problem as a Stackelberg game and characterize the firms’ equilibrium decisions, deriving managerial insights through sensitivity analysis and numerical studies. Results : Competition between recovery channels is a key factor motivating e-Stewards adoption, whereas a recycler always chooses R2 in its absence. Interestingly, when competition exists both within and between recovery channels, recyclers with strong e-waste processing scale economies choose e-Stewards when incurring significantly higher processing costs than with R2. Furthermore, both the total environmental benefit and welfare might be higher when recyclers choose R2. Managerial implications : Policy makers who aim to encourage e-Stewards adoption should (1) lower entry barriers for new recyclers to induce competition, and (2) offer incentive programs to alleviate e-Stewards’ cost disadvantage, though only when recyclers have weak scale economies. Policy makers and nongovernmental organizations, however, should exercise caution in endorsing e-Stewards because R2 actually may generate a higher environmental benefit because of higher recycling volumes."
/doi/10.1287/isre.10.2.134," Previous literature has suggested that information technology (IT) can affect firm boundaries by changing the costs of coordinating economic activity within and between firms (internal and external coordination). This paper examines the empirical relationship between IT and firm structure and evaluates whether this structure is consistent with prior arguments about IT and coordination. We formulate an empirical model to relate the use of information technology capital to vertical integration and diversification. This model is tested using an 8-year panel data set of information technology capital stock, firm structure, and relevant control variables for 549 large firms. Overall, increased use of IT is found to be associated with substantial decreases in vertical integration and weak increases in diversification. In addition, firms that are less vertically integrated and more diversified have a higher demand for IT capital. While we cannot rule out all alternative explanations for these results, they are consistent with previous theoretical arguments that both internal and external coordination costs are reduced by IT."
/doi/10.1287/inte.28.1.24," As Hewlett-Packard Corporation installed a system for manufacturing ink-jet printers in Vancouver, Washington, in 1993, it realized that the system would not be fast enough or reliable enough to meet its production goals. At the time, the market for ink-jet printers was exploding, and any incremental printer shipments would translate directly into market share and revenue gains. The company undertook a simulation project to develop recommendations for design changes to improve the system performance but concluded that that project would take too long to be useful. MIT researchers used analytical methods to predict capacity and to determine the sizes and locations of buffers that would increase capacity at the cost of a minor increase in inventory. HP's implementation of this work yielded incremental revenues of about $280 million in printer sales and additional revenues from ancillary products, replacement ink-jet cartridges, media, and related items. Productivity increased about 50 percent, making the assembly of the print engine cost competitive. Finally, HP developed a method of creating rapid and effective system designs in the future."
/doi/10.1287/serv.2018.0218," In the last few years, service science has opened a debate on the need to adopt new approaches to better understand emerging social and economic dynamics. By following this direction, different multi- and transdisciplinary research pathways are requesting to consider an increasing number of new variables in the management of complex service systems (CSSs), underlying the fact that traditional approaches are useless in supporting decision makers in facing the challenges imposed by a more articulated scenario. To bridge this gap, this paper focuses attention on the phenomenon of ""smart cities"" as an example of CSSs with the aim of investigating the ways in which actors’ perceptions affect opportunities and willingness for value cocreation and collaborative paths. Via a survey on a random sample of 374 providers and users of a city service platform in Brno (Czech Republic), the actors’ perceptions were analysed, and through structural equation modeling, the relationships between actors’ perceptions and willingness to build value cocreation and collaborative paths were tested. The principal goal was to attract the attention of the service community to the role of cognitive and psychological dimensions affecting value cocreation and collaborative paths in CSS, using the example of a smart city as tangible evidence of CSS."
/doi/10.1287/mnsc.2016.2581," This study predicts and finds that the interaction of firm-level and aggregate-level shocks explains a significant portion of shocks to macroeconomic activity. Specifically, we hypothesize that the relation between uncertainty and economic growth is most pronounced when both firm-level and aggregate-level uncertainty are high simultaneously. Similarly, we hypothesize that aggregate performance affects unemployment most when both firm-level dispersion is high and aggregate performance is low, based on the sectoral shift theory. Our hypotheses and empirical results show that the interactive effect of firm-level and aggregate-level shocks are larger than the sum of the individual effects. This paper was accepted by Mary Barth, accounting ."
/doi/10.1287/trsc.2019.0906," Within a wide view to stimulate intermodal transport, this paper is devoted to the examination of the intrinsically related problems of designing freight carrying services and determining their associated prices as observed by the shipper firms. A path-based multicommodity formulation is developed for a medium-term planning horizon, from the perspective of an intermodal operator. In the quest of incorporating nonprice attributes, two approaches are proposed to depict a realistic assessment of the service quality. First, frequency delay constraints are added to the upper-level problem. Second, based on a random utility model, behavioral concepts are integrated in the expression of the lower level as a logistics costs minimization problem. Exact tests are invoked on real-world instances, demonstrating the capability of the presented approaches of reaching reasonable results within acceptable computation times and optimality gaps. The broader level-of-service perspective imposes additional costs on the service providers, although to a lesser extent on long-distance freight corridors, as indicated by the computed market share and net profit. Further experiments are conducted to test the impact of certain transport management instruments (e.g., subsidies and service capacities) on the modal split, as well as to assess the intermodality’s future based on a scenario analysis methodology."
/doi/10.1287/deca.1070.0091," Kilgour and Gerchak (Kilgour, D. M., Y. Gerchak. 2004. Elicitation of probabilities using competitive scoring rules. Decision Anal. 2 108–113) introduce a competitive probability scoring rule designed to reward forecasters for their accuracy relative to rival forecasters. The rule proposed is both proper (in the usual sense of scoring rules) and self-financing in that forecasters share a preset reward pool that can be fixed at net zero. This paper elaborates on the Kilgour-Gerchak forecasting competition by demonstrating its possible analogy with forecasters making “Kelly bets” in an exogenous fixed-odds betting market. The construction of forecasters as Kelly (log utility) bettors leads to a modification of the Kilgour-Gerchak rule, called the parimutuel Kelly competitive scoring rule. Unlike the Kilgour-Gerchak score, the parimutuel Kelly score is not proper. Its appeal, however, is that it emulates a prediction market formed within a cohort of forecasters, as if they engage in a closed betting tournament where each attempts to accumulate maximum possible wealth over the long run and ruin all others. Within such a competition, near honesty is a Nash equilibrium forecasting strategy under realistic conditions."
/doi/10.1287/mnsc.2019.3388," Artificial intelligence (AI) is surpassing human performance in a growing number of domains. However, there is limited evidence of its economic effects. Using data from a digital platform, we study a key application of AI: machine translation. We find that the introduction of a new machine translation system has significantly increased international trade on this platform, increasing exports by 10.9%. Furthermore, heterogeneous treatment effects are consistent with a substantial reduction in translation costs. Our results provide causal evidence that language barriers significantly hinder trade and that AI has already begun to improve economic efficiency in at least one domain. This paper was accepted by Joshua Gans, business strategy."
/doi/10.1287/mksc.1060.0238," A cross-market network effect exists in many industries (e.g., newspaper publishing, media, software) in which a seller sells both a primary and a secondary product (e.g., a newspaper publisher sells newspapers to readers and advertising space to advertisers), and the value of the secondary product depends on the size of the user base of the primary product. This paper examines the competitive implications of asymmetric customer loyalty in such markets. In traditional markets, an advantage in customer loyalty generates a profit advantage. We show here, however, that in the presence of a cross-market network effect, a midlevel of loyalty advantage in the primary product market can lead to an overall profit disadvantage. This surprising result is derived from the interdependence of the two markets, whereby a profit in one market may be gained at the cost of the other, and by the positive relationship between a larger loyalty segment and a higher opportunity cost of price competition in the product of the primary market. Extending our model to a two-period entry game also shows that under certain conditions, the entrant with disadvantage in customer loyalty can outperform the incumbent in profit and market share. This result suggests that asymmetry in customer loyalty can be a source of “first-mover” advantage or disadvantage."
/doi/10.1287/stsc.2021.0125," We expand the perspective on disruption by going beyond substitute products to consider the ways in which complements can impact the competitiveness of incumbents. Complementors represent a different kind of disruptive threat, one that is latent within the initial structure of value creation: complementors that disrupt are not new entrants but, rather, established actors that can shift their impact from positive to negative. With this perspective, we consider how ecosystem dynamics can clarify aspects of disruptive competition, and we use the dynamics of disruption to illuminate dimensions of competition in ecosystem settings. We elaborate three processes through which disruption through complements can occur: commoditization, adjacent entry, and value inversion. For each process we discuss specific examples, and we illustrate their interaction in the context of the automotive industry, which is fast evolving in response to technological change. In so doing, the paper fills a critical gap in the literature, which is so far missing a systematic examination of how complementors can disrupt established firms."
/doi/10.1287/trsc.2018.0888," In global liner shipping networks, a large share of transported cargo is transshipped at least once between container vessels, and the total transportation time of these containers depends on how well the corresponding services are synchronized. We propose a problem formulation that integrates service scheduling into the liner shipping network design problem. Furthermore, the model incorporates many industry-relevant modeling aspects: it allows for leg-based sailing speed optimization, it is not limited to simple or butterfly-type services, and it accounts for service-level requirements such as cargo transit time limits. The classic liner shipping network design problem is already a hard problem, and to solve the extended version, we propose a column-generation matheuristic that uses advanced linear programming techniques. The proposed method solves LINER-LIB instances of up to 114 ports and, if applied to the classic liner shipping network design problem, finds new best solutions to all instances, outperforming existing methods reported in the literature. Additionally, we analyze the relevance of scheduling for liner shipping network design. The results indicate that neglecting scheduling and approximating transshipments instead may result in the design of liner shipping networks that underestimate cargo transit times and their implications."
/doi/10.1287/mnsc.1080.0917," Agglomeration in foreign direct investment (FDI) is typically attributed to location-specific characteristics such as natural resource advantages or production-related spillovers between multinational firms. The increasing collocation of the largest global firms in the cement industry since the 1980s is not easily attributed to either of these explanations. This paper draws on theories of multimarket contact to test whether strategic interaction across national markets has influenced the successive market entry decisions generating the observed agglomeration. We first establish that there is indeed nonrandom agglomeration of the six largest cement firms. We next show that preexisting cross-market interaction with current incumbents helps predict which firm will enter a given market and also the choice of market a given firm enters. The association does not appear to be caused by strategic convergence or mimicry of recent entry events and cannot be explained by production side effects, which depend only on local conditions. The findings are consistent with multimarket contact models where collocation allows firms to sustain higher prices in all markets. This latter inference is also supported by evidence of an association between global firm market share and local cement price. The paper suggests that pricing spillovers can serve as an alternative motivation for FDI agglomeration."
/doi/10.1287/inte.29.4.82," Seven out of every 10 American jobs are expected to be related to technologies using advanced computers and electronics, requiring workers with strong math and science skills. However, school systems in several regions in the US that have suffered economic and demographic declines are having problems maintaining and improving math and science education. We conducted a study and engendered cooperation between school districts to improve student access to math and science courses in one such region. We first examined the math and science curricula, predicted enrollment rates, forecasted teacher availability, and analyzed access characteristics for a set of school districts in Western Pennsylvania known as the Mon Valley Education Consortium. We then proposed strategies for cooperation between the school districts that included moving students to multiple centers for advanced math and science courses, moving teachers between schools, and using an area vo-tech school as a math and science center. As a result of the study a pilot project was implemented signaling the beginning of regional cooperation in the area."
/doi/10.1287/deca.1080.0114," Climate policy decisions are necessarily sequential decisions over time under uncertainty, given the magnitude of uncertainty in both economic and scientific processes, the decades-to-centuries time scale of the phenomenon, and the ability to reduce uncertainty and revise decisions along the way. Thus, an appropriate choice of analytical method is decision analysis. However, applying decision analysis in the context of idealized government decision makers over a century raises the question of how to deal with the fact that political systems tend to exhibit path dependency, a force that makes large policy shifts difficult and rare, and limits most decisions to small incremental changes. This paper explores the effect of considering path dependency in an application of decision analysis to climate-change policy decisions, presenting two alternative methods for modeling path dependency. I demonstrate that consideration of path dependence in the context of climate policy justifies greater near-term emissions reductions. The more general result of path-dependency is to shift the near-term strategy towards a more moderate hedging strategy, because drastic shifts later will be difficult."
/doi/10.1287/mnsc.1080.0975," Group decision making provides a mechanism for channeling individual members' knowledge into productive organizational outcomes. However, in hidden profile experiments in which group members have common information favoring an inferior choice, with private information favoring a superior choice, groups typically choose an inferior alternative. We report a hidden profile experiment where we induce homogenous preferences over choice characteristics and provide financial incentives so that the common purpose assumptions of the model hold more completely than in past experiments. Nevertheless, groups continue to choose an inferior alternative most of the time. These failures primarily result from mistakes in recalling information. Mistakes in recalling common information (which favors an inferior candidate) are typically corrected, whereas mistakes in recalling the private information needed to uncover the hidden profile cannot be corrected. Therefore, the dismal performance of groups in pooling the information needed to identify the superior option primarily result from the structure of the problem rather than deficiencies in how groups share and process information. The discussions necessary to resolve mistakes in recalling common information also help to explain the often noted fact that groups spend a disproportionate amount of time discussing common information."
/doi/10.1287/mnsc.14.10.B581," This article proposes using a flexible price system to allocate computer time and to determine charges for computer users. The proposal is presented in the context of a central university computing center (UCC) although it may be applicable, with some modifications, to a wide range of queueing problems. At present, user-charges in most UCC's are based on average costs with little or no attention to speed of service. This leads to high charges and under-utilization when there is excess capacity, low charges and long queues when capacity is short, and to other problems. Under the proposed fiexible price systems, user-charges are dynamically determined by overall system demand and by user selected turn-around priority. The complexity of the price system can be varied to meet the needs of a particular instillation. The main reason for proposing flexible pricing for computer service is that this approach is consistent with an efficient use of scarce resources, including both the computer and users' time. This conclusion is justified in terms of a formal economic analysis which also serves to clarify the conditions under which revenue from a flexible pricing system would cover the full costs of the computer installation. The pricing of specialized computer hardware and software is also discussed. Finally, consideration is given to possible applications of fiexible pricing to other problems that have traditionidly been discussed in terms of queueing theory."
/doi/10.1287/mksc.1070.0311," Switching marketing channels is an expensive and sticky decision. While a number of theories suggest efficiency and strategic differences between channels, there is virtually no work on combining these ideas into an empirically workable methodology to assess the impact of a channel switch. In this study, we undertake to close this gap with an empirical study of the sports drink market, featuring competing producers and heterogeneous channels. We estimate demand and cost parameters for a number of alternative models of competitive interaction and use these estimates to study the switching of Gatorade from its extant (independent wholesaler) channel to the direct store delivery (DSD) channel belonging to Pepsi. Our initial results indicate the following: Pepsi should switch Gatorade to the DSD channel only if (i) the switch decreases Gatorade's manufacturing cost by at least 14%, or (ii) the switch increases the share of profit it can obtain by at least 13%, or (iii) the switch enhances demand by the equivalent of a price cut of 4.96¢ for a 32-ounces package. Absent these increases, Pepsi should not switch . Our methodology and results speak to both managers contemplating a channel switch and antitrust authorities faced with the task of evaluating the consequences of a change in vertical structure."
/doi/10.1287/inte.2017.0908," In this analysis of the risk and return of stocks in global and Chinese markets, we build a reasonably large number of models for stock selection and create optimized portfolios to outperform a global benchmark. We apply robust regression techniques in producing stock-selection models and Markowitz-based optimization techniques in portfolio construction in a global stock universe and two Chinese stock universes. We report the results of applying a data mining corrections test to the global and Chinese stock universes. We find that (1) robust regression applications are appropriate for modeling stock returns in global and Chinese stock markets; (2) mean-variance techniques continue to produce portfolios capable of generating returns that exceed transactions costs; and (3) our global portfolio selection models pass data mining tests, such that the models produce statistically significant asset selection for global and MSCI-China universes, but not for China A-shares."
/doi/10.1287/mnsc.1110.1357," This paper analyzes the interactions between competitive (wholesale) spot, retail, and forward markets and vertical integration in electricity markets. We develop an equilibrium model with producers, retailers, and traders to study and quantify the impact of forward markets and vertical integration on prices, risk premia, and retail market shares. We point out that forward hedging and vertical integration are two separate mechanisms for demand and spot price risk diversification that both reduce the retail price and increase retail market shares. We show that they differ in their impact on prices and firms' utility because of the asymmetry between production and retail segments. Vertical integration restores the symmetry between producers' and retailers' exposure to demand risk, whereas linear forward contracts do not. Vertical integration is superior to forward hedging when retailers are highly risk averse. We illustrate our analysis with data from the French electricity market. This paper was accepted by Wei Xiong, finance."
/doi/10.1287/mnsc.2018.3198," We study the effect of superstition and conspicuous spending motives on housing demand and price in Singapore. We find that buyers pay less for homes with unlucky addresses and more for homes with lucky addresses. There were fewer housing transactions on inauspicious days of the lunar calendar when people are advised to avoid making major economic decisions. This suggests that superstitious belief still affects economic activities. The demand for lucky addresses is also weaker on these inauspicious days, suggesting that superstitious belief indeed affects the demand for lucky addresses. Moreover, the price premium for a lucky address is significantly higher for apartments of larger size or on top floors. Because these two housing features can signal wealth and are highly visible, the larger price premium suggests that conspicuous spending motives also play a significant role in the Singapore housing market. We also find that informed buyers, even with less superstitious or conspicuous spending motives, might still pay price premiums for lucky addresses. In contrast, uninformed buyers are unlikely to pay a premium for these addresses. This paper was accepted by Tomasz Piskorski, finance."
/doi/10.1287/msom.2.4.372.12342," This paper studies a distribution system in which a manufacturer supplies a common product to two independent retailers, who in turn use service as well as retail price to directly compete for end customers. We examine the drivers of each firm's strategy, and the consequences for total sales, market share, and profitability. We show that the relative intensity of competition with respect to each competitive dimension plays a key role, as does the degree of cooperation between the retailers. We discover a number of insights concerning the preferences of each party regarding competition. For instance, there will be circumstances under which both retailers would prefer an increase in competitive intensity. Our analysis generalizes existing knowledge about manufacturer wholesale pricing strategies, and rationalizes behaviors that would not be evident without both price and service competition. Finally, we characterize the structure of wholesale pricing mechanisms that can coordinate the system, and show that the most commonly used formats (those that are linear in the order quantity) can achieve coordination only under very limiting conditions."
/doi/10.1287/mnsc.2019.3404," Financial models incorporating a reference point, such as the Capital Gains Overhang (CGO) model, typically assume it is fixed at the purchase price. Combining experimental and market data, this paper examines whether such models can be improved by incorporating reference-point adjustment. Using real stock prices over horizons from 6 months to 5 years, experimental evidence demonstrates that a number of salient points in the prior share price path are key determinants of the reference point, in addition to the purchase price. Market data testing is then undertaken by using the CGO model. We show that composite CGO variables, created by using a mix of salient points with weights determined in the experiment, have greater predictive power than the traditional CGO variable in both cross-sectional U.S. equity-return analysis and when analyzing the performance of double-sorted portfolios. In addition, future trading volume is more sensitive to changes in the composite CGO variables than to the traditional CGO, further emphasizing the importance of adjusting reference points. This paper was accepted by Tyler Shumway, Finance ."
/doi/10.1287/mksc.16.1.24," Selling information that is later used in decision making constitutes an increasingly important business in modern economies (Jensen [Jensen, Fred O. 1991. Information services. Congram, Friedman, eds. The AMA Handbook of Marketing for the Service Industries , Chapter 22. AMA-COM, New York, 423–443.]). Information is sold under a large variety of forms: industry reports, consulting services, database access, and/or professional opinions given by medical, engineering, accounting/financial, and legal professionals, among others. This paper is the first attempt in marketing to study competition in the rapidly emerging information sector. Specifically, we are interested in answering the following questions: (1) Is competition fundamentally different when competing firms sell information rather than traditional goods and services, and—if yes—why? (2) What are the implications of such differences for decision makers (marketers and regulators)? (3) Can we explain some of the observed marketing strategies in the information industry? As such, the audience of the paper includes academics as well as professionals who are interested in understanding what is specific about competition in information markets. Familiarity with the practical implications of such differences and understanding of the mechanisms that drive them is essential for those who are faced with the problem of marketing information. To answer the above research questions we build a simple game-theoretic model that consists of two firms selling information to a population of consumers who are heterogeneous in their willingness to pay for the quality of information. The most important features of the model are the following. Information products sold by the two firms are modeled as random draws from two normal distributions having equal mean. The variances of these distributions and their correlatedness constitute the product-attribute space, which is assumed to be common knowledge. Consumers are interested in assessing the mean of the distributions and to do so they can buy the sample from any of the firms or they can buy both samples and combine them to obtain a more accurate estimate. Quality of information is linked to the accuracy of consumers' estimate of the mean which in turn is influenced by the accuracy of each sample as well as by their correlatedness. Consumers' utility depends on the quality of information they purchased, on their inherent utility for quality (taste), and on the total price they paid to acquire information. Knowing consumer preferences, firms simultaneously price their information products. The main finding of the paper is that information markets face unique competitive structures. In particular, the qualitative nature of competition changes depending on basic product characteristics. While traditional products and services compete either as substitutes or as complements in the relevant product-attribute space, information may be one or the other, depending on its position within the same product-attribute space. Said differently, the nature of competition changes qualitatively with a continuous change in basic product-attribute levels. The intuition behind this finding is the following. When purchasing information, consumers facing important decisions may find it beneficial to purchase from several information sellers. This is more likely to happen when the reliability of information is low and the sources of information are independent. Under such conditions information products tend to be complements and, as a result, competition between sellers is relatively mild. In the opposite case, when information is reliable and/or sellers' sources are highly correlated, consumers are satisfied after consulting a single source. In this case, information products are substitutes and sellers tend to undercut one another's prices to induce consumers to choose their brand. Understanding this discontinuity in competitive structures has important implications for decision makers as very different strategies are optimal under different product characteristics. Under substitution, traditional strategies to avoid competition (e.g., differentiation) are recommended. When the competing products' reliability is generally low (they are complements) firms are better off accommodating competition. In fact, we find that a firm may benefit from “inviting” a competitor. Finally, our findings are also important for regulators of information markets. As the literature on complementarity suggests, price fixing agreements between firms offering complementary products may benefit firms as well as consumers."
/doi/10.1287/mnsc.1050.0487," This paper extends our previous studies on the assimilation of Internet-based e-business innovations by firms in an international setting. Drawing upon theories on the process and contexts of technology diffusion, we develop an integrative model to examine three assimilation stages: initiation → adoption → routinization. The model features technological, organizational, and environmental contexts as prominent antecedents of this three-stage assimilation process. Based on this model, we hypothesize how technology readiness, technology integration, firm size, global scope, managerial obstacles, competition intensity, and regulatory environment influence e-business assimilation at the firm level. A unique data set of 1,857 firms from 10 countries is used to test the conceptual model and hypotheses. To probe deeper into the influence of the environmental context, we compare two subsamples from developed and developing countries. Our empirical analysis leads to several key findings: (1) Competition positively affects initiation and adoption, but negatively impacts routinization, suggesting that too much competition is not necessarily good for technology assimilation because it drives firms to chase the latest technologies without learning how to use existing ones effectively. (2) Large firms tend to enjoy resource advantages at the initiation stage, but have to overcome structural inertia in later stages. (3) We also find that economic environments shape innovation assimilation: Regulatory environment plays a more important role in developing countries than in developed countries. Moreover, while technology readiness is the strongest factor facilitating assimilation in developing countries, technology integration turns out to be the strongest in developed countries, implying that as e-business evolves, the key determinant of its assimilation shifts from accumulation to integration of technologies. Together, these findings offer insights into how innovation assimilation is influenced by contextual factors, and how the effects may vary across different stages and in different environments."
/doi/10.1287/mnsc.2019.3347," We model an expert review system where two producers competing for market share each are evaluated by two raters. Employing economics experiments, the paper examines how the rater’s incentive to provide objective feedback can be distorted in the presence of social ties and different penalty structures for assigning unobjective ratings. The results reject the self-interested model. We find that raters assign more biased ratings to help the producer they know compete, and this distortion is exacerbated when the reputation cost for rating unobjectively is lowered. Counterintuitively, when both of the raters know the same producer, the likelihood of biased ratings drops significantly. To explain the empirical regularities, we develop a behavioral economics model and show that the rater’s utility function should account not only for social preferences toward the producer, but also the rater’s psychological aversion toward favoring a producer more than the other rater. Our findings demonstrate that it is critical for policymakers to be cognizant of the nonpecuniary factors that can influence behavior in expert review systems. This paper was accepted by John List, behavioral economics."
/doi/10.1287/opre.1120.1094," Growing social concerns over the environmental externalities associated with business activities are pushing firms to identify activities that create economic value with less environmental impact and to become more eco-efficient. Over the past two decades, researchers have increasingly used frontier efficiency models to evaluate productive efficiency in the presence of undesirable outputs, such as greenhouse gas emissions or toxic emissions. In this paper, we identify critical flaws in existing frontier models and show that these models can identify eco-inefficient firms as eco-efficient. We develop a new eco-inefficiency frontier model that rectifies these problems. Our model calculates an eco-inefficiency score for each firm and improvements in outputs necessary to attain eco-efficiency. We demonstrate through a Monte Carlo experiment that our eco-inefficiency model provides a more reliable measurement of corporate eco-inefficiency than the existing frontier models. We also extend the single-output Cobb-Douglas production function to multiple desirable and undesirable outputs. This extension allows for greater flexibility in the simulation analysis of frontier models."
/doi/10.1287/mksc.17.1.4," In the standard economic account of consumer behavior the cost of a purchase takes the form of a reduction in future utility when expenditures that otherwise could have been made are forgone. The reality of consumer hedonics is different. When people make purchases, they often experience an immediate pain of paying , which can undermine the pleasure derived from consumption. The ticking of the taxi meter, for example, reduces one's pleasure from the ride. We propose a “double-entry” mental accounting theory that describes the nature of these reciprocal interactions between the pleasure of consumption and the pain of paying and draws out their implications for consumer behavior and hedonics. A central assumption of the model, which we call prospective accounting , is that consumption that has already been paid for can be enjoyed as if it were free and that the pain associated with payments made prior to consumption (but not after) is buffered by thoughts of the benefits that the payments will finance. Another important concept is coupling , which refers to the degree to which consumption calls to mind thoughts of payment, and vice versa. Some financing methods, such as credit cards, tend to weaken coupling, whereas others, such as cash payment, produce tight coupling. Our model makes a variety of predictions that are at variance with economic formulations. Contrary to the standard prediction that people will finance purchases to minimize the present value of payments, our model predicts strong debt aversion —that they should prefer to prepay for consumption or to get paid for work after it is performed. Such pay-before sequences confer hedonic benefits because consumption can be enjoyed without thinking about the need to pay for it in the future. Likewise, when paying beforehand, the pain of paying is mitigated by thoughts of future consumption benefits. Contrary to the economic prediction that consumers should prefer to pay, at the margin, for what they consume, our model predicts that consumers will find it less painful to pay for, and hence will prefer, flat-rate pricing schemes such as unlimited Internet access at a fixed monthly price, even if it involves paying more for the same usage. Other predictions concern spending patterns with cash, charge, or credit cards, and preferences for the earmarking of purchases. We test these predictions in a series of surveys and in a conjoint-like analysis that pitted our double-entry mental accounting model against a standard discounting formulation and another benchmark that did not incorporate hedonic interactions between consumption and payments. Our model provides a better fit of the data for 60% of the subjects; the discounting formulation provides a better fit for only 29% of the subjects (even when allowing for positive and negative discount rates). The pain of paying, we argue, plays an important role in consumer self-regulation, but is hedonically costly. From a hedonic perspective the ideal situation is one in which payments are tightly coupled to consumption (so that paying evokes thoughts about the benefits being financed) but consumption is decoupled from payments (so that consumption does not evoke thoughts about payment). From an efficiency perspective, however, it is important for consumers to be aware of what they are paying for consumption. This creates a tension between hedonic efficiency and what we call decision efficiency . Various institutional arrangements, such as financing of public parks through taxes or usage fees, play into this tradeoff. A producer developing a pricing structure for their product or service should be aware of these two conflicting objectives, and should try to devise a structure that reconciles them."
/doi/10.1287/mnsc.2018.3053," A newsvendor game allows the players to collaborate on inventory pooling and share the resulting total cost. There are several possible ways to allocate the cost. Previous studies have focused on the core of the game. It is known that the core of the newsvendor game is nonempty, and one can use duality theory in stochastic programming to construct an allocation—referred to as the dual-based allocation—belonging to the core. Yet, an allocation that lies in the core does not necessarily guarantee the unhindered formation of a coalition, as some existing members’ allocated costs may increase when new members are added in the process. In this work, we use the concept of population monotonic allocation scheme (PMAS), which requires the cost allocated to every member of a coalition to decrease as the coalition grows, to study allocation schemes in a growing population. We show that when the demands faced by the newsvendors are independent, log-concavity of their distributions is sufficient to guarantee the existence of a PMAS. Specifically, for continuous demands, log-concavity ensures that the game is convex, which in turn implies a PMAS exists. We also show that under the same condition the dual-based allocation scheme is a PMAS. For discrete and log-concave demands, however, the game may no longer be convex, but we manage to show that, even so, the dual-based allocation scheme is a PMAS. When the demands are dependent, the game is in general not convex. We derive a sufficient condition based on the dependence structure, measured by the copula, to ensure that the dual-based allocation scheme is still a PMAS. We also include an example of a game with no PMAS. This paper was accepted by Yinyu Ye, optimization. The online appendix is available at https://doi.org/10.1287/mnsc.2018.3053 ."
/doi/10.1287/trsc.32.4.346," The reliability of urban passenger trains is a critical performance measure for passenger satisfaction and ultimately market share. A delay to one train in a peak period can have a severe effect on the schedule adherence of other trains. This paper presents an analytically based model to quantify the expected positive delay for individual passenger trains and track links in an urban rail network. The model specifically addresses direct delay to trains, knock-on delays to other trains, and delays at scheduled connections. A solution to the resultant system of equations is found using an iterative refinement algorithm. Model validation, which is carried out using a real-life suburban train network consisting of 157 trains, shows the model estimates to be on average within 8% of those obtained from a large scale simulation. Also discussed, is the application of the model to assess the consequences of increased scheduled slack time as well as investment strategies designed to reduce delay."
/doi/10.1287/mnsc.1040.0353," This paper empirically documents the association between supply chain glitches and operating performance. The results are based on a sample of 885 glitches announced by publicly traded firms. Changes in various operating performance metrics for the sample firms are compared against a sample of control firms of similar size and from similar industries. In the year leading up to the announcement, the control-adjusted mean percent changes in operating income, return on sales, and return on assets for the sample firms are −107%, −114%, and −92%, respectively. During this same period, the control-adjusted changes in the level of return on sales and return on assets are −13.78% and −2.32%, respectively. Relative to controls, firms that experience glitches report on average 6.92% lower sales growth, 10.66% higher growth in cost, and 13.88% higher growth in inventories. More importantly, firms do not quickly recover from the negative economic consequences of glitches. During the two-year time period after the glitch announcement, operating income, sales, total costs, and inventories do not improve. We also find that it does not matter who caused the glitch, what the reason was for the glitch, or what industry a firm belongs to—glitches are associated with negative operating performance across the board."
/doi/10.1287/mnsc.46.4.563.12061," There have been many claims that the Internet represents a new nearly “frictionless market.” Our research empirically analyzes the characteristics of the Internet as a channel for two categories of homogeneous products—books and CDs. Using a data set of over 8,500 price observations collected over a period of 15 months, we compare pricing behavior at 41 Internet and conventional retail outlets. We find that prices on the Internet are 9–16% lower than prices in conventional outlets, depending on whether taxes, shipping, and shopping costs are included in the price. Additionally, we find that Internet retailers' price adjustments over time are up to 100 times smaller than conventional retailers' price adjustments—presumably reflecting lower menu costs in Internet channels. We also find that levels of price dispersion depend importantly on the measures employed. When we compare the prices posted by different Internet retailers we find substantial dispersion. Internet retailer prices differ by an average of 33% for books and 25% for CDs. However, when we weight these prices by proxies for market share, we find dispersion is lower in Internet channels than in conventional channels, reflecting the dominance of certain heavily branded retailers. We conclude that while there is lower friction in many dimensions of Internet competition, branding, awareness, and trust remain important sources of heterogeneity among Internet retailers."
/doi/10.1287/mnsc.1120.1655," We investigate the effect of financial development on the formation of European corporate groups. Because cross-country regressions are hard to interpret in a causal sense, we exploit exogenous industry measures to investigate a specific channel through which financial development may affect group affiliation: internal capital markets. Using a comprehensive firm-level data set on European corporate groups in 15 countries, we find that countries with less developed financial markets have a higher percentage of group affiliates in more capital-intensive industries. This relationship is more pronounced for young and small firms and for affiliates of large and diversified groups. Our findings are consistent with the view that internal capital markets may, under some conditions, be more efficient than prevailing external markets, and that this may drive group affiliation even in developed economies. This paper was accepted by Bruno Cassiman, business strategy."
/doi/10.1287/mnsc.1120.1537," We consider choice over uncertain, monetary payoffs and study a general class of preferences. These preferences favor diversification, except perhaps on a subset of sufficiently disliked acts over which concentration is instead preferred. This structure encompasses a number of known models (e.g., expected utility and several variants under a concave utility function). We show that such preferences share a representation in terms of a family of measures of risk and targets. Specifically, the choice function is equivalent to selection of a maximum index level such that the risk of beating the target at that level is acceptable. This representation may help to uncover new models of choice. One that we explore in detail is the special case when the targets are bounded. This case corresponds to a type of satisficing and has descriptive relevance. Moreover, the model is amenable to large-scale optimization. This paper was accepted by Teck Ho, decision analysis."
/doi/10.1287/serv.2021.0278," The postpandemic world requires a renewed focus from service providers on ensuring that all customer segments receive the essential services (food, healthcare, housing, education, etc.) that they need. Philanthropic service providers are unable to cope with the increased demand caused by the social, economic, and operational challenges induced by the pandemic. For-profit service providers offering no-pay services to customers, allowing them to self-select a service option, is becoming a popular strategy in various settings. Obtaining insights into how to efficiently balance societal and financial goals is critical for a for-profit service provider. We develop and analyze a quantitative model of customer utilities, vertically differentiated product assortment, pricing, and market size to understand how service providers can effectively use customer segmentation and serve the poor in the lowest economic strata. We identify conditions under which designing the service delivery to be accessible to the poor can simultaneously benefit the for-profit service provider, customers, and the entire society. Interestingly, we observe that the increasing customer valuation of the no-pay option because of a superior quality service offered by a service provider need not benefit customers. Our work provides a framework to obtain operational, economic, and strategic insights into socially responsible service delivery strategies."
/doi/10.1287/mnsc.1080.0907," Good metrics are well-defined formulae (often involving averaging) that transmute multiple measures of raw numerical performance (e.g., dollar sales, referrals, number of customers) to create informative summary statistics (e.g., average share of wallet, average customer tenure). Despite myriad uses (benchmarking, monitoring, allocating resources, diagnosing problems, explanatory variables), most uses require metrics that contain information summarizing multiple observations. On this criterion, we show empirically (with people data) that although averaging has remarkable theoretical properties, supposedly inferior nonaveraging metrics (e.g., maximum, variance) are often better. We explain theoretically (with exact proofs) and numerically (with simulations) when and why. For example, when the environment causes a correlation between observed sample sizes (e.g., number of past purchases, projects, observations) and latent underlying parameters (e.g., the likelihood of favorable outcomes), the maximum statistic is a better metric than the mean. We refer to this environmental effect as the Muth effect, which occurs when rational markets provide more opportunities (i.e., more observations) to individuals and organizations with greater innate ability. Moreover, when environments are adverse (e.g., failure-rich), nonaveraging metrics correctly overweight favorable outcomes. We refer to this environmental effect as the Anna Karenina effect, which occurs when less-favorable outcomes convey less information. These environmental effects impact metric construction, selection, and employment."
/doi/10.1287/serv.1120.0020," This paper presents a metamodel that addresses service system analysis and design based on an operational view of service that traverses and integrates three essential layers: service activities, service systems, and value constellations. The metamodel's service-in-operation perspective and underlying premises diverge from a view of service systems as systems of economic exchange that has appeared a number of times in the journal Service Science . In addition to the metamodel itself, this paper's contributions include an explanation of eight premises on which it is based plus clarifications concerning concepts such as service, service system, customer, product/service, coproduction and cocreation of value, actor role, resources, symmetrical treatment of automated and nonautomated service systems, and the relationship between service-dominant logic and service systems. Many articles have discussed these topics individually; few, if any, have tied them together using an integrated metamodel."
/doi/10.1287/mnsc.2021.4055," Innovation is a contract-intensive economic activity in a world of incomplete contracts. We show that trust mitigates incomplete contracting and enhances innovation by acting as an informal contracting mechanism. Trust plays an especially important role when formal laws and regulations are lacking, and it promotes innovation by encouraging collaboration and fostering tolerance for failure. Further analyses show that trust also facilitates cross-border technological spillover and innovation collaboration. Overall, our evidence highlights innovation as a key conduit through which trust affects economic growth. This paper was accepted by Gustavo Manso, finance."
/doi/10.1287/mnsc.2020.3847," We show that the difference between the natural rate of interest and the current level of monetary policy stance, which we label Convergence Gap (CG), contains information that is valuable for bond predictability. Adding CG in forecasting regressions of bond excess returns significantly raises the R 2 , and restores countercyclical variation in bond risk premia that is otherwise missed by forward rates. Consistent with the argument that CG captures the effect of real imbalances on the path of rates, our factor has predictive ability for real bond excess returns. The importance of the gap remains robust out-of-sample and in countries other than the United States. Furthermore, its inclusion brings significant economic gains in the context of dynamic conditional asset allocation. This paper was accepted by Gustavo Manso, finance."
/doi/10.1287/isre.2021.1071," The proliferation of omnichannel practices and emerging technologies opens up new opportunities for companies to collect voluminous data across multiple channels. This study examines whether leveraging omnichannel data can lead to, statistically and economically, significantly better predictions on consumers’ online path-to-purchase journeys, given the intrinsic fluidity in and heterogeneity brought forth by the digital transformation of traditional marketing. Using an omnichannel data set that captures consumers’ online behavior in terms of their website browsing trajectories and their offline behavior in terms of physical location trajectories, we predict consumers’ future path-to-purchase journeys based on their historical omnichannel behaviors. Using a state-of-the-art deep-learning algorithm, we find that using omnichannel data can significantly improve our model’s predictive power. The lift curve analysis reveals that the omnichannel model outperforms the corresponding single-channel model by 7.38%. This enhanced predictive power benefits various heterogeneous online firms, regardless of their size, offline presence, mobile app availability, or whether they are selling single- or multicategory products. Using an illustrative example of targeted marketing, we further quantify the economic value of the improved predictive power using a cost-revenue analysis. Our paper contributes to the emerging literature on omnichannel marketing and sheds light on the inherent dynamics and fluidity in consumers’ online path-to-purchase journeys."
/doi/10.1287/mnsc.46.12.1569.12077," As result of public housing reform and welfare reform, the operating environment of public housing authorities has changed significantly. Given these policy initiatives, housing mobility programs represent viable strategies for providing public housing residents with access to economically healthy, integrated neighborhoods. In this paper we present a decision support methodology to assist the design of housing mobility programs. This methodology incorporates economic models for estimating dollar-valued impacts associated with tenant relocation, and a multiobjective optimization model for generating alternative relocation schemes associated with various objective function weights. Using data for Lake County, Illinois and Chicago, we demonstrate that nondominated allocations represent significant trade-offs between dollar-valued and non-dollar-valued policy objectives; existing distributions of subsidized housing represent suboptimal solutions to the housing relocation problem; and increases in available rental housing can result in housing dispersion schemes that have positive net economic benefits relative to the status quo."
/doi/10.1287/mnsc.2014.2126," We examine the simultaneous management of hedge funds and funds of hedge funds. Hedge fund firms can choose to simultaneously offer a fund of hedge funds. Similarly, fund of hedge funds firms can simultaneously offer a hedge fund. We find that although superior past performance and larger size drive the decision to become simultaneous for hedge fund firms, past flows drive the decision for fund of hedge funds firms. The effects of simultaneity are also different. When hedge fund firms start funds of hedge funds, we find evidence of value creation, driven by better management of economies of scale and cross learning. In contrast, fund of hedge funds firms starting hedge funds destroy value due to expansion beyond core competencies and agency problems. We find that firms learn about their competencies in the two business lines and discontinue underperforming simultaneity arrangements to focus on the business where they perform better. This paper was accepted by Gustavo Manso, finance ."
/doi/10.1287/trsc.2015.0616," This paper introduces a dynamic spatial price equilibrium model that estimates urban freight-related flows for integrated producer-carrier operations that compete in a market where a generic commodity is traded. The model is applicable to cases where suppliers compete in a market by producing a commodity that is delivered to customers by means of delivery tours. The model obtains the patterns of commodity flows, production levels, and delivery tours that maximize economic welfare. The model is then reinterpreted as a Nash equilibrium model, where a set of suppliers deploys strategies involving production and delivery decisions to maximize profits, that is then solved with a heuristic approach that decomposes the interrelated decisions into how much to produce, how best to deliver to customers, and how much to charge for the cargo. Once the suppliers make these decisions, a market-clearing mechanism determines the amount of supplies that the various consumer nodes purchase from the suppliers. At this stage, the suppliers readjust their market strategies in anticipation of the next time period. The process ends when equilibrium is reached. Three different dynamics of the suppliers’ decisions on production levels are tested to gain insight into how efficiently each helps to reach the equilibrium solutions. By developing a model that explicitly considers delivery tours, the paper makes a significant contribution to the fields of spatial price equilibrium and freight demand modeling."
/doi/10.1287/mnsc.1100.1184," We study the classical problem of capacity and flexible technology selection with a newsvendor network model of resource portfolio investment. The resources differ by their level of flexibility, where “level- k flexibility” refers to the ability to process k different product types. We present an exact set-theoretic methodology to analyze newsvendor networks with multiple products and parallel resources. This simple approach is sufficiently powerful to prove that (i) flexibility exhibits decreasing returns and (ii) the optimal portfolio will invest in at most two, adjacent levels of flexibility in symmetric systems, and to characterize (iii) the optimal flexibility configuration for asymmetric systems as well. The optimal flexibility configuration can serve as a theoretical performance benchmark for other configurations suggested in the literature. For example, although chaining is not optimal in our setting, the gap is small and the inclusion of scale economies quickly favors chaining over pairing . We also demonstrate how this methodology can be applied to other settings such as product substitution and queuing systems with parameter uncertainty."
/doi/10.1287/mnsc.13.10.C207," Fifteen years ago hardly anyone had thought seriously about the need of organized management education in India. Soon after Independence in 1947 a high level Commission on Education was appointed by the Government of India with Dr. S. Radhakrishnan (the present President of India) as Chairman to make a comprehensive study of the various aspects of the educational system then existing and make recommendations for its modification for the new requirements of the nation. This commission however, had little to say on management education. But the formulation of a definite program for planned economic development soon after, brought about a complete change in the situation. The need for technically trained and competent administrative personnel became urgent. As a result, during the past one decade there has been an increasing awareness of the need for providing facilities of training in management."
